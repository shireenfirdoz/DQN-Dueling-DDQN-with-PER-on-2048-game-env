{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import ipdb\n",
    "from six import StringIO\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from collections import namedtuple\n",
    "from numba import jitclass, int64, float32, float64, bool_\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse_loss(input, target, weight):\n",
    "    return torch.sum(weight * (input - target) ** 2)\n",
    "\n",
    "\n",
    "def optimize_model(\n",
    "    dqn_net,\n",
    "    target_net,\n",
    "    memory,\n",
    "    learning_rate,\n",
    "    batch_size,\n",
    "    size_board,\n",
    "    gamma,\n",
    "    optimizer,\n",
    "    device,\n",
    "):\n",
    "\n",
    "    tree_indexes, memory_batch, batch_ISWeights = memory.sample(batch_size)\n",
    "\n",
    "    samples = Transition(*zip(*memory_batch))\n",
    "\n",
    "    states_batch = samples.state\n",
    "    actions_batch = samples.action\n",
    "    rewards_batch = samples.reward\n",
    "    next_states_batch = samples.next_state\n",
    "    dones_batch = samples.done\n",
    "\n",
    "    target_qs_batch = []\n",
    "\n",
    "    torch_next_states_batch = (\n",
    "        torch.from_numpy(np.asarray(next_states_batch)).float().to(device)\n",
    "    )\n",
    "\n",
    "    # Get Q values for next state\n",
    "    q_next_state = dqn_net(torch_next_states_batch, batch_size, size_board)\n",
    "\n",
    "    q_target_next_state = (\n",
    "        target_net(torch_next_states_batch, batch_size, size_board).cpu().detach()\n",
    "    )\n",
    "\n",
    "    for i in range(0, len(memory_batch)):\n",
    "        terminal = dones_batch[i]\n",
    "\n",
    "        action = np.argmax(q_next_state[i].cpu().detach().numpy())\n",
    "\n",
    "        if terminal:\n",
    "            target_qs_batch.append(rewards_batch[i])\n",
    "        else:\n",
    "            target = rewards_batch[i] + gamma * q_target_next_state[i][action]\n",
    "            target_qs_batch.append(target)\n",
    "\n",
    "    targets_batch = np.array([each for each in target_qs_batch])\n",
    "\n",
    "    torch_states_batch = torch.from_numpy(np.asarray(states_batch)).float().to(device)\n",
    "\n",
    "    output = dqn_net(torch_states_batch, batch_size, size_board)\n",
    "\n",
    "    torch_actions_batch = torch.from_numpy(np.asarray(actions_batch))\n",
    "    torch_actions_batch = torch_actions_batch.unsqueeze(0)\n",
    "    torch_actions_batch = torch_actions_batch.view(batch_size, 1)\n",
    "\n",
    "    q_values = output.gather(1, torch_actions_batch.to(device))\n",
    "    q_values = q_values.float()\n",
    "\n",
    "    absolute_errors = (\n",
    "        torch.abs(\n",
    "            q_values\n",
    "            - torch.from_numpy(targets_batch).view(batch_size, 1).float().to(device)\n",
    "        )\n",
    "        .cpu()\n",
    "        .detach()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    torch_batch_ISWeights = torch.from_numpy(batch_ISWeights).to(device)\n",
    "\n",
    "    diff_target = q_values - torch.from_numpy(targets_batch).view(\n",
    "        batch_size, 1\n",
    "    ).float().to(device)\n",
    "    squared_diff = diff_target ** 2\n",
    "    weighted_squared_diff = squared_diff * torch_batch_ISWeights\n",
    "\n",
    "    loss = torch.mean(weighted_squared_diff)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    absolute_errors = np.squeeze(absolute_errors, 1)\n",
    "\n",
    "    memory.batch_update(tree_indexes, absolute_errors)\n",
    "\n",
    "    return loss.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def pre_train(env, pre_train_len, memory):\n",
    "    print(\"Starting pretrain...\")\n",
    "    board, valid_movements = env.reset()\n",
    "    state = to_power_two_matrix(board)\n",
    "\n",
    "    eps_threshold = 1\n",
    "\n",
    "    for i in range(pre_train_len):\n",
    "        action = selection_action(\n",
    "            eps_threshold, valid_movements, None, None, None, None\n",
    "        )\n",
    "\n",
    "        new_board, reward, done, info = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            next_state = np.zeros(state.shape)\n",
    "            memory.store(state, action, reward, next_state, done)\n",
    "\n",
    "            board, valid_movements = env.reset()\n",
    "\n",
    "        else:\n",
    "            next_state = to_power_two_matrix(new_board)\n",
    "            memory.store(state, action, reward, next_state, done)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            valid_movements = info[\"valid_movements\"]\n",
    "\n",
    "\n",
    "def train(\n",
    "    dqn_net,\n",
    "    target_net,\n",
    "    env,\n",
    "    memory,\n",
    "    batch_size,\n",
    "    size_board,\n",
    "    episodes,\n",
    "    ep_update_target,\n",
    "    decay_rate,\n",
    "    explore_start,\n",
    "    explore_stop,\n",
    "    learning_rate,\n",
    "    gamma,\n",
    "    interval_mean,\n",
    "):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dqn_net.to(device)\n",
    "    target_net.to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    decay_step = 0\n",
    "\n",
    "    total_steps_per_episode = []\n",
    "    total_rewards_per_episode = []\n",
    "    total_loss_per_episode = []\n",
    "    total_score_per_episode = []\n",
    "\n",
    "    best_board = None\n",
    "    best_reward = 0\n",
    "    best_score = 0\n",
    "    best_steps = 0\n",
    "    best_ep = -1\n",
    "\n",
    "    optimizer = optim.RMSprop(dqn_net.parameters(), lr=learning_rate)\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        step = 0\n",
    "        episode_rewards = []\n",
    "        board, valid_movements = env.reset()\n",
    "        state = to_power_two_matrix(board)\n",
    "        done = False\n",
    "        loss_ep = []\n",
    "\n",
    "        while True:\n",
    "            step += 1\n",
    "\n",
    "            decay_step += 1\n",
    "\n",
    "            eps_threshold = explore_stop + (explore_start - explore_stop) * np.exp(\n",
    "                -decay_rate * decay_step\n",
    "            )\n",
    "            action = selection_action(\n",
    "                eps_threshold, valid_movements, dqn_net, state, size_board, device\n",
    "            )\n",
    "            new_board, reward, done, info = env.step(action)\n",
    "\n",
    "            episode_rewards.append(reward)\n",
    "\n",
    "            if done:\n",
    "                total_steps_per_episode.append(step)\n",
    "\n",
    "                next_state = np.zeros((1, size_board, size_board, 16))\n",
    "\n",
    "                total_reward = np.sum(episode_rewards)\n",
    "\n",
    "                total_rewards_per_episode.append(total_reward)\n",
    "\n",
    "                memory.store(state, action, reward, next_state, done)\n",
    "\n",
    "                loss_total_ep = np.sum(loss_ep) / step\n",
    "                total_loss_per_episode.append(loss_total_ep)\n",
    "\n",
    "                total_score_per_episode.append(info[\"total_score\"])\n",
    "\n",
    "                print(\"Episode:\", ep)\n",
    "                print(\"Total Reward:\", total_reward)\n",
    "                print(\"Total episodes\", step)\n",
    "                print(\"Eps_threshold:\", eps_threshold)\n",
    "                print(\"Loss ep:\", loss_total_ep)\n",
    "                env.render()\n",
    "                print(\"---------------------------\")\n",
    "\n",
    "                if info[\"total_score\"] > best_score:\n",
    "                    best_score = info[\"total_score\"]\n",
    "                    best_reward = total_reward\n",
    "                    best_ep = ep\n",
    "                    best_board = deepcopy(new_board)\n",
    "                    best_steps = step\n",
    "\n",
    "            else:\n",
    "                next_state = to_power_two_matrix(new_board)\n",
    "\n",
    "                memory.store(state, action, reward, next_state, done)\n",
    "\n",
    "                state = deepcopy(next_state)\n",
    "\n",
    "                valid_movements = info[\"valid_movements\"]\n",
    "\n",
    "                board = deepcopy(new_board)\n",
    "\n",
    "            loss = optimize_model(\n",
    "                dqn_net,\n",
    "                target_net,\n",
    "                memory,\n",
    "                learning_rate,\n",
    "                batch_size,\n",
    "                size_board,\n",
    "                gamma,\n",
    "                optimizer,\n",
    "                device,\n",
    "            )\n",
    "\n",
    "            loss_ep.append(loss)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        if ep % ep_update_target == 0:\n",
    "            target_net = deepcopy(dqn_net)\n",
    "\n",
    "    print(\"***********************\")\n",
    "    print(\"Best ep\", best_ep)\n",
    "    print(\"Best Board:\")\n",
    "    print(best_board)\n",
    "    print(\"Best step\", best_steps)\n",
    "    print(\"Best score\", best_score)\n",
    "    print(\"***********************\")\n",
    "\n",
    "    plot_info(\n",
    "        total_steps_per_episode,\n",
    "        total_rewards_per_episode,\n",
    "        total_loss_per_episode,\n",
    "        total_score_per_episode,\n",
    "        interval_mean,\n",
    "        episodes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipdb in /home/duvvuri.s/.local/lib/python3.7/site-packages (0.13.9)\n",
      "Requirement already satisfied: decorator; python_version > \"3.6\" in /home/ood.discovery.neu.edu/software/anaconda3/2019.10/lib/python3.7/site-packages (from ipdb) (4.4.0)\n",
      "Requirement already satisfied: setuptools in /home/ood.discovery.neu.edu/software/anaconda3/2019.10/lib/python3.7/site-packages (from ipdb) (41.4.0)\n",
      "Requirement already satisfied: toml>=0.10.2; python_version > \"3.6\" in /home/duvvuri.s/.local/lib/python3.7/site-packages (from ipdb) (0.10.2)\n",
      "Requirement already satisfied: ipython>=7.17.0; python_version > \"3.6\" in /home/duvvuri.s/.local/lib/python3.7/site-packages (from ipdb) (7.30.1)\n",
      "Requirement already satisfied: backcall in /home/ood.discovery.neu.edu/software/anaconda3/2019.10/lib/python3.7/site-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.1.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/duvvuri.s/.local/lib/python3.7/site-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.1.3)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/ood.discovery.neu.edu/software/anaconda3/2019.10/lib/python3.7/site-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (4.3.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/duvvuri.s/.local/lib/python3.7/site-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /home/ood.discovery.neu.edu/software/anaconda3/2019.10/lib/python3.7/site-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (4.7.0)\n",
      "Requirement already satisfied: pygments in /home/ood.discovery.neu.edu/software/anaconda3/2019.10/lib/python3.7/site-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (2.4.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ood.discovery.neu.edu/software/anaconda3/2019.10/lib/python3.7/site-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (2.0.10)\n",
      "Requirement already satisfied: pickleshare in /home/ood.discovery.neu.edu/software/anaconda3/2019.10/lib/python3.7/site-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.7.5)\n",
      "Requirement already satisfied: ipython-genutils in /home/ood.discovery.neu.edu/software/anaconda3/2019.10/lib/python3.7/site-packages (from traitlets>=4.2->ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.2.0)\n",
      "Requirement already satisfied: six in /home/ood.discovery.neu.edu/software/anaconda3/2019.10/lib/python3.7/site-packages (from traitlets>=4.2->ipython>=7.17.0; python_version > \"3.6\"->ipdb) (1.12.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/duvvuri.s/.local/lib/python3.7/site-packages (from jedi>=0.16->ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ood.discovery.neu.edu/software/anaconda3/2019.10/lib/python3.7/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /home/ood.discovery.neu.edu/software/anaconda3/2019.10/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.1.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipdb --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = [\n",
    "    (\"__size_board\", int64),\n",
    "    (\"__seed\", int64),\n",
    "    (\"__board\", float64[:, :]),\n",
    "    (\"__total_score\", int64),\n",
    "    (\"__merged\", int64),\n",
    "    (\"__scores_move\", int64),\n",
    "    (\"__temp_board\", float64[:, :]),\n",
    "    (\"__valid_movements\", float64[:]),\n",
    "]\n",
    "\n",
    "\n",
    "@jitclass(spec)\n",
    "class Game2048:\n",
    "\n",
    "    def __init__(self, size_board, seed):\n",
    "\n",
    "        self.__size_board = size_board\n",
    "        self.__seed = seed\n",
    "\n",
    "        self.__board = self.__init_board()\n",
    "        self.__total_score = 0\n",
    "        self.__merged = 0\n",
    "        self.__scores_move = 0\n",
    "        self.__temp_board = np.zeros((size_board, size_board))\n",
    "\n",
    "        self.__valid_movements = np.zeros(4)\n",
    "\n",
    "        if self.__seed:\n",
    "            random.seed(self.__seed)\n",
    "\n",
    "        self.__add_two_or_four()\n",
    "        self.__add_two_or_four()\n",
    "\n",
    "    def __init_board(self):\n",
    "        return np.zeros((self.__size_board, self.__size_board))\n",
    "\n",
    "    def __get_empty_spaces_index(self):\n",
    "        return np.where(self.__board == 0)\n",
    "\n",
    "    def __add_two_or_four(self):\n",
    "        indexes = self.__get_empty_spaces_index()\n",
    "\n",
    "        index = np.random.choice(np.arange(len(indexes[0])))\n",
    "\n",
    "        sample = np.random.rand(1)\n",
    "\n",
    "        if sample[0] >= 0.9:\n",
    "            self.__board[indexes[0][index]][indexes[1][index]] = 4\n",
    "        else:\n",
    "            self.__board[indexes[0][index]][indexes[1][index]] = 2\n",
    "\n",
    "    def __reverse_array(self, array):\n",
    "        temp_array = np.zeros(len(array))\n",
    "        for cell in range(len(array)):\n",
    "            temp_array[cell] = array[len(array) - cell - 1]\n",
    "\n",
    "        return temp_array\n",
    "\n",
    "    def __merge(self, array, reverse):\n",
    "        array = array[array != 0]\n",
    "\n",
    "        temp_array = np.zeros(self.__size_board)\n",
    "        if reverse:\n",
    "            count_index = self.__size_board - 1\n",
    "        else:\n",
    "            count_index = 0\n",
    "        i = 0\n",
    "        while True:\n",
    "            if i >= (len(array) - 1):\n",
    "                if i == (len(array) - 1):\n",
    "                    temp_array[count_index] = array[i]\n",
    "                return temp_array\n",
    "\n",
    "            if (array[i] == array[i + 1]) and array[i] != 0:\n",
    "                temp_array[count_index] = array[i] + array[i + 1]\n",
    "                self.__scores_move += temp_array[count_index]\n",
    "                self.__merged += 1\n",
    "                i = i + 2\n",
    "                if reverse:\n",
    "                    count_index -= 1\n",
    "                else:\n",
    "                    count_index += 1\n",
    "            else:\n",
    "                if array[i] != 0:\n",
    "                    temp_array[count_index] = array[i]\n",
    "                    if reverse:\n",
    "                        count_index -= 1\n",
    "                    else:\n",
    "                        count_index += 1\n",
    "                i = i + 1\n",
    "\n",
    "    def __up(self):\n",
    "        self.__temp_board = np.zeros((self.__size_board, self.__size_board))\n",
    "        for column in range(self.__size_board):\n",
    "            self.__temp_board[:, column] = self.__merge(\n",
    "                self.__board[:, column].copy(), False\n",
    "            )\n",
    "\n",
    "    def __down(self):\n",
    "        self.__temp_board = np.zeros((self.__size_board, self.__size_board))\n",
    "        for column in range(self.__size_board):\n",
    "            self.__temp_board[:, column] = self.__merge(\n",
    "                self.__reverse_array(self.__board[:, column].copy()), True\n",
    "            )\n",
    "\n",
    "    def __right(self):\n",
    "        self.__temp_board = np.zeros((self.__size_board, self.__size_board))\n",
    "        for line in range(self.__size_board):\n",
    "            self.__temp_board[line, :] = self.__merge(\n",
    "                self.__reverse_array(self.__board[line, :].copy()), True\n",
    "            )\n",
    "\n",
    "    def __left(self):\n",
    "        self.__temp_board = np.zeros((self.__size_board, self.__size_board))\n",
    "        for line in range(self.__size_board):\n",
    "            self.__temp_board[line, :] = self.__merge(\n",
    "                self.__board[line, :].copy(), False\n",
    "            )\n",
    "\n",
    "    def __array_equal(self, a, b):\n",
    "        for value_a, value_b in zip(a.flat, b.flat):\n",
    "            if value_a != value_b:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def __check_available_moves(self):\n",
    "        self.__valid_movements = np.zeros(4)\n",
    "        for i in range(4):\n",
    "            self.make_move(i)\n",
    "            if self.__array_equal(self.__board, self.__temp_board) is False:\n",
    "                self.__valid_movements[i] = 1\n",
    "\n",
    "    def make_move(self, move):\n",
    "        self.__merged = 0\n",
    "        self.__scores_move = 0\n",
    "        if move == 0:\n",
    "            self.__up()\n",
    "        if move == 1:\n",
    "            self.__down()\n",
    "        if move == 2:\n",
    "            self.__right()\n",
    "        if move == 3:\n",
    "            self.__left()\n",
    "\n",
    "    def confirm_move(self):\n",
    "        self.__board = self.__temp_board.copy()\n",
    "        self.__total_score += self.__scores_move\n",
    "        returned_move_scores = self.__scores_move\n",
    "        returned_merged = self.__merged\n",
    "        self.__add_two_or_four()\n",
    "        self.__check_available_moves()\n",
    "\n",
    "        return returned_move_scores, returned_merged, self.__valid_movements\n",
    "\n",
    "    def get_board(self):\n",
    "        return self.__board\n",
    "\n",
    "    def get_total_score(self):\n",
    "        return self.__total_score\n",
    "\n",
    "    def reset(self):\n",
    "        self.__board = self.__init_board()\n",
    "        self.__total_score = 0\n",
    "        self.__add_two_or_four()\n",
    "        self.__add_two_or_four()\n",
    "        return self.get_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvalidMove(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Game2048Env(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"human\", \"ansi\"]}\n",
    "\n",
    "    def __init__(self, size_board, seed=None):\n",
    "        self.__size_board = size_board\n",
    "        self.__game = Game2048(size_board, seed)\n",
    "\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            0, 2 ** 16, (size_board * size_board,), dtype=np.int\n",
    "        )\n",
    "\n",
    "        self.reward_range = (0., np.inf)\n",
    "\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "\n",
    "        self.__actions_legends = {0: \"UP\", 1: \"DOWN\", 2: \"RIGHT\", 3: \"LEFT\"}\n",
    "\n",
    "        self.__old_max = 0\n",
    "\n",
    "        self.__last_action = None\n",
    "        self.__last_scores_move = None\n",
    "\n",
    "        print(\"Environment initialised...\")\n",
    "\n",
    "    def __reward_calculation(self, merged):\n",
    "        reward = 0\n",
    "        max_board = self.__game.get_board().max()\n",
    "        if max_board > self.__old_max:\n",
    "            self.__old_max = max_board\n",
    "            reward += math.log(self.__old_max, 2) * 0.1\n",
    "\n",
    "        reward += merged\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def reset(self):\n",
    "        self.__game.reset()\n",
    "        valid_movements = np.ones(4)\n",
    "        return (self.__game.get_board(), valid_movements)\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = 0\n",
    "        try:\n",
    "            self.__last_action = self.__actions_legends[action]\n",
    "\n",
    "            self.__game.make_move(action)\n",
    "            returned_move_scores, returned_merged, valid_movements = (\n",
    "                self.__game.confirm_move()\n",
    "            )\n",
    "\n",
    "            reward = self.__reward_calculation(returned_merged)\n",
    "\n",
    "            if len(np.nonzero(valid_movements)[0]) == 0:\n",
    "                done = True\n",
    "\n",
    "            self.__last_scores_move = returned_move_scores\n",
    "\n",
    "            info = dict()\n",
    "            info[\"valid_movements\"] = valid_movements\n",
    "            info[\"total_score\"] = self.__game.get_total_score()\n",
    "            info[\"last_action\"] = self.__actions_legends[action]\n",
    "            info[\"scores_move\"] = returned_move_scores\n",
    "            return self.__game.get_board(), reward, done, info\n",
    "\n",
    "        except InvalidMove as e:\n",
    "            print(\"Invalid move\")\n",
    "            done = False\n",
    "            reward = 0\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        outfile = StringIO() if mode == \"ansi\" else sys.stdout\n",
    "        info_render = \"Score: {}\\n\".format(self.__game.get_total_score())\n",
    "        info_render += \"Highest: {}\\n\".format(self.__game.get_board().max())\n",
    "        npa = np.array(self.__game.get_board())\n",
    "        grid = npa.reshape((self.__size_board, self.__size_board))\n",
    "        info_render += \"{}\\n\".format(grid)\n",
    "        info_render += \"Last action: {}\\n\".format(self.__last_action)\n",
    "        info_render += \"Last scores move: {}\".format(self.__last_scores_move)\n",
    "        info_render += \"\\n\"\n",
    "        outfile.write(info_render)\n",
    "        return outfile\n",
    "\n",
    "    def get_actions_legends(self):\n",
    "        return self.__actions_legends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_sum_tree = [\n",
    "    (\"__capacity\", int64),\n",
    "    (\"__data_pointer\", int64),\n",
    "    (\"__tree\", float64[:]),\n",
    "    (\"__state\", float64[:, :, :, :, :]),\n",
    "    (\"__action\", int64[:]),\n",
    "    (\"__reward\", float64[:]),\n",
    "    (\"__next_state\", float64[:, :, :, :, :]),\n",
    "    (\"__done\", bool_[:]),\n",
    "]\n",
    "\n",
    "\n",
    "@jitclass(spec_sum_tree)\n",
    "class SumTree:\n",
    "    def __init__(self, capacity, size_board=4):\n",
    "        self.__data_pointer = 0\n",
    "        self.__capacity = capacity\n",
    "        self.__tree = np.zeros(2 * capacity - 1)\n",
    "\n",
    "        self.__state = np.zeros((capacity, 1, size_board, size_board, 16))\n",
    "        self.__action = np.zeros(capacity, dtype=np.int64)\n",
    "        self.__reward = np.zeros(capacity)\n",
    "        self.__next_state = np.zeros((capacity, 1, size_board, size_board, 16))\n",
    "        self.__done = np.zeros(capacity, dtype=np.bool_)\n",
    "\n",
    "    def update(self, tree_index, priority):\n",
    "        change = priority - self.__tree[tree_index]\n",
    "        self.__tree[tree_index] = priority\n",
    "        while tree_index != 0:\n",
    "            tree_index = (tree_index - 1) // 2\n",
    "            self.__tree[tree_index] += change\n",
    "\n",
    "    def add(self, priority, state, action, reward, next_state, done):\n",
    "        self.__state[self.__data_pointer] = state\n",
    "        self.__action[self.__data_pointer] = action\n",
    "        self.__reward[self.__data_pointer] = reward\n",
    "        self.__next_state[self.__data_pointer] = next_state\n",
    "        self.__done[self.__data_pointer] = done\n",
    "\n",
    "        tree_index = self.__data_pointer + self.__capacity - 1\n",
    "        self.update(tree_index, priority)\n",
    "\n",
    "        self.__data_pointer += 1\n",
    "\n",
    "        if self.__data_pointer >= self.__capacity:\n",
    "            self.__data_pointer = 0\n",
    "\n",
    "    def get_leaf(self, value):\n",
    "        parent_index = 0\n",
    "\n",
    "        while True:\n",
    "            left_child_index = 2 * parent_index + 1\n",
    "            right_child_index = left_child_index + 1\n",
    "            if left_child_index >= len(self.__tree):\n",
    "                leaf_index = parent_index\n",
    "                break\n",
    "\n",
    "            else: \n",
    "                if value <= self.__tree[left_child_index]:\n",
    "                    parent_index = left_child_index\n",
    "                else:\n",
    "                    value -= self.__tree[left_child_index]\n",
    "                    parent_index = right_child_index\n",
    "\n",
    "        data_index = leaf_index - self.__capacity + 1\n",
    "\n",
    "        return (\n",
    "            leaf_index,\n",
    "            self.__tree[leaf_index],\n",
    "            self.__state[data_index],\n",
    "            self.__action[data_index],\n",
    "            self.__reward[data_index],\n",
    "            self.__next_state[data_index],\n",
    "            self.__done[data_index],\n",
    "        )\n",
    "\n",
    "    def total_priority(self):\n",
    "        return self.__tree[0]\n",
    "\n",
    "    def get_priotiry(self):\n",
    "        return self.__tree[-self.__capacity:]\n",
    "\n",
    "    def get_all_tree(self):\n",
    "        return self.__tree\n",
    "\n",
    "\n",
    "spec_memory = [\n",
    "    (\"__per_e\", float64),\n",
    "    (\"__per_a\", float64),\n",
    "    (\"__per_b\", float64),\n",
    "    (\"__per_b_increment_per_sampling\", float64),\n",
    "    (\"__absolute_error_uper\", float64),\n",
    "    (\"__tree\", SumTree),\n",
    "]\n",
    "\n",
    "\n",
    "Transition = namedtuple(\n",
    "    \"Transition\", (\"state\", \"action\", \"reward\", \"next_state\", \"done\")\n",
    ")\n",
    "\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, size_board, capacity):\n",
    "        self.__capacity = capacity\n",
    "        self.__per_e = 0.01\n",
    "        self.__per_a = 0.6\n",
    "        self.__per_b = 0.4\n",
    "        self.__per_b_increment_per_sampling = 0.001\n",
    "        self.__absolute_error_upper = 1.\n",
    "        self.__tree = SumTree(capacity, size_board)\n",
    "    spec_store = [(\"max_priority\", float64)]\n",
    "\n",
    "    def store(self, state, action, reward, next_state, done):\n",
    "        max_priority = np.max(self.__tree.get_priotiry())\n",
    "        if max_priority == 0:\n",
    "            max_priority = self.__absolute_error_upper\n",
    "        self.__tree.add(max_priority, state, action, reward, next_state, done)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        memory_batch = []\n",
    "\n",
    "        batch_idx, batch_ISWeights = (\n",
    "            np.empty((batch_size,), dtype=np.int32),\n",
    "            np.empty((batch_size, 1), dtype=np.float32),\n",
    "        )\n",
    "        priority_segment = self.__tree.total_priority() / batch_size\n",
    "        self.__per_b = np.min(\n",
    "            [1., self.__per_b + self.__per_b_increment_per_sampling]\n",
    "        )\n",
    "        p_min = np.min(self.__tree.get_priotiry()) / self.__tree.total_priority()\n",
    "        max_weight = (p_min * batch_size) ** (-self.__per_b)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            limit_a, limit_b = priority_segment * i, priority_segment * (i + 1)\n",
    "            value = np.random.uniform(limit_a, limit_b)\n",
    "\n",
    "            index, priority, state, action, reward, next_state, done = self.__tree.get_leaf(\n",
    "                value\n",
    "            )\n",
    "\n",
    "            sampling_probabilities = priority / self.__tree.total_priority()\n",
    "\n",
    "            batch_ISWeights[i, 0] = (\n",
    "                np.power(batch_size * sampling_probabilities, -self.__per_b)\n",
    "                / max_weight\n",
    "            )\n",
    "\n",
    "            batch_idx[i] = index\n",
    "            memory_batch.append(Transition(state, action, reward, next_state, done))\n",
    "\n",
    "        return batch_idx, memory_batch, batch_ISWeights\n",
    "\n",
    "    def batch_update(self, tree_indexes, abs_errors):\n",
    "        abs_errors += self.__per_e\n",
    "        clipped_errors = np.minimum(abs_errors, self.__absolute_error_upper)\n",
    "        priorities = np.power(clipped_errors, self.__per_a)\n",
    "\n",
    "        for tree_index, priority in zip(tree_indexes, priorities):\n",
    "            self.__tree.update(tree_index, priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def to_power_two_matrix(matrix):\n",
    "    power_matrix = np.zeros(\n",
    "        shape=(1, matrix.shape[0], matrix.shape[1], 16), dtype=np.float32\n",
    "    )\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            if matrix[i][j] == 0:\n",
    "                power_matrix[0][i][j][0] = 1.0\n",
    "            else:\n",
    "                power = int(np.log(matrix[i][j]) / np.log(2))\n",
    "                power_matrix[0][i][j][power] = 1.0\n",
    "\n",
    "    return power_matrix\n",
    "\n",
    "\n",
    "def selection_action(\n",
    "    eps_threshold, valid_movements, dqn_net, state, size_board, device\n",
    "):\n",
    "    sample = np.random.rand(1)\n",
    "\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            output = dqn_net(torch.from_numpy(state).float().to(device), 1, size_board)\n",
    "            output_np = output.cpu().detach().numpy()\n",
    "            ordered = np.flip(np.argsort(output_np), axis=1)[0]\n",
    "            for x in ordered:\n",
    "                if valid_movements[x] != 0:\n",
    "                    return x\n",
    "\n",
    "    else:\n",
    "        return np.random.choice(np.nonzero(valid_movements)[0])\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--seed\", type=int, default=10)\n",
    "    parser.add_argument(\"--capacity\", type=int, default=100000)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--size_board\", type=int, default=4)\n",
    "    parser.add_argument(\"--num_episodes\", type=int, default=1000)\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.00025)\n",
    "    parser.add_argument(\"--ep_update_target\", type=int, default=10)\n",
    "    parser.add_argument(\"--decay_rate\", type=float, default=0.00005)\n",
    "    parser.add_argument(\"--interval_mean\", type=int, default=5)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_mean_interval(array, interval_mean):\n",
    "    interval_mean_list = []\n",
    "    for x in range(interval_mean):\n",
    "        interval_mean_list.append(0)\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        if i + interval_mean == len(array):\n",
    "            break\n",
    "        else:\n",
    "            interval_mean_list.append(np.mean(array[i: interval_mean + i]))\n",
    "\n",
    "    return interval_mean_list\n",
    "\n",
    "\n",
    "def plot_info(\n",
    "    total_steps_per_episode,\n",
    "    total_rewards_per_episode,\n",
    "    total_loss_per_episode,\n",
    "    total_score_per_episode,\n",
    "    interval_mean,\n",
    "    episodes,\n",
    "):\n",
    "\n",
    "    interval_steps = get_mean_interval(total_steps_per_episode, interval_mean)\n",
    "    plt.plot(range(episodes), total_steps_per_episode)\n",
    "    plt.plot(range(episodes), interval_steps)\n",
    "    plt.ylabel(\"Episode durations\")\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.savefig(\"episodes_durations.png\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    interval_rewards = get_mean_interval(total_rewards_per_episode, interval_mean)\n",
    "    plt.plot(range(episodes), total_rewards_per_episode)\n",
    "    plt.plot(range(episodes), interval_rewards)\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.savefig(\"episodes_rewards.png\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    interval_score = get_mean_interval(total_score_per_episode, interval_mean)\n",
    "    plt.plot(range(episodes), total_score_per_episode)\n",
    "    plt.plot(range(episodes), interval_score)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.savefig(\"episodes_scores.png\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    interval_loss = get_mean_interval(total_loss_per_episode, interval_mean)\n",
    "    plt.plot(range(episodes), total_loss_per_episode)\n",
    "    plt.plot(range(episodes), interval_loss)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.savefig(\"episodes_losses.png\", bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_2048_MODEL(nn.Module):\n",
    "    def __init__(self, c_in_1, c_in_2, c_out_1, c_out_2):\n",
    "        super(CNN_2048_MODEL, self).__init__()\n",
    "        self.__c_in_1 = c_in_1\n",
    "        self.__c_in_2 = c_in_2\n",
    "        self.__c_out_1 = c_out_1\n",
    "        self.__c_out_2 = c_out_2\n",
    "\n",
    "        self.__expanded_size = (\n",
    "            2 * 4 * c_out_2 * 2 + 3 * 3 * c_out_2 * 2 + 4 * 3 * c_out_1 * 2\n",
    "        )\n",
    "\n",
    "        self.__dense_value_1 = nn.Linear(self.__expanded_size, 256)\n",
    "        self.__dense_value_2 = nn.Linear(256, 1)\n",
    "        self.__dense_advantage_1 = nn.Linear(self.__expanded_size, 256)\n",
    "        self.__dense_advantage_2 = nn.Linear(256, 4)\n",
    "\n",
    "        self.__cnn_1 = nn.Conv2d(\n",
    "            c_in_1,\n",
    "            c_out_1,\n",
    "            kernel_size=(1, 2),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "            dilation=(1, 1),\n",
    "        )\n",
    "\n",
    "        self.__cnn_1_2 = nn.Conv2d(\n",
    "            c_out_1,\n",
    "            c_out_2,\n",
    "            kernel_size=(1, 2),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "            dilation=(1, 1),\n",
    "        )\n",
    "\n",
    "        self.__cnn_2 = nn.Conv2d(\n",
    "            c_in_2,\n",
    "            c_out_2,\n",
    "            kernel_size=(2, 1),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "            dilation=(1, 1),\n",
    "        )\n",
    "\n",
    "        self.__cnn_2_2 = nn.Conv2d(\n",
    "            c_out_1,\n",
    "            c_out_2,\n",
    "            kernel_size=(2, 1),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "            dilation=(1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, features, batch_size, size_board):\n",
    "        features_view = features.view(batch_size, 16, size_board, size_board)\n",
    "        conv1_output = F.elu(self.__cnn_1(features_view))\n",
    "        conv2_output = F.elu(self.__cnn_2(features_view))\n",
    "        conv1_2_1_output = F.elu(self.__cnn_1_2(conv1_output))\n",
    "        conv1_2_2_output = F.elu(self.__cnn_1_2(conv2_output))\n",
    "        conv2_2_1_output = F.elu(self.__cnn_2_2(conv1_output))\n",
    "        conv2_2_2_output = F.elu(self.__cnn_2_2(conv2_output))\n",
    "\n",
    "        conv1_output_shape = list(conv1_output.shape)\n",
    "        conv2_output_shape = list(conv2_output.shape)\n",
    "        conv1_2_1_output_shape = list(conv1_2_1_output.shape)\n",
    "        conv1_2_2_output_shape = list(conv1_2_2_output.shape)\n",
    "        conv2_2_1_output_shape = list(conv2_2_1_output.shape)\n",
    "        conv2_2_2_output_shape = list(conv2_2_2_output.shape)\n",
    "\n",
    "        hidden1 = conv1_output.view(\n",
    "            batch_size,\n",
    "            (conv1_output_shape[1] * conv1_output_shape[2] * conv1_output_shape[3]),\n",
    "        )\n",
    "\n",
    "        hidden2 = conv2_output.view(\n",
    "            batch_size,\n",
    "            (conv2_output_shape[1] * conv2_output_shape[2] * conv2_output_shape[3]),\n",
    "        )\n",
    "\n",
    "        hidden1_2_1 = conv1_2_1_output.view(\n",
    "            batch_size,\n",
    "            (\n",
    "                conv1_2_1_output_shape[1]\n",
    "                * conv1_2_1_output_shape[2]\n",
    "                * conv1_2_1_output_shape[3]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        hidden1_2_2 = conv1_2_2_output.view(\n",
    "            batch_size,\n",
    "            (\n",
    "                conv1_2_2_output_shape[1]\n",
    "                * conv1_2_2_output_shape[2]\n",
    "                * conv1_2_2_output_shape[3]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        hidden2_2_1 = conv2_2_1_output.view(\n",
    "            batch_size,\n",
    "            (\n",
    "                conv2_2_1_output_shape[1]\n",
    "                * conv2_2_1_output_shape[2]\n",
    "                * conv2_2_1_output_shape[3]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        hidden2_2_2 = conv2_2_2_output.view(\n",
    "            batch_size,\n",
    "            (\n",
    "                conv2_2_2_output_shape[1]\n",
    "                * conv2_2_2_output_shape[2]\n",
    "                * conv2_2_2_output_shape[3]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        hidden = torch.cat(\n",
    "            (hidden1, hidden2, hidden1_2_1, hidden1_2_2, hidden2_2_1, hidden2_2_2), 1\n",
    "        )\n",
    "\n",
    "        hidden_value_1 = F.elu(self.__dense_value_1(hidden))\n",
    "        hidden_value_2 = self.__dense_value_2(hidden_value_1)\n",
    "\n",
    "        advantage_action_1 = F.elu(self.__dense_advantage_1(hidden))\n",
    "        advantage_action_2 = self.__dense_advantage_2(advantage_action_1)\n",
    "\n",
    "        reduced_mean = torch.mean(advantage_action_2, dim=1, keepdim=True)\n",
    "        output = hidden_value_2 + (advantage_action_2 - reduced_mean)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numba==0.47.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    seed = 10\n",
    "    capacity = 100000\n",
    "    size_board = 4\n",
    "    batch_size = 128\n",
    "    episodes = 1000\n",
    "    ep_update_target = 100\n",
    "    learning_rate = 0.00025\n",
    "    decay_rate = 0.00005\n",
    "    interval_mean = 5\n",
    "    explore_start = 1.\n",
    "    explore_stop = 0.01\n",
    "    gamma = 0.95\n",
    "\n",
    "    env = Game2048Env(size_board, seed)\n",
    "\n",
    "    memory = Memory(size_board, capacity)\n",
    "\n",
    "    c_in_1 = c_in_2 = size_board * size_board\n",
    "    c_out_1 = c_out_2 = 128\n",
    "    dqn_net = CNN_2048_MODEL(c_in_1, c_in_2, c_out_1, c_out_2)\n",
    "    target_net = deepcopy(dqn_net)\n",
    "\n",
    "    start = time.time()\n",
    "    pre_train(env, capacity, memory)\n",
    "    print(\"Execution pre-train (in seconds):\", time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    train(\n",
    "        dqn_net,\n",
    "        target_net,\n",
    "        env,\n",
    "        memory,\n",
    "        batch_size,\n",
    "        size_board,\n",
    "        episodes,\n",
    "        ep_update_target,\n",
    "        decay_rate,\n",
    "        explore_start,\n",
    "        explore_stop,\n",
    "        learning_rate,\n",
    "        gamma,\n",
    "        interval_mean,\n",
    "    )\n",
    "    print(\"Execution train (in seconds)\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment initialised...\n",
      "Starting pretrain...\n",
      "Execution pre-train (in seconds): 18.706619262695312\n",
      "Starting training...\n",
      "Episode: 0\n",
      "Total Reward: 108\n",
      "Total episodes 122\n",
      "Eps_threshold: 0.9939793815551794\n",
      "Loss ep: 0.40106879687700114\n",
      "Score: 1012\n",
      "Highest: 64.0\n",
      "[[ 2. 16. 32.  4.]\n",
      " [ 8. 64.  8. 64.]\n",
      " [ 4. 16.  2.  8.]\n",
      " [ 2.  4. 32.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Update target_net\n",
      "Episode: 1\n",
      "Total Reward: 171\n",
      "Total episodes 185\n",
      "Eps_threshold: 0.9849195386477164\n",
      "Loss ep: 0.11639946602486276\n",
      "Score: 2200\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  4.  64.  16.   4.]\n",
      " [  8.   4. 256.   8.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 2\n",
      "Total Reward: 73\n",
      "Total episodes 87\n",
      "Eps_threshold: 0.9806878492518778\n",
      "Loss ep: 0.0816317700791633\n",
      "Score: 632\n",
      "Highest: 64.0\n",
      "[[ 2.  8.  4.  2.]\n",
      " [ 4. 16.  8.  4.]\n",
      " [16. 64. 32.  8.]\n",
      " [ 8.  2. 16.  4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 3\n",
      "Total Reward: 96\n",
      "Total episodes 110\n",
      "Eps_threshold: 0.9753637208553166\n",
      "Loss ep: 0.06599243770946156\n",
      "Score: 940\n",
      "Highest: 64.0\n",
      "[[ 2.  4. 32.  8.]\n",
      " [64. 16. 64. 32.]\n",
      " [ 2.  4.  2.  4.]\n",
      " [ 4.  8.  4.  2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 4\n",
      "Total Reward: 120\n",
      "Total episodes 134\n",
      "Eps_threshold: 0.9689174032042989\n",
      "Loss ep: 0.04961230505758257\n",
      "Score: 1256\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [ 32. 128.  32.   4.]\n",
      " [  4.  16.   8.  16.]\n",
      " [  8.  32.   2.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 5\n",
      "Total Reward: 135\n",
      "Total episodes 149\n",
      "Eps_threshold: 0.9618000137455393\n",
      "Loss ep: 0.04821200018761142\n",
      "Score: 1436\n",
      "Highest: 128.0\n",
      "[[ 16.   2.  64.   2.]\n",
      " [  2.   8.  32.   8.]\n",
      " [128.  32.   4.   2.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 32\n",
      "---------------------------\n",
      "Episode: 6\n",
      "Total Reward: 49\n",
      "Total episodes 63\n",
      "Eps_threshold: 0.9588065608657375\n",
      "Loss ep: 0.047315442372882176\n",
      "Score: 380\n",
      "Highest: 32.0\n",
      "[[ 2.  8.  4.  2.]\n",
      " [32. 16.  8.  4.]\n",
      " [ 2. 32.  4.  2.]\n",
      " [ 4.  2. 16.  4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 7\n",
      "Total Reward: 103\n",
      "Total episodes 117\n",
      "Eps_threshold: 0.9532722461384151\n",
      "Loss ep: 0.05073599122528337\n",
      "Score: 1112\n",
      "Highest: 128.0\n",
      "[[  4.   2.   8.   4.]\n",
      " [  2.  32. 128.   8.]\n",
      " [  4.  16.  32.   2.]\n",
      " [  2.   4.   2.  16.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 8\n",
      "Total Reward: 79\n",
      "Total episodes 93\n",
      "Eps_threshold: 0.9488962123574752\n",
      "Loss ep: 0.050357705803327664\n",
      "Score: 672\n",
      "Highest: 64.0\n",
      "[[ 2. 16.  8.  2.]\n",
      " [16.  4. 16.  4.]\n",
      " [ 4. 32. 64.  8.]\n",
      " [ 2.  8.  2. 16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 9\n",
      "Total Reward: 91\n",
      "Total episodes 105\n",
      "Eps_threshold: 0.9439799237921774\n",
      "Loss ep: 0.050755909511021206\n",
      "Score: 984\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  4.  32.   2.   8.]\n",
      " [  8.   4.   8. 128.]\n",
      " [  4.   2.  16.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 10\n",
      "Total Reward: 81\n",
      "Total episodes 95\n",
      "Eps_threshold: 0.9395540389522419\n",
      "Loss ep: 0.05016230031063682\n",
      "Score: 708\n",
      "Highest: 64.0\n",
      "[[ 2. 16.  8.  2.]\n",
      " [32.  2. 16.  8.]\n",
      " [ 4.  8. 64.  4.]\n",
      " [ 2.  4. 32.  2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 11\n",
      "Total Reward: 123\n",
      "Total episodes 137\n",
      "Eps_threshold: 0.9332083525742001\n",
      "Loss ep: 0.04900519865272689\n",
      "Score: 1296\n",
      "Highest: 128.0\n",
      "[[ 32.   4.  32.  16.]\n",
      " [  8. 128.  16.   2.]\n",
      " [  4.  16.  32.   4.]\n",
      " [  2.   4.  16.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 12\n",
      "Total Reward: 84\n",
      "Total episodes 98\n",
      "Eps_threshold: 0.9286956966825898\n",
      "Loss ep: 0.04810601351212482\n",
      "Score: 776\n",
      "Highest: 64.0\n",
      "[[ 2.  8. 32.  8.]\n",
      " [ 8. 32.  2. 16.]\n",
      " [ 2.  8. 64.  8.]\n",
      " [ 4.  2. 32.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 13\n",
      "Total Reward: 104\n",
      "Total episodes 118\n",
      "Eps_threshold: 0.923291350570292\n",
      "Loss ep: 0.045702675641593284\n",
      "Score: 1080\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   8.]\n",
      " [  4. 128.   8.  16.]\n",
      " [  8.  16.  32.   8.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 14\n",
      "Total Reward: 157\n",
      "Total episodes 171\n",
      "Eps_threshold: 0.9155159965278746\n",
      "Loss ep: 0.044943176514921135\n",
      "Score: 1796\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [ 16. 128.  32.   4.]\n",
      " [  8.   2. 128.   8.]\n",
      " [  2.   4.  16.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 15\n",
      "Total Reward: 90\n",
      "Total episodes 104\n",
      "Eps_threshold: 0.910819534729295\n",
      "Loss ep: 0.04214364290237427\n",
      "Score: 856\n",
      "Highest: 64.0\n",
      "[[ 2. 32.  8.  4.]\n",
      " [ 4. 64. 16.  8.]\n",
      " [ 8.  4. 64.  4.]\n",
      " [ 2.  8.  4.  2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 16\n",
      "Total Reward: 127\n",
      "Total episodes 141\n",
      "Eps_threshold: 0.9044910909852525\n",
      "Loss ep: 0.041946140586907134\n",
      "Score: 1360\n",
      "Highest: 128.0\n",
      "[[  2.  16.   8.   2.]\n",
      " [  4.  64.  32.   4.]\n",
      " [ 16. 128.   2.   8.]\n",
      " [  2.   8.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 17\n",
      "Total Reward: 117\n",
      "Total episodes 131\n",
      "Eps_threshold: 0.8986513204661305\n",
      "Loss ep: 0.03975496219314692\n",
      "Score: 1280\n",
      "Highest: 128.0\n",
      "[[  2.   4.  16.   2.]\n",
      " [  8.   2. 128.   4.]\n",
      " [ 64.  32.   4.   8.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 18\n",
      "Total Reward: 79\n",
      "Total episodes 93\n",
      "Eps_threshold: 0.8945286843833278\n",
      "Loss ep: 0.03940105950960549\n",
      "Score: 688\n",
      "Highest: 64.0\n",
      "[[ 4.  8.  2.  8.]\n",
      " [ 8. 32. 16.  2.]\n",
      " [32.  4. 64.  8.]\n",
      " [ 2.  8.  2.  4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 19\n",
      "Total Reward: 101\n",
      "Total episodes 115\n",
      "Eps_threshold: 0.8894572388269796\n",
      "Loss ep: 0.03877915092136549\n",
      "Score: 1076\n",
      "Highest: 128.0\n",
      "[[  4.   8.   4.   2.]\n",
      " [  8.   4.  32.   4.]\n",
      " [  2. 128.   8.  32.]\n",
      " [  4.   8.   2.   8.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 20\n",
      "Total Reward: 145\n",
      "Total episodes 159\n",
      "Eps_threshold: 0.8824932722238553\n",
      "Loss ep: 0.03866567551714819\n",
      "Score: 1496\n",
      "Highest: 128.0\n",
      "[[  8.   2.  16.   4.]\n",
      " [  2.  32.  64.   2.]\n",
      " [ 16. 128.  16.   8.]\n",
      " [  4.  32.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 21\n",
      "Total Reward: 101\n",
      "Total episodes 115\n",
      "Eps_threshold: 0.8774908317078101\n",
      "Loss ep: 0.0373706983483356\n",
      "Score: 1044\n",
      "Highest: 128.0\n",
      "[[  4.   8.   4.   2.]\n",
      " [ 16.  32.   8.  16.]\n",
      " [  4.   2. 128.   8.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 22\n",
      "Total Reward: 158\n",
      "Total episodes 172\n",
      "Eps_threshold: 0.8700623986013337\n",
      "Loss ep: 0.03575885018637014\n",
      "Score: 1908\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  4. 128.  16.   4.]\n",
      " [ 16.  64.   8.   2.]\n",
      " [  2. 128.   2.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 23\n",
      "Total Reward: 188\n",
      "Total episodes 202\n",
      "Eps_threshold: 0.8614194885430674\n",
      "Loss ep: 0.035262723960498774\n",
      "Score: 2400\n",
      "Highest: 256.0\n",
      "[[  4.  32.   8.   2.]\n",
      " [  2.  16.  64.   4.]\n",
      " [  4.   8. 256.   8.]\n",
      " [  2.   4.  32.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 24\n",
      "Total Reward: 108\n",
      "Total episodes 122\n",
      "Eps_threshold: 0.8562416381622573\n",
      "Loss ep: 0.033799933605506774\n",
      "Score: 1148\n",
      "Highest: 128.0\n",
      "[[  4.  16.   2.   4.]\n",
      " [  2.  32.  16.   2.]\n",
      " [ 16. 128.   4.  32.]\n",
      " [  2.   8.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 25\n",
      "Total Reward: 79\n",
      "Total episodes 93\n",
      "Eps_threshold: 0.8523157493103419\n",
      "Loss ep: 0.032131446305141656\n",
      "Score: 700\n",
      "Highest: 64.0\n",
      "[[ 2.  4.  8.  2.]\n",
      " [ 4. 16. 64. 32.]\n",
      " [ 8. 32.  4.  2.]\n",
      " [16.  4.  2.  8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 26\n",
      "Total Reward: 130\n",
      "Total episodes 144\n",
      "Eps_threshold: 0.8462728564349336\n",
      "Loss ep: 0.03238250811894735\n",
      "Score: 1368\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  4.  64.  16.   4.]\n",
      " [  8.  32. 128.  16.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 27\n",
      "Total Reward: 138\n",
      "Total episodes 152\n",
      "Eps_threshold: 0.8399412732182427\n",
      "Loss ep: 0.03227729860105013\n",
      "Score: 1564\n",
      "Highest: 128.0\n",
      "[[  2. 128.   4.   8.]\n",
      " [  4.   8.  64.  32.]\n",
      " [ 16.   2.   8.   2.]\n",
      " [  2.   4.  64.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 28\n",
      "Total Reward: 83\n",
      "Total episodes 97\n",
      "Eps_threshold: 0.8359258034285286\n",
      "Loss ep: 0.03184087497671855\n",
      "Score: 716\n",
      "Highest: 64.0\n",
      "[[ 2.  4.  8. 32.]\n",
      " [ 4.  2. 64.  2.]\n",
      " [ 8. 16. 32. 16.]\n",
      " [ 2.  4.  8.  4.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 29\n",
      "Total Reward: 103\n",
      "Total episodes 117\n",
      "Eps_threshold: 0.8311082425830183\n",
      "Loss ep: 0.03110084166893592\n",
      "Score: 940\n",
      "Highest: 64.0\n",
      "[[ 2. 16.  4.  2.]\n",
      " [ 4. 64.  8. 32.]\n",
      " [16.  8. 64.  4.]\n",
      " [ 2.  4. 16.  2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 30\n",
      "Total Reward: 68\n",
      "Total episodes 82\n",
      "Eps_threshold: 0.8277485907809331\n",
      "Loss ep: 0.03015968276233208\n",
      "Score: 636\n",
      "Highest: 64.0\n",
      "[[ 4. 32.  4.  2.]\n",
      " [ 8. 64.  2.  4.]\n",
      " [ 4.  8. 16. 32.]\n",
      " [ 2.  4.  8.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 31\n",
      "Total Reward: 158\n",
      "Total episodes 172\n",
      "Eps_threshold: 0.8207461067401824\n",
      "Loss ep: 0.03041832391605821\n",
      "Score: 2040\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  8.  32.   4.  16.]\n",
      " [  4.   8. 256.   8.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 32\n",
      "Total Reward: 129\n",
      "Total episodes 143\n",
      "Eps_threshold: 0.8149699464576254\n",
      "Loss ep: 0.02930493454833131\n",
      "Score: 1364\n",
      "Highest: 128.0\n",
      "[[  2.   8.  16.   2.]\n",
      " [  4.  64.   4.  16.]\n",
      " [ 16. 128.  32.   4.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 33\n",
      "Total Reward: 136\n",
      "Total episodes 150\n",
      "Eps_threshold: 0.808955255145453\n",
      "Loss ep: 0.029599297841389975\n",
      "Score: 1536\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  4.  64. 128.   8.]\n",
      " [  8.  32.   4.   2.]\n",
      " [  2.  64.   2.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 34\n",
      "Total Reward: 84\n",
      "Total episodes 98\n",
      "Eps_threshold: 0.8050499502062026\n",
      "Loss ep: 0.02822121308774364\n",
      "Score: 736\n",
      "Highest: 64.0\n",
      "[[ 4.  8.  4. 16.]\n",
      " [16.  4. 32.  2.]\n",
      " [ 4.  8. 64.  4.]\n",
      " [ 2. 16. 32.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 35\n",
      "Total Reward: 163\n",
      "Total episodes 177\n",
      "Eps_threshold: 0.7980448016509042\n",
      "Loss ep: 0.028466653015653966\n",
      "Score: 1740\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  4.  64.   8.   4.]\n",
      " [ 32. 128.  32.  64.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 36\n",
      "Total Reward: 108\n",
      "Total episodes 122\n",
      "Eps_threshold: 0.7932523601679099\n",
      "Loss ep: 0.027383401745655497\n",
      "Score: 1212\n",
      "Highest: 128.0\n",
      "[[  8.   4.   8.   4.]\n",
      " [ 16. 128.  16.   2.]\n",
      " [  2.  64.   2.   4.]\n",
      " [ 16.   2.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 37\n",
      "Total Reward: 119\n",
      "Total episodes 133\n",
      "Eps_threshold: 0.7880610123355202\n",
      "Loss ep: 0.028306378457779276\n",
      "Score: 1304\n",
      "Highest: 128.0\n",
      "[[  2.   8.  32.   4.]\n",
      " [  4.  64.   4.   2.]\n",
      " [ 16.   2.  16. 128.]\n",
      " [  4.   8.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 38\n",
      "Total Reward: 243\n",
      "Total episodes 257\n",
      "Eps_threshold: 0.7781268917469828\n",
      "Loss ep: 0.026923994145968546\n",
      "Score: 3108\n",
      "Highest: 256.0\n",
      "[[  8.  16.   4.   2.]\n",
      " [  4. 128.   8. 256.]\n",
      " [ 32.   2.  16.   2.]\n",
      " [  2.   8.  64.  16.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 39\n",
      "Total Reward: 174\n",
      "Total episodes 188\n",
      "Eps_threshold: 0.7709403287277328\n",
      "Loss ep: 0.027158706746202833\n",
      "Score: 2232\n",
      "Highest: 256.0\n",
      "[[  8.   2.   4.   2.]\n",
      " [  2.  32.  16.   4.]\n",
      " [ 16. 256.   2.  32.]\n",
      " [  2.   8.  32.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 40\n",
      "Total Reward: 100\n",
      "Total episodes 114\n",
      "Eps_threshold: 0.7666153068762518\n",
      "Loss ep: 0.026249776806747706\n",
      "Score: 1068\n",
      "Highest: 128.0\n",
      "[[  2.  16.   2.   4.]\n",
      " [  4.  32.   4.   8.]\n",
      " [  2.  16. 128.  16.]\n",
      " [ 16.   2.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 41\n",
      "Total Reward: 212\n",
      "Total episodes 226\n",
      "Eps_threshold: 0.7581136785726826\n",
      "Loss ep: 0.026303335628678315\n",
      "Score: 2676\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.  64.]\n",
      " [ 32.   8. 256.   4.]\n",
      " [  8.   2.  32.   8.]\n",
      " [  2.   4.  64.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 42\n",
      "Total Reward: 119\n",
      "Total episodes 133\n",
      "Eps_threshold: 0.7531552277321301\n",
      "Loss ep: 0.025975463981915237\n",
      "Score: 1320\n",
      "Highest: 128.0\n",
      "[[  4.   2.   8.   2.]\n",
      " [  2.  16.   2.  32.]\n",
      " [ 16.  64.  16.   4.]\n",
      " [  2.   4. 128.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 43\n",
      "Total Reward: 50\n",
      "Total episodes 64\n",
      "Eps_threshold: 0.7507809319027795\n",
      "Loss ep: 0.024618610739707947\n",
      "Score: 364\n",
      "Highest: 32.0\n",
      "[[ 2.  4. 32.  8.]\n",
      " [ 8. 16.  2. 16.]\n",
      " [ 2.  8. 16.  8.]\n",
      " [ 4. 16.  4.  2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 44\n",
      "Total Reward: 113\n",
      "Total episodes 127\n",
      "Eps_threshold: 0.7460918764923177\n",
      "Loss ep: 0.02539849281311035\n",
      "Score: 1236\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [ 16. 128.  32.   8.]\n",
      " [  4.  32.   2.  32.]\n",
      " [  2.  16.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 45\n",
      "Total Reward: 217\n",
      "Total episodes 231\n",
      "Eps_threshold: 0.7376389250834131\n",
      "Loss ep: 0.02504760775215182\n",
      "Score: 2856\n",
      "Highest: 256.0\n",
      "[[  2.   4.  32.   2.]\n",
      " [ 32. 256.   8.   4.]\n",
      " [  8.   4. 128.   8.]\n",
      " [ 16.   2.  16.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 46\n",
      "Total Reward: 118\n",
      "Total episodes 132\n",
      "Eps_threshold: 0.7328523213455564\n",
      "Loss ep: 0.024814096364107998\n",
      "Score: 1284\n",
      "Highest: 128.0\n",
      "[[  2. 128.   8.   4.]\n",
      " [  4.  32.  16.   8.]\n",
      " [  2.   8.  64.   4.]\n",
      " [  4.   2.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 47\n",
      "Total Reward: 129\n",
      "Total episodes 143\n",
      "Eps_threshold: 0.7277023602985669\n",
      "Loss ep: 0.024850485208151224\n",
      "Score: 1400\n",
      "Highest: 128.0\n",
      "[[  2.  32.   4.   8.]\n",
      " [  8.  16.   8.   4.]\n",
      " [  4.  32.  64. 128.]\n",
      " [  2.   8.   2.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 48\n",
      "Total Reward: 67\n",
      "Total episodes 81\n",
      "Eps_threshold: 0.7248015438577029\n",
      "Loss ep: 0.02398171248259368\n",
      "Score: 604\n",
      "Highest: 64.0\n",
      "[[ 2.  4. 16.  4.]\n",
      " [16.  8. 32.  8.]\n",
      " [ 4. 64. 16.  2.]\n",
      " [ 2.  4.  8.  4.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 49\n",
      "Total Reward: 118\n",
      "Total episodes 132\n",
      "Eps_threshold: 0.7200993878518751\n",
      "Loss ep: 0.02446952010646011\n",
      "Score: 1284\n",
      "Highest: 128.0\n",
      "[[  2.   4. 128.   2.]\n",
      " [  4.  64.   2.   8.]\n",
      " [  8.  32.  16.   2.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 50\n",
      "Total Reward: 117\n",
      "Total episodes 131\n",
      "Eps_threshold: 0.7154634361776596\n",
      "Loss ep: 0.0240519956778024\n",
      "Score: 1284\n",
      "Highest: 128.0\n",
      "[[  4.   2.   8.   2.]\n",
      " [  8.  16.  64.   8.]\n",
      " [  4.   2.   8.  32.]\n",
      " [  2.   4. 128.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 51\n",
      "Total Reward: 113\n",
      "Total episodes 127\n",
      "Eps_threshold: 0.7109979363249636\n",
      "Loss ep: 0.02431234036843608\n",
      "Score: 1232\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [ 16. 128.   8.  16.]\n",
      " [  2.   4.  64.   4.]\n",
      " [  4.   8.  16.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 52\n",
      "Total Reward: 210\n",
      "Total episodes 224\n",
      "Eps_threshold: 0.703190562345322\n",
      "Loss ep: 0.02383894579751151\n",
      "Score: 2756\n",
      "Highest: 256.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [  4.  16.   4.  16.]\n",
      " [  2. 256. 128.   8.]\n",
      " [  8.   2.  32.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 128\n",
      "---------------------------\n",
      "Episode: 53\n",
      "Total Reward: 83\n",
      "Total episodes 97\n",
      "Eps_threshold: 0.6998367277410744\n",
      "Loss ep: 0.023714512893834066\n",
      "Score: 924\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   8.]\n",
      " [  4.  16.   8. 128.]\n",
      " [ 16.   2.  16.   2.]\n",
      " [  4.   8.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 54\n",
      "Total Reward: 63\n",
      "Total episodes 77\n",
      "Eps_threshold: 0.697185962336921\n",
      "Loss ep: 0.023368148060588092\n",
      "Score: 568\n",
      "Highest: 64.0\n",
      "[[ 2.  4.  2.  8.]\n",
      " [32.  2. 16.  4.]\n",
      " [ 4. 16. 64.  2.]\n",
      " [ 2.  8.  2.  8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 55\n",
      "Total Reward: 126\n",
      "Total episodes 140\n",
      "Eps_threshold: 0.6923924574411601\n",
      "Loss ep: 0.02312466757638114\n",
      "Score: 1348\n",
      "Highest: 128.0\n",
      "[[128.   2.   4.   2.]\n",
      " [  2.  16.   2.   4.]\n",
      " [ 16.   8.  16.   2.]\n",
      " [  4.  64.  32.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 56\n",
      "Total Reward: 106\n",
      "Total episodes 120\n",
      "Eps_threshold: 0.6883103612314236\n",
      "Loss ep: 0.022976698478062947\n",
      "Score: 1128\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  8.  32.   8.  16.]\n",
      " [  4. 128.  16.   2.]\n",
      " [  2.   4.  32.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 57\n",
      "Total Reward: 148\n",
      "Total episodes 162\n",
      "Eps_threshold: 0.6828382393179923\n",
      "Loss ep: 0.023254044261979467\n",
      "Score: 1660\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [ 32.  64.  32.  16.]\n",
      " [  4. 128.  64.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 58\n",
      "Total Reward: 102\n",
      "Total episodes 116\n",
      "Eps_threshold: 0.6789470728210197\n",
      "Loss ep: 0.022539909543662237\n",
      "Score: 1088\n",
      "Highest: 128.0\n",
      "[[  4.   8.   4.   2.]\n",
      " [ 32. 128.  32.   4.]\n",
      " [  4.  16.   4.   8.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 59\n",
      "Total Reward: 83\n",
      "Total episodes 97\n",
      "Eps_threshold: 0.6757105344676317\n",
      "Loss ep: 0.02243630910657116\n",
      "Score: 736\n",
      "Highest: 64.0\n",
      "[[ 2. 16.  4.  8.]\n",
      " [ 4. 32. 64. 32.]\n",
      " [16.  8. 16.  4.]\n",
      " [ 2.  4.  8.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 60\n",
      "Total Reward: 72\n",
      "Total episodes 86\n",
      "Eps_threshold: 0.6728541248513458\n",
      "Loss ep: 0.02288115994874821\n",
      "Score: 620\n",
      "Highest: 64.0\n",
      "[[ 2. 16.  4.  2.]\n",
      " [ 4. 32.  8. 16.]\n",
      " [64.  4. 16.  4.]\n",
      " [ 2.  8.  4.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 61\n",
      "Total Reward: 74\n",
      "Total episodes 88\n",
      "Eps_threshold: 0.6699439737295102\n",
      "Loss ep: 0.02311905405738137\n",
      "Score: 676\n",
      "Highest: 64.0\n",
      "[[ 2. 32.  4.  2.]\n",
      " [ 4.  2. 64. 16.]\n",
      " [ 2.  8. 32.  8.]\n",
      " [ 4. 16.  2.  4.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 62\n",
      "Total Reward: 138\n",
      "Total episodes 152\n",
      "Eps_threshold: 0.6649474105194652\n",
      "Loss ep: 0.022224765074880498\n",
      "Score: 1452\n",
      "Highest: 128.0\n",
      "[[  2.  32.   4.   2.]\n",
      " [  8.  16.  32.   4.]\n",
      " [ 16.   8. 128.  64.]\n",
      " [  8.   4.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 63\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.6601186879900304\n",
      "Loss ep: 0.022180140018463135\n",
      "Score: 1388\n",
      "Highest: 128.0\n",
      "[[  2.  32.   8.   4.]\n",
      " [  4.  16.  64.  16.]\n",
      " [128.   4.   8.   2.]\n",
      " [  8.   2.   4.  16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 64\n",
      "Total Reward: 120\n",
      "Total episodes 134\n",
      "Eps_threshold: 0.6557774521603542\n",
      "Loss ep: 0.022183944929891557\n",
      "Score: 1248\n",
      "Highest: 128.0\n",
      "[[  4.   2.   8.   2.]\n",
      " [  8.   4.  16.   4.]\n",
      " [  4.   8. 128.  16.]\n",
      " [  2.   4.  64.   8.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 65\n",
      "Total Reward: 61\n",
      "Total episodes 75\n",
      "Eps_threshold: 0.6533603216670021\n",
      "Loss ep: 0.02252867380777995\n",
      "Score: 456\n",
      "Highest: 32.0\n",
      "[[ 2. 16.  2.  4.]\n",
      " [ 8. 32.  4.  8.]\n",
      " [32.  8. 16.  4.]\n",
      " [ 2. 16.  8.  2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 66\n",
      "Total Reward: 94\n",
      "Total episodes 108\n",
      "Eps_threshold: 0.6498955392619111\n",
      "Loss ep: 0.021074749805309153\n",
      "Score: 888\n",
      "Highest: 64.0\n",
      "[[ 2. 16. 64.  8.]\n",
      " [ 4.  2.  8.  2.]\n",
      " [ 8. 16. 64. 32.]\n",
      " [ 4.  2.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 67\n",
      "Total Reward: 119\n",
      "Total episodes 133\n",
      "Eps_threshold: 0.6456543515047609\n",
      "Loss ep: 0.021945598430203318\n",
      "Score: 1264\n",
      "Highest: 128.0\n",
      "[[  8.   2.  16.   4.]\n",
      " [128.  16.   4.   2.]\n",
      " [  8.  64.  16.   8.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 68\n",
      "Total Reward: 173\n",
      "Total episodes 187\n",
      "Eps_threshold: 0.639738682169156\n",
      "Loss ep: 0.021699477007044828\n",
      "Score: 2268\n",
      "Highest: 256.0\n",
      "[[  4.   2.   8.   2.]\n",
      " [  2.   8.  64.   4.]\n",
      " [ 32. 256.   4.   2.]\n",
      " [  4.  16.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 69\n",
      "Total Reward: 84\n",
      "Total episodes 98\n",
      "Eps_threshold: 0.6366605103064971\n",
      "Loss ep: 0.020977438712606624\n",
      "Score: 712\n",
      "Highest: 64.0\n",
      "[[ 2. 16.  8.  2.]\n",
      " [16.  8. 16.  4.]\n",
      " [ 4. 64. 32. 16.]\n",
      " [ 2. 16.  8.  2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 70\n",
      "Total Reward: 89\n",
      "Total episodes 103\n",
      "Eps_threshold: 0.6334415047324417\n",
      "Loss ep: 0.02139809525128707\n",
      "Score: 792\n",
      "Highest: 64.0\n",
      "[[ 2. 32.  8.  2.]\n",
      " [ 4. 64. 32.  8.]\n",
      " [ 8. 32.  8. 16.]\n",
      " [ 2.  4.  2.  4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 71\n",
      "Total Reward: 97\n",
      "Total episodes 111\n",
      "Eps_threshold: 0.6299909884209803\n",
      "Loss ep: 0.021547854483664572\n",
      "Score: 900\n",
      "Highest: 64.0\n",
      "[[ 2. 16.  4.  2.]\n",
      " [ 8.  2.  8.  4.]\n",
      " [64.  8. 32. 16.]\n",
      " [ 2.  4. 64.  4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 72\n",
      "Total Reward: 132\n",
      "Total episodes 146\n",
      "Eps_threshold: 0.6254815337408087\n",
      "Loss ep: 0.021142995520813824\n",
      "Score: 1412\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [ 32.  16.  32.   8.]\n",
      " [  4. 128.   8.   4.]\n",
      " [  2.   8.  64.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 73\n",
      "Total Reward: 96\n",
      "Total episodes 110\n",
      "Eps_threshold: 0.6221056774200832\n",
      "Loss ep: 0.020740162242542614\n",
      "Score: 1064\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  4.  32. 128.   4.]\n",
      " [  2.  16.   2.  32.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 74\n",
      "Total Reward: 146\n",
      "Total episodes 160\n",
      "Eps_threshold: 0.6172283672536812\n",
      "Loss ep: 0.02085104286670685\n",
      "Score: 1608\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   8.]\n",
      " [ 16.   2.  64.   2.]\n",
      " [  8.  64. 128.   4.]\n",
      " [  2.  32.  16.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 64\n",
      "---------------------------\n",
      "Episode: 75\n",
      "Total Reward: 127\n",
      "Total episodes 141\n",
      "Eps_threshold: 0.6129624622485166\n",
      "Loss ep: 0.021157645164652072\n",
      "Score: 1356\n",
      "Highest: 128.0\n",
      "[[  4.   8.  16.   2.]\n",
      " [  2.  16.  64.   4.]\n",
      " [  4. 128.   4.   8.]\n",
      " [ 32.   4.   2.  16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 76\n",
      "Total Reward: 116\n",
      "Total episodes 130\n",
      "Eps_threshold: 0.6090559162726105\n",
      "Loss ep: 0.02053183042086088\n",
      "Score: 1276\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [ 32.  16.   2.   4.]\n",
      " [  8.  64. 128.   8.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 77\n",
      "Total Reward: 169\n",
      "Total episodes 183\n",
      "Eps_threshold: 0.6035995555572824\n",
      "Loss ep: 0.020340704527057586\n",
      "Score: 2148\n",
      "Highest: 256.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  4.  32. 256.  32.]\n",
      " [  2.   4.  16.   8.]\n",
      " [  8.   2.   8.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 78\n",
      "Total Reward: 228\n",
      "Total episodes 242\n",
      "Eps_threshold: 0.5964602806531002\n",
      "Loss ep: 0.020451131931021195\n",
      "Score: 2788\n",
      "Highest: 256.0\n",
      "[[  8.   4.  32.   4.]\n",
      " [ 64. 256.  64.  16.]\n",
      " [  2.  32.  16.   4.]\n",
      " [  4.   2.   4.  16.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 79\n",
      "Total Reward: 64\n",
      "Total episodes 78\n",
      "Eps_threshold: 0.5941775397965966\n",
      "Loss ep: 0.0205341684512603\n",
      "Score: 592\n",
      "Highest: 64.0\n",
      "[[ 2. 32.  8.  4.]\n",
      " [ 4. 16.  4.  2.]\n",
      " [ 2. 64. 16.  8.]\n",
      " [ 4. 16.  8.  2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 80\n",
      "Total Reward: 102\n",
      "Total episodes 116\n",
      "Eps_threshold: 0.5907991169628343\n",
      "Loss ep: 0.019906763372750116\n",
      "Score: 1092\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [ 16.  32.   4.   8.]\n",
      " [  2.   4. 128.  32.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 81\n",
      "Total Reward: 190\n",
      "Total episodes 204\n",
      "Eps_threshold: 0.5849050766765143\n",
      "Loss ep: 0.020551896562763287\n",
      "Score: 2364\n",
      "Highest: 256.0\n",
      "[[  2.   4.  16.   2.]\n",
      " [ 16.  64.   8.   4.]\n",
      " [  8. 256.  32.   8.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 82\n",
      "Total Reward: 61\n",
      "Total episodes 75\n",
      "Eps_threshold: 0.5827532198921546\n",
      "Loss ep: 0.019303897221883137\n",
      "Score: 544\n",
      "Highest: 64.0\n",
      "[[ 2.  8.  4.  2.]\n",
      " [64.  2. 16.  4.]\n",
      " [ 2.  8. 32.  8.]\n",
      " [ 8.  2.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 83\n",
      "Total Reward: 131\n",
      "Total episodes 145\n",
      "Eps_threshold: 0.5786157754070479\n",
      "Loss ep: 0.020288903137733197\n",
      "Score: 1424\n",
      "Highest: 128.0\n",
      "[[  8. 128.  32.   2.]\n",
      " [  4.  32.   8.   4.]\n",
      " [  8.   4.  64.  16.]\n",
      " [  4.  16.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 84\n",
      "Total Reward: 104\n",
      "Total episodes 118\n",
      "Eps_threshold: 0.5752708196547691\n",
      "Loss ep: 0.0205695810964552\n",
      "Score: 1072\n",
      "Highest: 128.0\n",
      "[[  4.  16.   8.   2.]\n",
      " [ 16.   4.  16.   4.]\n",
      " [  4. 128.  32.   8.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 85\n",
      "Total Reward: 123\n",
      "Total episodes 137\n",
      "Eps_threshold: 0.5714119462704623\n",
      "Loss ep: 0.019803184662422126\n",
      "Score: 1324\n",
      "Highest: 128.0\n",
      "[[  4.   8.  16.   2.]\n",
      " [  2.   4.  64.   8.]\n",
      " [  4.  32. 128.  16.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 86\n",
      "Total Reward: 228\n",
      "Total episodes 242\n",
      "Eps_threshold: 0.5646597946197524\n",
      "Loss ep: 0.019948486454230696\n",
      "Score: 2904\n",
      "Highest: 256.0\n",
      "[[  2.  16.   8.   2.]\n",
      " [  8. 256.  32.   8.]\n",
      " [ 16.   4. 128.   4.]\n",
      " [  4.   8.  32.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 87\n",
      "Total Reward: 139\n",
      "Total episodes 153\n",
      "Eps_threshold: 0.5604328359222582\n",
      "Loss ep: 0.01906510583715501\n",
      "Score: 1452\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [ 16.  32.  64.   4.]\n",
      " [  4. 128.  16.   8.]\n",
      " [  2.   4.  32.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 88\n",
      "Total Reward: 45\n",
      "Total episodes 59\n",
      "Eps_threshold: 0.5588114517737478\n",
      "Loss ep: 0.019083025091785496\n",
      "Score: 324\n",
      "Highest: 32.0\n",
      "[[ 4.  8.  2. 16.]\n",
      " [ 2. 16.  4.  2.]\n",
      " [ 8.  2. 32.  8.]\n",
      " [ 2.  8. 16.  2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 89\n",
      "Total Reward: 158\n",
      "Total episodes 172\n",
      "Eps_threshold: 0.5541119102817142\n",
      "Loss ep: 0.019221239311750547\n",
      "Score: 1888\n",
      "Highest: 128.0\n",
      "[[  2.   4. 128.   4.]\n",
      " [  4.  64.   4.  16.]\n",
      " [  2.   8. 128.   4.]\n",
      " [  4.   2.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 90\n",
      "Total Reward: 229\n",
      "Total episodes 243\n",
      "Eps_threshold: 0.547540949990494\n",
      "Loss ep: 0.019590534791043758\n",
      "Score: 3028\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [ 16. 256. 128.   4.]\n",
      " [  2.  64.  16.   2.]\n",
      " [  8.  32.   2.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 91\n",
      "Total Reward: 38\n",
      "Total episodes 52\n",
      "Eps_threshold: 0.5461451588353159\n",
      "Loss ep: 0.01936954030623803\n",
      "Score: 280\n",
      "Highest: 32.0\n",
      "[[ 4. 16.  8.  2.]\n",
      " [ 2.  8.  2.  4.]\n",
      " [ 8. 16. 32.  8.]\n",
      " [ 4.  8.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 92\n",
      "Total Reward: 129\n",
      "Total episodes 143\n",
      "Eps_threshold: 0.5423253928858974\n",
      "Loss ep: 0.019129002844537054\n",
      "Score: 1364\n",
      "Highest: 128.0\n",
      "[[  4.  16.   4.   2.]\n",
      " [ 16.  64.   8.  32.]\n",
      " [  4. 128.   2.   8.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 93\n",
      "Total Reward: 101\n",
      "Total episodes 115\n",
      "Eps_threshold: 0.539273305038498\n",
      "Loss ep: 0.019254690667857295\n",
      "Score: 1048\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  4.   8.   2.   8.]\n",
      " [  8.  32.  16. 128.]\n",
      " [ 16.   4.   8.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 94\n",
      "Total Reward: 118\n",
      "Total episodes 132\n",
      "Eps_threshold: 0.5357916034789579\n",
      "Loss ep: 0.019271677190607243\n",
      "Score: 1304\n",
      "Highest: 128.0\n",
      "[[  2.   4.  16.   2.]\n",
      " [  4.   8.  32.   4.]\n",
      " [128.   4.  64.   8.]\n",
      " [  4.   8.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 95\n",
      "Total Reward: 79\n",
      "Total episodes 93\n",
      "Eps_threshold: 0.5333523481865671\n",
      "Loss ep: 0.01880383619698145\n",
      "Score: 700\n",
      "Highest: 64.0\n",
      "[[ 2.  4. 16.  2.]\n",
      " [ 4. 32.  8. 16.]\n",
      " [ 8.  4. 64.  8.]\n",
      " [ 2. 32.  4.  2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 96\n",
      "Total Reward: 182\n",
      "Total episodes 196\n",
      "Eps_threshold: 0.5282485446589994\n",
      "Loss ep: 0.01918236576780981\n",
      "Score: 2084\n",
      "Highest: 128.0\n",
      "[[  8.   2.   8.   2.]\n",
      " [ 16.   8. 128.  16.]\n",
      " [  4.  32.  64. 128.]\n",
      " [  2.   8.   4.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 97\n",
      "Total Reward: 137\n",
      "Total episodes 151\n",
      "Eps_threshold: 0.5243505017752084\n",
      "Loss ep: 0.019380580510524725\n",
      "Score: 1444\n",
      "Highest: 128.0\n",
      "[[  4.   8.   4.   2.]\n",
      " [  2.  32. 128.  16.]\n",
      " [  8.  64.  32.   4.]\n",
      " [  4.  16.   4.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 98\n",
      "Total Reward: 77\n",
      "Total episodes 91\n",
      "Eps_threshold: 0.5220155230969477\n",
      "Loss ep: 0.018551172790946542\n",
      "Score: 692\n",
      "Highest: 64.0\n",
      "[[ 2.  4. 32.  8.]\n",
      " [ 8. 16. 64.  2.]\n",
      " [ 4. 32.  2.  8.]\n",
      " [ 2. 16.  4.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 99\n",
      "Total Reward: 112\n",
      "Total episodes 126\n",
      "Eps_threshold: 0.5187999649450667\n",
      "Loss ep: 0.018229844078185068\n",
      "Score: 1260\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [ 16.  32. 128.   4.]\n",
      " [  4.  64.   2.   8.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 100\n",
      "Total Reward: 76\n",
      "Total episodes 90\n",
      "Eps_threshold: 0.5165155089837451\n",
      "Loss ep: 0.018981402450137668\n",
      "Score: 688\n",
      "Highest: 64.0\n",
      "[[ 2.  4. 32.  2.]\n",
      " [ 8. 16.  4.  8.]\n",
      " [32. 64.  8.  4.]\n",
      " [16.  2.  4.  2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Update target_net\n",
      "Episode: 101\n",
      "Total Reward: 128\n",
      "Total episodes 142\n",
      "Eps_threshold: 0.5129319854323405\n",
      "Loss ep: 0.08868817880120076\n",
      "Score: 1348\n",
      "Highest: 128.0\n",
      "[[  2.   8.   2.   8.]\n",
      " [  4.  64.  16.   2.]\n",
      " [ 16.   4. 128.   8.]\n",
      " [  2.   8.  32.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 102\n",
      "Total Reward: 131\n",
      "Total episodes 145\n",
      "Eps_threshold: 0.5092989143342809\n",
      "Loss ep: 0.07375160743450296\n",
      "Score: 1476\n",
      "Highest: 128.0\n",
      "[[  2.   4.  16.   2.]\n",
      " [  4. 128.   2.   4.]\n",
      " [  2.  64.   8.  16.]\n",
      " [  4.   2.  64.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 103\n",
      "Total Reward: 77\n",
      "Total episodes 91\n",
      "Eps_threshold: 0.507032264812164\n",
      "Loss ep: 0.06947870568914728\n",
      "Score: 648\n",
      "Highest: 64.0\n",
      "[[ 2.  4. 32.  8.]\n",
      " [ 8. 16.  8. 16.]\n",
      " [ 4. 64. 16.  4.]\n",
      " [ 2.  8.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 104\n",
      "Total Reward: 119\n",
      "Total episodes 133\n",
      "Eps_threshold: 0.503737965935098\n",
      "Loss ep: 0.06762633646341194\n",
      "Score: 1324\n",
      "Highest: 128.0\n",
      "[[  4.  16.   4.   2.]\n",
      " [ 16.   8. 128.  32.]\n",
      " [  4.  64.  16.   4.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 105\n",
      "Total Reward: 127\n",
      "Total episodes 141\n",
      "Eps_threshold: 0.5002693544971176\n",
      "Loss ep: 0.06722200001385195\n",
      "Score: 1464\n",
      "Highest: 128.0\n",
      "[[ 16.   2.   4.   2.]\n",
      " [  8.  64.  16.   4.]\n",
      " [  4. 128.   2.   8.]\n",
      " [  2.  64.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 106\n",
      "Total Reward: 165\n",
      "Total episodes 179\n",
      "Eps_threshold: 0.49590102122525576\n",
      "Loss ep: 0.061363752993791466\n",
      "Score: 2132\n",
      "Highest: 256.0\n",
      "[[  2.  32.  16.   8.]\n",
      " [  4. 256.   8.   4.]\n",
      " [ 16.  32.   4.   2.]\n",
      " [  2.   8.   2.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 107\n",
      "Total Reward: 220\n",
      "Total episodes 234\n",
      "Eps_threshold: 0.4902491074465848\n",
      "Loss ep: 0.06209617190890842\n",
      "Score: 2860\n",
      "Highest: 256.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [ 32.   2.   4.  16.]\n",
      " [  2. 256.  32.   4.]\n",
      " [ 16. 128.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 108\n",
      "Total Reward: 182\n",
      "Total episodes 196\n",
      "Eps_threshold: 0.4855656526055197\n",
      "Loss ep: 0.05871995127930933\n",
      "Score: 2288\n",
      "Highest: 256.0\n",
      "[[  2.  16.   2.   8.]\n",
      " [  8.   4. 256.  16.]\n",
      " [  4.   8.  64.   8.]\n",
      " [  8.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 109\n",
      "Total Reward: 202\n",
      "Total episodes 216\n",
      "Eps_threshold: 0.480457178969283\n",
      "Loss ep: 0.056209820288198965\n",
      "Score: 2524\n",
      "Highest: 256.0\n",
      "[[  4. 256.   2.   8.]\n",
      " [ 64.   8.  32.   2.]\n",
      " [ 16.  32.   8.  32.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 110\n",
      "Total Reward: 193\n",
      "Total episodes 207\n",
      "Eps_threshold: 0.47561305873195775\n",
      "Loss ep: 0.055783663394946406\n",
      "Score: 2436\n",
      "Highest: 256.0\n",
      "[[  4.  16.  64.   2.]\n",
      " [ 32. 256.   4.   8.]\n",
      " [  2.   4.  32.   2.]\n",
      " [  4.  16.   4.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 111\n",
      "Total Reward: 146\n",
      "Total episodes 160\n",
      "Eps_threshold: 0.47190301422700476\n",
      "Loss ep: 0.056135493516922\n",
      "Score: 1536\n",
      "Highest: 128.0\n",
      "[[  2.  64.   2.   8.]\n",
      " [ 32.   4.   8.   2.]\n",
      " [  8.  16.  32. 128.]\n",
      " [  2.   4.   8.  32.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 112\n",
      "Total Reward: 77\n",
      "Total episodes 91\n",
      "Eps_threshold: 0.46980612954249085\n",
      "Loss ep: 0.051700864519391744\n",
      "Score: 736\n",
      "Highest: 64.0\n",
      "[[ 4.  2.  8.  2.]\n",
      " [ 2.  8. 64.  4.]\n",
      " [ 4. 16.  8.  2.]\n",
      " [ 2.  8. 64.  4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 113\n",
      "Total Reward: 72\n",
      "Total episodes 86\n",
      "Eps_threshold: 0.4678332080067025\n",
      "Loss ep: 0.0528420182161553\n",
      "Score: 652\n",
      "Highest: 64.0\n",
      "[[ 4. 16.  2.  8.]\n",
      " [ 2. 32. 64.  4.]\n",
      " [ 4.  8.  4.  8.]\n",
      " [ 2.  4. 32.  2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 114\n",
      "Total Reward: 120\n",
      "Total episodes 134\n",
      "Eps_threshold: 0.46477597866791936\n",
      "Loss ep: 0.05108980634319248\n",
      "Score: 1312\n",
      "Highest: 128.0\n",
      "[[  4.  64.   8.   2.]\n",
      " [  2.  16. 128.   4.]\n",
      " [ 32.   4.   8.  16.]\n",
      " [  2.   8.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 115\n",
      "Total Reward: 147\n",
      "Total episodes 161\n",
      "Eps_threshold: 0.46112972788951817\n",
      "Loss ep: 0.05220144283697472\n",
      "Score: 1568\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [ 64.   8. 128.   8.]\n",
      " [  8.  16.   4.  16.]\n",
      " [  2.   4.  64.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 116\n",
      "Total Reward: 73\n",
      "Total episodes 87\n",
      "Eps_threshold: 0.4591715756420973\n",
      "Loss ep: 0.04940247261661223\n",
      "Score: 656\n",
      "Highest: 64.0\n",
      "[[ 2. 16.  8.  4.]\n",
      " [ 8. 32.  4. 32.]\n",
      " [ 4.  2. 64.  4.]\n",
      " [ 2.  8.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 117\n",
      "Total Reward: 122\n",
      "Total episodes 136\n",
      "Eps_threshold: 0.45612757027553563\n",
      "Loss ep: 0.05094692636938656\n",
      "Score: 1320\n",
      "Highest: 128.0\n",
      "[[  4.   2.   4.   2.]\n",
      " [ 16.  32.  64.  16.]\n",
      " [  4.   8. 128.   8.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 118\n",
      "Total Reward: 92\n",
      "Total episodes 106\n",
      "Eps_threshold: 0.4537693489597626\n",
      "Loss ep: 0.04859182519732781\n",
      "Score: 776\n",
      "Highest: 64.0\n",
      "[[ 2.  8. 16.  2.]\n",
      " [ 8. 64.  8.  4.]\n",
      " [16. 32. 16. 32.]\n",
      " [ 4.  8.  4.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 119\n",
      "Total Reward: 127\n",
      "Total episodes 141\n",
      "Eps_threshold: 0.4506517774019187\n",
      "Loss ep: 0.05072498321533203\n",
      "Score: 1344\n",
      "Highest: 128.0\n",
      "[[  4.   8.  16.   2.]\n",
      " [  2.  64.   2.   8.]\n",
      " [  4.   8. 128.   4.]\n",
      " [ 16.   2.   8.  32.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 120\n",
      "Total Reward: 133\n",
      "Total episodes 147\n",
      "Eps_threshold: 0.4474248602855815\n",
      "Loss ep: 0.04997623210050622\n",
      "Score: 1432\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.  32.]\n",
      " [  4.  16. 128.   4.]\n",
      " [  2.   8.  32.  64.]\n",
      " [  8.   4.   8.  16.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 121\n",
      "Total Reward: 228\n",
      "Total episodes 242\n",
      "Eps_threshold: 0.44216391239863373\n",
      "Loss ep: 0.048906566682925895\n",
      "Score: 2824\n",
      "Highest: 256.0\n",
      "[[  2.  16.   2.   4.]\n",
      " [  4.  32.  64.  32.]\n",
      " [  8. 256.  32.   8.]\n",
      " [  2.   8.  64.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 122\n",
      "Total Reward: 110\n",
      "Total episodes 124\n",
      "Eps_threshold: 0.4394927851926062\n",
      "Loss ep: 0.05000291716667914\n",
      "Score: 1188\n",
      "Highest: 128.0\n",
      "[[  2.  32.   4.   2.]\n",
      " [  8.   2.  16.  32.]\n",
      " [  2.   8.   4.   2.]\n",
      " [  4. 128.   2.  32.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 123\n",
      "Total Reward: 135\n",
      "Total episodes 149\n",
      "Eps_threshold: 0.4363049533608673\n",
      "Loss ep: 0.04893560537555874\n",
      "Score: 1496\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [  8.  64.   8.   2.]\n",
      " [ 16.   4.  16.  64.]\n",
      " [  4. 128.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 124\n",
      "Total Reward: 61\n",
      "Total episodes 75\n",
      "Eps_threshold: 0.43470930349915643\n",
      "Loss ep: 0.04653848012288411\n",
      "Score: 456\n",
      "Highest: 32.0\n",
      "[[ 2. 16.  2.  8.]\n",
      " [ 4.  8. 32.  2.]\n",
      " [ 8. 32. 16.  8.]\n",
      " [ 2. 16.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 125\n",
      "Total Reward: 136\n",
      "Total episodes 150\n",
      "Eps_threshold: 0.4315358988656089\n",
      "Loss ep: 0.04687396685282389\n",
      "Score: 1444\n",
      "Highest: 128.0\n",
      "[[  4.  16.   8.   2.]\n",
      " [ 16.  64.  32.   4.]\n",
      " [  8. 128.   4.   8.]\n",
      " [  2.   4.  32.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 126\n",
      "Total Reward: 90\n",
      "Total episodes 104\n",
      "Eps_threshold: 0.4293496014911359\n",
      "Loss ep: 0.04507907078816341\n",
      "Score: 868\n",
      "Highest: 64.0\n",
      "[[ 2. 64.  2.  4.]\n",
      " [ 4.  8. 32.  2.]\n",
      " [16. 64. 16.  8.]\n",
      " [ 4.  2.  4.  2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 127\n",
      "Total Reward: 224\n",
      "Total episodes 238\n",
      "Eps_threshold: 0.42438891585302435\n",
      "Loss ep: 0.0476338562845182\n",
      "Score: 2888\n",
      "Highest: 256.0\n",
      "[[  8. 128.  16.  32.]\n",
      " [  2.  16.   8.   2.]\n",
      " [  8.   2. 256.  32.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 128\n",
      "Total Reward: 201\n",
      "Total episodes 215\n",
      "Eps_threshold: 0.41995809334822926\n",
      "Loss ep: 0.045682978075604105\n",
      "Score: 2584\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  8.  16.   4.  32.]\n",
      " [ 64. 256.  64.   4.]\n",
      " [  4.   8.   2.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 129\n",
      "Total Reward: 179\n",
      "Total episodes 193\n",
      "Eps_threshold: 0.4160210246562833\n",
      "Loss ep: 0.045512095634183736\n",
      "Score: 2312\n",
      "Highest: 256.0\n",
      "[[  4.   8.   2.   8.]\n",
      " [256.  64.  16.   2.]\n",
      " [  2.   4.  32.   4.]\n",
      " [  4.   2.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 130\n",
      "Total Reward: 82\n",
      "Total episodes 96\n",
      "Eps_threshold: 0.41407679362532956\n",
      "Loss ep: 0.045196865995725\n",
      "Score: 744\n",
      "Highest: 64.0\n",
      "[[32.  2.  8.  2.]\n",
      " [ 2.  8. 64.  8.]\n",
      " [ 8.  2. 32.  4.]\n",
      " [ 2. 32.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 131\n",
      "Total Reward: 139\n",
      "Total episodes 153\n",
      "Eps_threshold: 0.41099739985307854\n",
      "Loss ep: 0.0466617696425494\n",
      "Score: 1512\n",
      "Highest: 128.0\n",
      "[[  2.   4.  16.   4.]\n",
      " [  4. 128.   4.   8.]\n",
      " [ 64.   4.  64.   4.]\n",
      " [  2.   8.  16.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 132\n",
      "Total Reward: 114\n",
      "Total episodes 128\n",
      "Eps_threshold: 0.40843921142892003\n",
      "Loss ep: 0.04584650322794914\n",
      "Score: 1236\n",
      "Highest: 128.0\n",
      "[[  4.   2.  16.   2.]\n",
      " [  2.   4.  64.   4.]\n",
      " [  8.  16. 128.  16.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 133\n",
      "Total Reward: 185\n",
      "Total episodes 199\n",
      "Eps_threshold: 0.4044943992612052\n",
      "Loss ep: 0.04480523919340354\n",
      "Score: 2364\n",
      "Highest: 256.0\n",
      "[[  2.   8.  16.   2.]\n",
      " [ 16.  64.   8.  32.]\n",
      " [  4.   8. 256.   2.]\n",
      " [  2.   4.   8.  16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 134\n",
      "Total Reward: 205\n",
      "Total episodes 219\n",
      "Eps_threshold: 0.40019824993336617\n",
      "Loss ep: 0.0444976075054848\n",
      "Score: 2540\n",
      "Highest: 256.0\n",
      "[[  8.  32.   4.   2.]\n",
      " [  4.   8. 256.  32.]\n",
      " [  8.  16.   8.   2.]\n",
      " [  2.  64.  32.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 135\n",
      "Total Reward: 166\n",
      "Total episodes 180\n",
      "Eps_threshold: 0.3967022214104795\n",
      "Loss ep: 0.04478823873731825\n",
      "Score: 2136\n",
      "Highest: 256.0\n",
      "[[  4.  32.   8.   2.]\n",
      " [  8.  16.   2.   4.]\n",
      " [  4.   8. 256.  16.]\n",
      " [  2.  32.   2.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 136\n",
      "Total Reward: 197\n",
      "Total episodes 211\n",
      "Eps_threshold: 0.39264395795549323\n",
      "Loss ep: 0.0440886529136043\n",
      "Score: 2480\n",
      "Highest: 256.0\n",
      "[[  2.  16.   8.   4.]\n",
      " [  8.  32.  64.   8.]\n",
      " [ 16. 256.  32.   4.]\n",
      " [  8.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 137\n",
      "Total Reward: 131\n",
      "Total episodes 145\n",
      "Eps_threshold: 0.38987982136294735\n",
      "Loss ep: 0.04232154056943696\n",
      "Score: 1380\n",
      "Highest: 128.0\n",
      "[[  8.   4.  16.   4.]\n",
      " [ 16.   8.  64.   8.]\n",
      " [  8. 128.  32.   4.]\n",
      " [  4.  16.   4.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 138\n",
      "Total Reward: 139\n",
      "Total episodes 153\n",
      "Eps_threshold: 0.38698482819688707\n",
      "Loss ep: 0.042986542570824716\n",
      "Score: 1476\n",
      "Highest: 128.0\n",
      "[[ 32.   2.  64.   4.]\n",
      " [  4.   8.  32.  16.]\n",
      " [  2.  16. 128.   8.]\n",
      " [ 16.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 139\n",
      "Total Reward: 126\n",
      "Total episodes 140\n",
      "Eps_threshold: 0.3843551490144951\n",
      "Loss ep: 0.043630668095179966\n",
      "Score: 1372\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  4.  64.  32.  16.]\n",
      " [ 16.   8. 128.   8.]\n",
      " [  2.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 140\n",
      "Total Reward: 186\n",
      "Total episodes 200\n",
      "Eps_threshold: 0.3806302530449459\n",
      "Loss ep: 0.04234699249267578\n",
      "Score: 2396\n",
      "Highest: 256.0\n",
      "[[  8.  32.   2.   4.]\n",
      " [  2.   8.   4.  32.]\n",
      " [ 64. 256.   8.   2.]\n",
      " [  4.   8.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 141\n",
      "Total Reward: 188\n",
      "Total episodes 202\n",
      "Eps_threshold: 0.37690572800217076\n",
      "Loss ep: 0.04250450417546943\n",
      "Score: 2368\n",
      "Highest: 256.0\n",
      "[[  2.  64.   2.  16.]\n",
      " [  4.   8.   4.   2.]\n",
      " [ 16.  32.  16.   4.]\n",
      " [  4. 256.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 142\n",
      "Total Reward: 124\n",
      "Total episodes 138\n",
      "Eps_threshold: 0.37438279261577706\n",
      "Loss ep: 0.041997764421545944\n",
      "Score: 1344\n",
      "Highest: 128.0\n",
      "[[  2.   4.  32.   2.]\n",
      " [ 16.  64.  16.   4.]\n",
      " [  8. 128.   8.   2.]\n",
      " [ 16.   4.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 143\n",
      "Total Reward: 208\n",
      "Total episodes 222\n",
      "Eps_threshold: 0.37036050859278596\n",
      "Loss ep: 0.04208088780308629\n",
      "Score: 2648\n",
      "Highest: 256.0\n",
      "[[  4.  64.  16.   2.]\n",
      " [ 16.   2. 256.  32.]\n",
      " [  8.  16.  64.   8.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 144\n",
      "Total Reward: 136\n",
      "Total episodes 150\n",
      "Eps_threshold: 0.36766791462723325\n",
      "Loss ep: 0.04145762125651042\n",
      "Score: 1440\n",
      "Highest: 128.0\n",
      "[[  4.   2.   4.   2.]\n",
      " [ 16.  32.  64.   8.]\n",
      " [  4. 128.   8.   2.]\n",
      " [  2.   4.  16.  32.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 145\n",
      "Total Reward: 89\n",
      "Total episodes 103\n",
      "Eps_threshold: 0.36583065985864616\n",
      "Loss ep: 0.040315618792783864\n",
      "Score: 760\n",
      "Highest: 64.0\n",
      "[[ 4. 16.  8.  2.]\n",
      " [ 2.  8. 32. 16.]\n",
      " [ 8.  4. 64.  4.]\n",
      " [ 4.  2. 32. 16.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 146\n",
      "Total Reward: 99\n",
      "Total episodes 113\n",
      "Eps_threshold: 0.3638258854512603\n",
      "Loss ep: 0.040931659462177646\n",
      "Score: 908\n",
      "Highest: 64.0\n",
      "[[ 4.  8. 64.  2.]\n",
      " [ 2. 64.  4. 16.]\n",
      " [32. 16.  2.  8.]\n",
      " [ 4.  2.  8.  4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 147\n",
      "Total Reward: 144\n",
      "Total episodes 158\n",
      "Eps_threshold: 0.36104167307529\n",
      "Loss ep: 0.04204280768768697\n",
      "Score: 1476\n",
      "Highest: 128.0\n",
      "[[ 16.   8.   4.   2.]\n",
      " [  4.  32. 128.   4.]\n",
      " [  8.  64.   4.   8.]\n",
      " [  4.  16.  32.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 148\n",
      "Total Reward: 156\n",
      "Total episodes 170\n",
      "Eps_threshold: 0.35807046438023477\n",
      "Loss ep: 0.0414638968075023\n",
      "Score: 1720\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [128.  32.  64.  16.]\n",
      " [  8.  64.  16.   4.]\n",
      " [  4.  32.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 149\n",
      "Total Reward: 143\n",
      "Total episodes 157\n",
      "Eps_threshold: 0.3553488077135264\n",
      "Loss ep: 0.04134541711989482\n",
      "Score: 1520\n",
      "Highest: 128.0\n",
      "[[ 32.   4.   8.   2.]\n",
      " [  2.  16.  64.   4.]\n",
      " [128.  32.   8.  32.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 150\n",
      "Total Reward: 113\n",
      "Total episodes 127\n",
      "Eps_threshold: 0.3531627907339233\n",
      "Loss ep: 0.04043932036152036\n",
      "Score: 1216\n",
      "Highest: 128.0\n",
      "[[  4.  16.   8.   2.]\n",
      " [128.  64.   4.   8.]\n",
      " [  4.  16.   2.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 151\n",
      "Total Reward: 194\n",
      "Total episodes 208\n",
      "Eps_threshold: 0.34961239178569276\n",
      "Loss ep: 0.04106559203221248\n",
      "Score: 2440\n",
      "Highest: 256.0\n",
      "[[  2.   4.  64.   2.]\n",
      " [  4.   8.  16.  32.]\n",
      " [ 16. 256.  32.   4.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 152\n",
      "Total Reward: 154\n",
      "Total episodes 168\n",
      "Eps_threshold: 0.34677159574193783\n",
      "Loss ep: 0.041699733052934916\n",
      "Score: 1600\n",
      "Highest: 128.0\n",
      "[[  4.  16.   4.   2.]\n",
      " [ 32.  64. 128.   8.]\n",
      " [ 16.  32.  16.  32.]\n",
      " [  8.   2.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 153\n",
      "Total Reward: 132\n",
      "Total episodes 146\n",
      "Eps_threshold: 0.3443221145770016\n",
      "Loss ep: 0.04194201835214275\n",
      "Score: 1424\n",
      "Highest: 128.0\n",
      "[[  2.   4.  32.  16.]\n",
      " [  8.  16. 128.   4.]\n",
      " [  2.   8.  32.  64.]\n",
      " [  4.   2.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 154\n",
      "Total Reward: 229\n",
      "Total episodes 243\n",
      "Eps_threshold: 0.3402846779801352\n",
      "Loss ep: 0.041019957742573304\n",
      "Score: 2956\n",
      "Highest: 256.0\n",
      "[[ 32.   8.  32.   2.]\n",
      " [  4.  32.  16.   8.]\n",
      " [  2. 256. 128.   4.]\n",
      " [  8.   2.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 155\n",
      "Total Reward: 193\n",
      "Total episodes 207\n",
      "Eps_threshold: 0.33688386114875574\n",
      "Loss ep: 0.04052045149503699\n",
      "Score: 2156\n",
      "Highest: 128.0\n",
      "[[  2.   4.  16.   2.]\n",
      " [ 16. 128.  32.   8.]\n",
      " [ 64.   8. 128.  16.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 156\n",
      "Total Reward: 99\n",
      "Total episodes 113\n",
      "Eps_threshold: 0.3350421749959133\n",
      "Loss ep: 0.039857944556042156\n",
      "Score: 1072\n",
      "Highest: 128.0\n",
      "[[  4.  32.   2.   4.]\n",
      " [  2.  16.   4.   8.]\n",
      " [  4.   2.  32.   4.]\n",
      " [  2. 128.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 157\n",
      "Total Reward: 183\n",
      "Total episodes 197\n",
      "Eps_threshold: 0.3318562261293898\n",
      "Loss ep: 0.03971262510657916\n",
      "Score: 2316\n",
      "Highest: 256.0\n",
      "[[  8.   4.  32.   2.]\n",
      " [  4.   8. 256.   8.]\n",
      " [  2.  16.  64.   4.]\n",
      " [  8.   2.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 158\n",
      "Total Reward: 72\n",
      "Total episodes 86\n",
      "Eps_threshold: 0.3304752156574544\n",
      "Loss ep: 0.03954461009003395\n",
      "Score: 636\n",
      "Highest: 64.0\n",
      "[[ 2.  4. 16.  2.]\n",
      " [16. 32. 64.  4.]\n",
      " [ 4. 16.  4.  2.]\n",
      " [ 2.  8.  2. 16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 159\n",
      "Total Reward: 185\n",
      "Total episodes 199\n",
      "Eps_threshold: 0.3273022987007053\n",
      "Loss ep: 0.03941023888899453\n",
      "Score: 2356\n",
      "Highest: 256.0\n",
      "[[  4.  32.   8.   2.]\n",
      " [ 16.  64.  16.   4.]\n",
      " [  4. 256.   4.   8.]\n",
      " [  2.  16.   2.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 160\n",
      "Total Reward: 165\n",
      "Total episodes 179\n",
      "Eps_threshold: 0.3244751136524489\n",
      "Loss ep: 0.040118750247209435\n",
      "Score: 1800\n",
      "Highest: 128.0\n",
      "[[  2.  32.  64.   2.]\n",
      " [  8. 128.   2.   4.]\n",
      " [  4.  32.  64.  16.]\n",
      " [  2.   8.  32.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 161\n",
      "Total Reward: 276\n",
      "Total episodes 290\n",
      "Eps_threshold: 0.3199481244922446\n",
      "Loss ep: 0.03942982574989056\n",
      "Score: 3484\n",
      "Highest: 256.0\n",
      "[[  4.   8.   2.   4.]\n",
      " [ 32. 128.  16.   8.]\n",
      " [  2.  16. 256.  32.]\n",
      " [  4.  64.   8.  64.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 162\n",
      "Total Reward: 145\n",
      "Total episodes 159\n",
      "Eps_threshold: 0.31749380574612346\n",
      "Loss ep: 0.038959017339742406\n",
      "Score: 1516\n",
      "Highest: 128.0\n",
      "[[  2.   4.  32.   2.]\n",
      " [ 16. 128.  16.   4.]\n",
      " [ 32.  16.  64.   8.]\n",
      " [  4.   8.  16.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 163\n",
      "Total Reward: 215\n",
      "Total episodes 229\n",
      "Eps_threshold: 0.31399308156233996\n",
      "Loss ep: 0.03941186130307127\n",
      "Score: 2824\n",
      "Highest: 256.0\n",
      "[[  8.   2. 128.   2.]\n",
      " [  2.  32.   4.  16.]\n",
      " [  4.   8. 256.   4.]\n",
      " [  2.  32.   4.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 164\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.3117518355963957\n",
      "Loss ep: 0.039301717603528824\n",
      "Score: 1436\n",
      "Highest: 128.0\n",
      "[[  2.  32.   4.   2.]\n",
      " [ 64.   8. 128.  16.]\n",
      " [  2.  32.  16.   8.]\n",
      " [  4.   2.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 165\n",
      "Total Reward: 121\n",
      "Total episodes 135\n",
      "Eps_threshold: 0.3097218695490514\n",
      "Loss ep: 0.03822435449670862\n",
      "Score: 1300\n",
      "Highest: 128.0\n",
      "[[  2.   8. 128.   2.]\n",
      " [ 16.  64.   4.   8.]\n",
      " [  2.   4.   8.  32.]\n",
      " [  4.   8.   2.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 166\n",
      "Total Reward: 110\n",
      "Total episodes 124\n",
      "Eps_threshold: 0.3078693427252581\n",
      "Loss ep: 0.03843636666574786\n",
      "Score: 1152\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  4.   8.  16.   8.]\n",
      " [ 32. 128.  32.   2.]\n",
      " [  8.  16.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 167\n",
      "Total Reward: 334.9\n",
      "Total episodes 348\n",
      "Eps_threshold: 0.30273124722617595\n",
      "Loss ep: 0.039232001907524024\n",
      "Score: 4972\n",
      "Highest: 512.0\n",
      "[[  4.  32.   4.   2.]\n",
      " [ 64. 512.  64.  32.]\n",
      " [  4.   8.  16.   8.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 168\n",
      "Total Reward: 106\n",
      "Total episodes 120\n",
      "Eps_threshold: 0.30098011838273264\n",
      "Loss ep: 0.037837886810302736\n",
      "Score: 1124\n",
      "Highest: 128.0\n",
      "[[  2.  16.   2.  32.]\n",
      " [ 16.   8.   4.   2.]\n",
      " [  2.   4.  32. 128.]\n",
      " [  4.   2.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 169\n",
      "Total Reward: 200\n",
      "Total episodes 214\n",
      "Eps_threshold: 0.2978832290209717\n",
      "Loss ep: 0.03850922183455708\n",
      "Score: 2532\n",
      "Highest: 256.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  4. 256.  32.   8.]\n",
      " [  8.  32.  64.   2.]\n",
      " [  4.  16.  32.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 170\n",
      "Total Reward: 180\n",
      "Total episodes 194\n",
      "Eps_threshold: 0.2951042614814222\n",
      "Loss ep: 0.03877707854988649\n",
      "Score: 2320\n",
      "Highest: 256.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  4.  16.  64.   4.]\n",
      " [  8.  32.   4.   8.]\n",
      " [  4. 256.   2.  16.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 171\n",
      "Total Reward: 124\n",
      "Total episodes 138\n",
      "Eps_threshold: 0.29314381340114887\n",
      "Loss ep: 0.03869653093642083\n",
      "Score: 1316\n",
      "Highest: 128.0\n",
      "[[  4.   2.   8.   2.]\n",
      " [  8.  32.   2.   8.]\n",
      " [  4.   8.  64.  16.]\n",
      " [  2. 128.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 172\n",
      "Total Reward: 114\n",
      "Total episodes 128\n",
      "Eps_threshold: 0.2913374794297059\n",
      "Loss ep: 0.03825711831450462\n",
      "Score: 1168\n",
      "Highest: 128.0\n",
      "[[  2.   8.   2. 128.]\n",
      " [  4.  32.   8.   2.]\n",
      " [ 16.   8.  16.   8.]\n",
      " [  2.   4.   8.  32.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 173\n",
      "Total Reward: 191\n",
      "Total episodes 205\n",
      "Eps_threshold: 0.28846849890919724\n",
      "Loss ep: 0.0384530881556069\n",
      "Score: 2408\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [ 16.   2.  64.  32.]\n",
      " [  4. 256.   8.   4.]\n",
      " [  2.   4.  32.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 174\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.286415437712491\n",
      "Loss ep: 0.03934215210579537\n",
      "Score: 1436\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  4. 128.  32.   8.]\n",
      " [  8.   2.  64.   2.]\n",
      " [ 32.  16.   2.  16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 175\n",
      "Total Reward: 72\n",
      "Total episodes 86\n",
      "Eps_threshold: 0.28522940313215606\n",
      "Loss ep: 0.037905221761659134\n",
      "Score: 648\n",
      "Highest: 64.0\n",
      "[[ 4.  2.  4.  2.]\n",
      " [ 2.  8. 32.  4.]\n",
      " [ 4. 16. 64.  2.]\n",
      " [ 2.  8.  2. 32.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 176\n",
      "Total Reward: 237\n",
      "Total episodes 251\n",
      "Eps_threshold: 0.28179685839382707\n",
      "Loss ep: 0.037950675326039594\n",
      "Score: 3028\n",
      "Highest: 256.0\n",
      "[[ 16.   4.   2.   4.]\n",
      " [  2.  16.  64.  16.]\n",
      " [128.   4.   8.   4.]\n",
      " [  2.  16. 256.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 177\n",
      "Total Reward: 146\n",
      "Total episodes 160\n",
      "Eps_threshold: 0.2796311578791257\n",
      "Loss ep: 0.03750195801258087\n",
      "Score: 1692\n",
      "Highest: 128.0\n",
      "[[  2.  16.   8.   2.]\n",
      " [  4. 128.   2. 128.]\n",
      " [  8.  16.   4.   8.]\n",
      " [  4.   8.  16.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 178\n",
      "Total Reward: 193\n",
      "Total episodes 207\n",
      "Eps_threshold: 0.27685486748143784\n",
      "Loss ep: 0.03862928998643073\n",
      "Score: 2444\n",
      "Highest: 256.0\n",
      "[[  8.  16.   4.   2.]\n",
      " [ 32.   8.  32.   8.]\n",
      " [  4. 256.   8.  64.]\n",
      " [  2.  16.   2.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 179\n",
      "Total Reward: 220\n",
      "Total episodes 234\n",
      "Eps_threshold: 0.27375085938814236\n",
      "Loss ep: 0.037833633585872814\n",
      "Score: 2756\n",
      "Highest: 256.0\n",
      "[[  2.   4. 256.   2.]\n",
      " [ 64.  32.  16.   4.]\n",
      " [  4.  16.  64.   8.]\n",
      " [ 16.   4.  32.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 180\n",
      "Total Reward: 150\n",
      "Total episodes 164\n",
      "Eps_threshold: 0.27159694545736\n",
      "Loss ep: 0.03753374262553889\n",
      "Score: 1624\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [  4.  64.  32.   2.]\n",
      " [  8.  16.  64.  16.]\n",
      " [  2.   4.   8. 128.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 181\n",
      "Total Reward: 132\n",
      "Total episodes 146\n",
      "Eps_threshold: 0.26969424107609846\n",
      "Loss ep: 0.03757120158574353\n",
      "Score: 1384\n",
      "Highest: 128.0\n",
      "[[ 16.   2.  16.   2.]\n",
      " [  8.  32.  64.   8.]\n",
      " [  2.   8.  16. 128.]\n",
      " [  8.   4.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 182\n",
      "Total Reward: 198\n",
      "Total episodes 212\n",
      "Eps_threshold: 0.26695602032947446\n",
      "Loss ep: 0.03628854031832713\n",
      "Score: 2480\n",
      "Highest: 256.0\n",
      "[[  4.   8.  32.   2.]\n",
      " [  2.   4.  64.  16.]\n",
      " [ 16. 256.  32.   8.]\n",
      " [  8.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 183\n",
      "Total Reward: 102\n",
      "Total episodes 116\n",
      "Eps_threshold: 0.26546998906806024\n",
      "Loss ep: 0.03731160739372517\n",
      "Score: 1112\n",
      "Highest: 128.0\n",
      "[[  2.  16.   8.   4.]\n",
      " [  8. 128.  32.   2.]\n",
      " [ 16.   8.   2.   4.]\n",
      " [  4.  32.   4.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 184\n",
      "Total Reward: 100\n",
      "Total episodes 114\n",
      "Eps_threshold: 0.2640179523663594\n",
      "Loss ep: 0.035802431273878665\n",
      "Score: 1040\n",
      "Highest: 128.0\n",
      "[[  8.  16.   8.   2.]\n",
      " [  4.   2. 128.   8.]\n",
      " [  2.  16.  32.   4.]\n",
      " [  4.   2.   8.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 185\n",
      "Total Reward: 237\n",
      "Total episodes 251\n",
      "Eps_threshold: 0.2608499478729674\n",
      "Loss ep: 0.03724665090857274\n",
      "Score: 3044\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  8. 128.  64.   4.]\n",
      " [256.  32.   2.   8.]\n",
      " [  2.   4.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 186\n",
      "Total Reward: 123\n",
      "Total episodes 137\n",
      "Eps_threshold: 0.2591374975683631\n",
      "Loss ep: 0.03662292452624245\n",
      "Score: 1340\n",
      "Highest: 128.0\n",
      "[[  8.  16.   2.   4.]\n",
      " [  2. 128.  64.  32.]\n",
      " [  4.   8.   4.  16.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 187\n",
      "Total Reward: 186\n",
      "Total episodes 200\n",
      "Eps_threshold: 0.2566585380482416\n",
      "Loss ep: 0.03749699115753174\n",
      "Score: 2372\n",
      "Highest: 256.0\n",
      "[[  2. 256.   4.   2.]\n",
      " [  4.  16.   2.   4.]\n",
      " [ 16.  32.  16.   2.]\n",
      " [  4.  64.   4.  16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 188\n",
      "Total Reward: 70\n",
      "Total episodes 84\n",
      "Eps_threshold: 0.25562474467420027\n",
      "Loss ep: 0.03701062713350568\n",
      "Score: 612\n",
      "Highest: 64.0\n",
      "[[ 4.  8.  4.  2.]\n",
      " [16.  4. 16. 64.]\n",
      " [ 8.  2. 32.  2.]\n",
      " [ 4. 16.  2.  4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 189\n",
      "Total Reward: 206\n",
      "Total episodes 220\n",
      "Eps_threshold: 0.2529376784415933\n",
      "Loss ep: 0.036746705662120474\n",
      "Score: 2856\n",
      "Highest: 256.0\n",
      "[[  4.   2.   8.   2.]\n",
      " [  8. 256.  64.   8.]\n",
      " [  4. 128.  16.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 190\n",
      "Total Reward: 133\n",
      "Total episodes 147\n",
      "Eps_threshold: 0.25115863250788917\n",
      "Loss ep: 0.03636871714170287\n",
      "Score: 1432\n",
      "Highest: 128.0\n",
      "[[  2.   4.  32.   4.]\n",
      " [ 64.   8.  16.   8.]\n",
      " [  8. 128.  32.   4.]\n",
      " [  2.   4.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 191\n",
      "Total Reward: 128\n",
      "Total episodes 142\n",
      "Eps_threshold: 0.2494524702603591\n",
      "Loss ep: 0.036345656488982726\n",
      "Score: 1396\n",
      "Highest: 128.0\n",
      "[[  2.  32.   8.   2.]\n",
      " [  4.  64.  16.   8.]\n",
      " [  2.  32.   8. 128.]\n",
      " [  8.   2.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 192\n",
      "Total Reward: 178\n",
      "Total episodes 192\n",
      "Eps_threshold: 0.24716472529156425\n",
      "Loss ep: 0.03643055011828741\n",
      "Score: 2044\n",
      "Highest: 128.0\n",
      "[[  4.   8.   4.  16.]\n",
      " [  2.  64.  16.   4.]\n",
      " [128.  16. 128.  16.]\n",
      " [  2.   4.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 193\n",
      "Total Reward: 246\n",
      "Total episodes 260\n",
      "Eps_threshold: 0.24410153772174784\n",
      "Loss ep: 0.03670156185443585\n",
      "Score: 3116\n",
      "Highest: 256.0\n",
      "[[  4.   2.  32.   4.]\n",
      " [ 16.   8.   2.   8.]\n",
      " [  2.  64. 128.  16.]\n",
      " [  4. 256.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 194\n",
      "Total Reward: 150\n",
      "Total episodes 164\n",
      "Eps_threshold: 0.2421897541374737\n",
      "Loss ep: 0.03644292529036359\n",
      "Score: 1628\n",
      "Highest: 128.0\n",
      "[[  4.   8.   4.   2.]\n",
      " [  2.  16.  32.   4.]\n",
      " [128.  64.   8.  16.]\n",
      " [  2.   8.  64.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 195\n",
      "Total Reward: 231\n",
      "Total episodes 245\n",
      "Eps_threshold: 0.23936278021636584\n",
      "Loss ep: 0.036583686361507495\n",
      "Score: 3040\n",
      "Highest: 256.0\n",
      "[[  8. 256.  16.   2.]\n",
      " [  2.  32.  64.   4.]\n",
      " [  4.   8. 128.   8.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 196\n",
      "Total Reward: 182\n",
      "Total episodes 196\n",
      "Eps_threshold: 0.2371260030798587\n",
      "Loss ep: 0.036028073758495094\n",
      "Score: 2236\n",
      "Highest: 256.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  8. 256.  32.  16.]\n",
      " [  2.  32.  16.   8.]\n",
      " [ 16.   2.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 197\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.23545147405588362\n",
      "Loss ep: 0.03576269665279904\n",
      "Score: 1436\n",
      "Highest: 128.0\n",
      "[[  8.   4.   2.   4.]\n",
      " [  4. 128.   8.  32.]\n",
      " [ 16.  32.  16.   4.]\n",
      " [  2.  64.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 198\n",
      "Total Reward: 202\n",
      "Total episodes 216\n",
      "Eps_threshold: 0.2330296992595853\n",
      "Loss ep: 0.03650423774012813\n",
      "Score: 2604\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [ 64.  32. 256.  16.]\n",
      " [  8.   4.  64.   8.]\n",
      " [  4.   2.  16.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 199\n",
      "Total Reward: 237\n",
      "Total episodes 251\n",
      "Eps_threshold: 0.23024816715592056\n",
      "Loss ep: 0.03574203779972882\n",
      "Score: 3064\n",
      "Highest: 256.0\n",
      "[[  2.   8. 256.   4.]\n",
      " [  8.  32.  64.   8.]\n",
      " [  4. 128.  16.   4.]\n",
      " [  2.  16.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 200\n",
      "Total Reward: 133\n",
      "Total episodes 147\n",
      "Eps_threshold: 0.2286352777568859\n",
      "Loss ep: 0.0357584336987969\n",
      "Score: 1428\n",
      "Highest: 128.0\n",
      "[[  4.   2.   4.  32.]\n",
      " [ 64.   4. 128.   4.]\n",
      " [  2.   8.  16.   2.]\n",
      " [  4.  16.  32.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Update target_net\n",
      "Episode: 201\n",
      "Total Reward: 226\n",
      "Total episodes 240\n",
      "Eps_threshold: 0.22602733338529024\n",
      "Loss ep: 0.053022301197052\n",
      "Score: 2972\n",
      "Highest: 256.0\n",
      "[[  4. 256.   4.   2.]\n",
      " [  2.   8.  64.  16.]\n",
      " [128.  16.   8.   4.]\n",
      " [  2.   8.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 202\n",
      "Total Reward: 145\n",
      "Total episodes 159\n",
      "Eps_threshold: 0.22431672476370026\n",
      "Loss ep: 0.04961321488866266\n",
      "Score: 1544\n",
      "Highest: 128.0\n",
      "[[  2.  16.   2.   4.]\n",
      " [  4.  32.  64.  32.]\n",
      " [  8. 128.  32.   8.]\n",
      " [  2.   4.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 203\n",
      "Total Reward: 191\n",
      "Total episodes 205\n",
      "Eps_threshold: 0.22213119829274205\n",
      "Loss ep: 0.048590506576910254\n",
      "Score: 2416\n",
      "Highest: 256.0\n",
      "[[  4.   8.   4.   2.]\n",
      " [  8.  32.  64.   8.]\n",
      " [  4. 256.   8.   4.]\n",
      " [  2.  32.   2.  16.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 204\n",
      "Total Reward: 262\n",
      "Total episodes 276\n",
      "Eps_threshold: 0.21922389429267075\n",
      "Loss ep: 0.04806296721748684\n",
      "Score: 3336\n",
      "Highest: 256.0\n",
      "[[  4. 128.   4.   2.]\n",
      " [  2.  64.  32.   4.]\n",
      " [  8. 256.  64.  16.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 32\n",
      "---------------------------\n",
      "Episode: 205\n",
      "Total Reward: 77\n",
      "Total episodes 91\n",
      "Eps_threshold: 0.2182740880215191\n",
      "Loss ep: 0.0475612053504357\n",
      "Score: 664\n",
      "Highest: 64.0\n",
      "[[ 2.  8.  4.  2.]\n",
      " [ 4. 16.  8. 16.]\n",
      " [64. 32.  2.  4.]\n",
      " [16.  8. 16.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 206\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.21673854827439748\n",
      "Loss ep: 0.04626773821341025\n",
      "Score: 1392\n",
      "Highest: 128.0\n",
      "[[  4.   8.  16.   8.]\n",
      " [  2. 128.  32.  16.]\n",
      " [  4.  64.   4.   8.]\n",
      " [  2.   8.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 207\n",
      "Total Reward: 254\n",
      "Total episodes 268\n",
      "Eps_threshold: 0.21398673008563493\n",
      "Loss ep: 0.04651476731940882\n",
      "Score: 3220\n",
      "Highest: 256.0\n",
      "[[  4. 128.  16.   8.]\n",
      " [  8. 256.  32.   4.]\n",
      " [  4.  16.  64.  32.]\n",
      " [  2.   4.  16.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 208\n",
      "Total Reward: 225\n",
      "Total episodes 239\n",
      "Eps_threshold: 0.2115635957246535\n",
      "Loss ep: 0.045085260558826654\n",
      "Score: 2892\n",
      "Highest: 256.0\n",
      "[[  8.   4.   8.   2.]\n",
      " [ 32. 128.  32.  16.]\n",
      " [  4.   8.  16. 256.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 209\n",
      "Total Reward: 198\n",
      "Total episodes 212\n",
      "Eps_threshold: 0.20943830554767326\n",
      "Loss ep: 0.04450004505661299\n",
      "Score: 2456\n",
      "Highest: 256.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  4.  32.  16.   4.]\n",
      " [ 16.   4.  64.  32.]\n",
      " [  4. 256.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 210\n",
      "Total Reward: 190\n",
      "Total episodes 204\n",
      "Eps_threshold: 0.20741437442725355\n",
      "Loss ep: 0.04452593653809791\n",
      "Score: 2384\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  4.   8.  32.   8.]\n",
      " [ 16.  64. 256.  16.]\n",
      " [  4.  16.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 211\n",
      "Total Reward: 199\n",
      "Total episodes 213\n",
      "Eps_threshold: 0.20532306731670297\n",
      "Loss ep: 0.044823498793051274\n",
      "Score: 2528\n",
      "Highest: 256.0\n",
      "[[ 32.   4.   8.   2.]\n",
      " [  2. 256.  32.   4.]\n",
      " [ 16.  64.  16.  32.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 212\n",
      "Total Reward: 252\n",
      "Total episodes 266\n",
      "Eps_threshold: 0.20274246953667766\n",
      "Loss ep: 0.04383930765596548\n",
      "Score: 3280\n",
      "Highest: 256.0\n",
      "[[  2.   8.  64.   2.]\n",
      " [  4.  64.   8.   4.]\n",
      " [128. 256.  32.   8.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 213\n",
      "Total Reward: 165\n",
      "Total episodes 179\n",
      "Eps_threshold: 0.2010251210325242\n",
      "Loss ep: 0.04409887004830984\n",
      "Score: 1884\n",
      "Highest: 128.0\n",
      "[[  4.   8.   4.   2.]\n",
      " [ 16.   4. 128.   8.]\n",
      " [  8.  32.  16.   2.]\n",
      " [  2. 128.  32.   8.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 214\n",
      "Total Reward: 242\n",
      "Total episodes 256\n",
      "Eps_threshold: 0.19859558170621594\n",
      "Loss ep: 0.04345951974391937\n",
      "Score: 3084\n",
      "Highest: 256.0\n",
      "[[  4.   2.   4.   2.]\n",
      " [  8. 256. 128.   8.]\n",
      " [ 32.   8.  64.  16.]\n",
      " [  2.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 215\n",
      "Total Reward: 211\n",
      "Total episodes 225\n",
      "Eps_threshold: 0.19648577134714998\n",
      "Loss ep: 0.0427597173055013\n",
      "Score: 2668\n",
      "Highest: 256.0\n",
      "[[  2.   8.  64.   2.]\n",
      " [  8.   4. 256.   4.]\n",
      " [  4.  32.   8.  32.]\n",
      " [  2.  64.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 216\n",
      "Total Reward: 112\n",
      "Total episodes 126\n",
      "Eps_threshold: 0.19531460403831905\n",
      "Loss ep: 0.04233967690240769\n",
      "Score: 1172\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  4.   8.  32.   8.]\n",
      " [  8.  16. 128.   4.]\n",
      " [  4.  32.  16.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 217\n",
      "Total Reward: 145\n",
      "Total episodes 159\n",
      "Eps_threshold: 0.19384719362128125\n",
      "Loss ep: 0.042433576763800857\n",
      "Score: 1592\n",
      "Highest: 128.0\n",
      "[[  4.   2.   8.   2.]\n",
      " [  8.  64. 128.  64.]\n",
      " [  4.  16.  32.   4.]\n",
      " [  8.   2.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 218\n",
      "Total Reward: 106\n",
      "Total episodes 120\n",
      "Eps_threshold: 0.19274741310045562\n",
      "Loss ep: 0.04224346081415812\n",
      "Score: 1128\n",
      "Highest: 128.0\n",
      "[[  2.   8.   2.   4.]\n",
      " [  4.  16.  32.   2.]\n",
      " [  2.  32. 128.   8.]\n",
      " [ 16.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 219\n",
      "Total Reward: 141\n",
      "Total episodes 155\n",
      "Eps_threshold: 0.1913365946319259\n",
      "Loss ep: 0.04236053959015877\n",
      "Score: 1464\n",
      "Highest: 128.0\n",
      "[[  4.  16.   8.   4.]\n",
      " [ 16.  64.  32.   8.]\n",
      " [  4.  32. 128.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 220\n",
      "Total Reward: 123\n",
      "Total episodes 137\n",
      "Eps_threshold: 0.19009868364431584\n",
      "Loss ep: 0.04238315220296818\n",
      "Score: 1332\n",
      "Highest: 128.0\n",
      "[[  2.   8.   2.   8.]\n",
      " [  4.  64.   8.   4.]\n",
      " [  8.  32. 128.  16.]\n",
      " [  2.  16.   8.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 221\n",
      "Total Reward: 188\n",
      "Total episodes 202\n",
      "Eps_threshold: 0.18828884202482252\n",
      "Loss ep: 0.04177392827402247\n",
      "Score: 2384\n",
      "Highest: 256.0\n",
      "[[  4.  32.   2.   8.]\n",
      " [  2.   8.  64.   2.]\n",
      " [  8. 256.   8.   4.]\n",
      " [  4.   2.  32.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 222\n",
      "Total Reward: 135\n",
      "Total episodes 149\n",
      "Eps_threshold: 0.18696552562593183\n",
      "Loss ep: 0.04121038577700621\n",
      "Score: 1424\n",
      "Highest: 128.0\n",
      "[[  2.  32.   8.   4.]\n",
      " [  4.  64.  32.   8.]\n",
      " [  8.  16. 128.   4.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 223\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.18566081412268998\n",
      "Loss ep: 0.040664601970363305\n",
      "Score: 1436\n",
      "Highest: 128.0\n",
      "[[  8.   2.  32.   2.]\n",
      " [  4.   8.  64.   4.]\n",
      " [ 16. 128.   8.  16.]\n",
      " [  2.  32.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 224\n",
      "Total Reward: 231\n",
      "Total episodes 245\n",
      "Eps_threshold: 0.1835220955460236\n",
      "Loss ep: 0.04172357831682478\n",
      "Score: 3036\n",
      "Highest: 256.0\n",
      "[[  2.  16.   8.   2.]\n",
      " [ 64. 128. 256.   4.]\n",
      " [  8.   2.   4.  16.]\n",
      " [  2.   4.  32.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 225\n",
      "Total Reward: 133\n",
      "Total episodes 147\n",
      "Eps_threshold: 0.18225138373026387\n",
      "Loss ep: 0.041615226641804184\n",
      "Score: 1404\n",
      "Highest: 128.0\n",
      "[[  4.   2.  16.   2.]\n",
      " [ 16.  32. 128.   8.]\n",
      " [  8.  64.   8.   2.]\n",
      " [  4.  16.   2.  16.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 226\n",
      "Total Reward: 153\n",
      "Total episodes 167\n",
      "Eps_threshold: 0.18081907289586444\n",
      "Loss ep: 0.04067442659846323\n",
      "Score: 1644\n",
      "Highest: 128.0\n",
      "[[  4.   8.   2.   4.]\n",
      " [ 16.  32.  64.   8.]\n",
      " [  4.   8. 128.  16.]\n",
      " [  2.  64.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 227\n",
      "Total Reward: 220\n",
      "Total episodes 234\n",
      "Eps_threshold: 0.17883213598981423\n",
      "Loss ep: 0.04048128209562383\n",
      "Score: 2740\n",
      "Highest: 256.0\n",
      "[[ 32.   2.  64.   2.]\n",
      " [  2.   4.   8.   4.]\n",
      " [256.  64.  32.  16.]\n",
      " [ 16.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 228\n",
      "Total Reward: 101\n",
      "Total episodes 115\n",
      "Eps_threshold: 0.17786413687237324\n",
      "Loss ep: 0.040148714314336365\n",
      "Score: 1088\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   8.]\n",
      " [  8.   2.  32.   2.]\n",
      " [  2. 128.   8.  16.]\n",
      " [  4.  32.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 32\n",
      "---------------------------\n",
      "Episode: 229\n",
      "Total Reward: 206\n",
      "Total episodes 220\n",
      "Eps_threshold: 0.1760277500113761\n",
      "Loss ep: 0.04037427035245028\n",
      "Score: 2624\n",
      "Highest: 256.0\n",
      "[[  8.  64.   8.   2.]\n",
      " [  2.  32.  16.   4.]\n",
      " [ 16.  64.   8. 256.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 230\n",
      "Total Reward: 232\n",
      "Total episodes 246\n",
      "Eps_threshold: 0.17399811652074332\n",
      "Loss ep: 0.04040875473642737\n",
      "Score: 3060\n",
      "Highest: 256.0\n",
      "[[  2.  32.   2.  64.]\n",
      " [  4.   8.  16.   2.]\n",
      " [  8. 128. 256.   4.]\n",
      " [  2.  16.   4.  16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 231\n",
      "Total Reward: 111\n",
      "Total episodes 125\n",
      "Eps_threshold: 0.17297632471801522\n",
      "Loss ep: 0.03892781066894531\n",
      "Score: 1148\n",
      "Highest: 128.0\n",
      "[[  2.   4.  32.   2.]\n",
      " [ 32.  16.   8.   4.]\n",
      " [  2.   8. 128.   8.]\n",
      " [  4.   2.  16.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 232\n",
      "Total Reward: 244\n",
      "Total episodes 258\n",
      "Eps_threshold: 0.17088743245190238\n",
      "Loss ep: 0.040360118067541785\n",
      "Score: 3112\n",
      "Highest: 256.0\n",
      "[[  2.   4.  16.   8.]\n",
      " [  4.  16.   2.  32.]\n",
      " [  8.  64. 128. 256.]\n",
      " [  4.   8.  16.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 233\n",
      "Total Reward: 260\n",
      "Total episodes 274\n",
      "Eps_threshold: 0.1686983043941867\n",
      "Loss ep: 0.04013054562311103\n",
      "Score: 3272\n",
      "Highest: 256.0\n",
      "[[ 32.  16.   8.   4.]\n",
      " [  4.  32. 128.   2.]\n",
      " [  8.  64.  32.   4.]\n",
      " [256.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 234\n",
      "Total Reward: 223\n",
      "Total episodes 237\n",
      "Eps_threshold: 0.16682882801101362\n",
      "Loss ep: 0.040078271793413764\n",
      "Score: 2928\n",
      "Highest: 256.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  4.  16. 128.   4.]\n",
      " [  8. 256.   8.   2.]\n",
      " [  2.   8.  64.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 235\n",
      "Total Reward: 126\n",
      "Total episodes 140\n",
      "Eps_threshold: 0.16573485957150894\n",
      "Loss ep: 0.038874973569597515\n",
      "Score: 1356\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [ 32.   8.  16.   4.]\n",
      " [  4. 128.  64.  16.]\n",
      " [  8.  16.   2.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 236\n",
      "Total Reward: 155\n",
      "Total episodes 169\n",
      "Eps_threshold: 0.16442444430984474\n",
      "Loss ep: 0.0392361703003652\n",
      "Score: 2072\n",
      "Highest: 256.0\n",
      "[[  8.   4.  32.   2.]\n",
      " [  4.   8.   2.   4.]\n",
      " [  2.  16.  32.   8.]\n",
      " [  4. 256.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 237\n",
      "Total Reward: 243\n",
      "Total episodes 257\n",
      "Eps_threshold: 0.16245278524034965\n",
      "Loss ep: 0.03907022587520139\n",
      "Score: 3132\n",
      "Highest: 256.0\n",
      "[[128.   4.   2.   4.]\n",
      " [  4.  16.  32.   2.]\n",
      " [  8. 256.  64.   4.]\n",
      " [  4.  32.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 238\n",
      "Total Reward: 240\n",
      "Total episodes 254\n",
      "Eps_threshold: 0.1605288775405442\n",
      "Loss ep: 0.03862914888877568\n",
      "Score: 3080\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [ 16. 256.  32.   8.]\n",
      " [  8.  64.  16. 128.]\n",
      " [  4.   2.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 239\n",
      "Total Reward: 216\n",
      "Total episodes 230\n",
      "Eps_threshold: 0.15880771112436737\n",
      "Loss ep: 0.03894445170526919\n",
      "Score: 2832\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  8. 128.  16.   4.]\n",
      " [  2. 256.   4.  32.]\n",
      " [  4.  32.   8.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 240\n",
      "Total Reward: 370\n",
      "Total episodes 384\n",
      "Eps_threshold: 0.15597785660674537\n",
      "Loss ep: 0.03915459414323171\n",
      "Score: 5420\n",
      "Highest: 512.0\n",
      "[[  2.   4.   2.  16.]\n",
      " [  4.   8.  16.   2.]\n",
      " [ 16. 512. 128.  16.]\n",
      " [  4.  64.   4.  32.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 241\n",
      "Total Reward: 251\n",
      "Total episodes 265\n",
      "Eps_threshold: 0.15405640771671775\n",
      "Loss ep: 0.03823983534327093\n",
      "Score: 3196\n",
      "Highest: 256.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [ 32.  64.  16.   4.]\n",
      " [  4.  32. 256. 128.]\n",
      " [ 16.   2.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 242\n",
      "Total Reward: 197\n",
      "Total episodes 211\n",
      "Eps_threshold: 0.1525446014158359\n",
      "Loss ep: 0.039623210780428485\n",
      "Score: 2460\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [ 16.   8. 256.  16.]\n",
      " [ 32.  64.  32.   8.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 243\n",
      "Total Reward: 161\n",
      "Total episodes 175\n",
      "Eps_threshold: 0.1513027770581004\n",
      "Loss ep: 0.0394880975995745\n",
      "Score: 2112\n",
      "Highest: 256.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [  4.  16.   8.   2.]\n",
      " [ 32. 256.  32.   4.]\n",
      " [  2.   4.   8.  16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 244\n",
      "Total Reward: 97\n",
      "Total episodes 111\n",
      "Eps_threshold: 0.1505207188643602\n",
      "Loss ep: 0.039384781777321756\n",
      "Score: 904\n",
      "Highest: 64.0\n",
      "[[ 4. 16.  4.  2.]\n",
      " [64.  8. 64.  8.]\n",
      " [ 8. 32.  8.  4.]\n",
      " [ 2.  4. 16.  2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 245\n",
      "Total Reward: 179\n",
      "Total episodes 193\n",
      "Eps_threshold: 0.1491712157522441\n",
      "Loss ep: 0.03832156423460017\n",
      "Score: 2320\n",
      "Highest: 256.0\n",
      "[[  2.  64.   2.   8.]\n",
      " [  8.  32.  16.   2.]\n",
      " [  2.   4. 256.   8.]\n",
      " [ 16.   2.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 246\n",
      "Total Reward: 245\n",
      "Total episodes 259\n",
      "Eps_threshold: 0.1473805679772017\n",
      "Loss ep: 0.03849501591391545\n",
      "Score: 3096\n",
      "Highest: 256.0\n",
      "[[  4.   8. 128.   4.]\n",
      " [ 16.  64.   4.  32.]\n",
      " [  8.  16. 256.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 247\n",
      "Total Reward: 265\n",
      "Total episodes 279\n",
      "Eps_threshold: 0.14547741441313247\n",
      "Loss ep: 0.039002145063065284\n",
      "Score: 3580\n",
      "Highest: 256.0\n",
      "[[  2.   4.  64.   4.]\n",
      " [256.   8. 128.   2.]\n",
      " [  2. 128.   2.   4.]\n",
      " [  4.   2.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 248\n",
      "Total Reward: 223\n",
      "Total episodes 237\n",
      "Eps_threshold: 0.14388148162944245\n",
      "Loss ep: 0.038104000976820034\n",
      "Score: 2884\n",
      "Highest: 256.0\n",
      "[[  4.  16.   4.   2.]\n",
      " [ 32.   4.  32.   8.]\n",
      " [  8. 256.  16.   2.]\n",
      " [  2.   8. 128.   8.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 249\n",
      "Total Reward: 251\n",
      "Total episodes 265\n",
      "Eps_threshold: 0.14211925254722518\n",
      "Loss ep: 0.037699692204313455\n",
      "Score: 3192\n",
      "Highest: 256.0\n",
      "[[ 32.   8.  32.   4.]\n",
      " [ 64.  16. 128.  16.]\n",
      " [  8. 256.   8.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 250\n",
      "Total Reward: 213\n",
      "Total episodes 227\n",
      "Eps_threshold: 0.1406281768921303\n",
      "Loss ep: 0.03763565618036077\n",
      "Score: 2728\n",
      "Highest: 256.0\n",
      "[[  2.   4.  16.   2.]\n",
      " [  4.  16.  64.   4.]\n",
      " [ 64.  32. 256.  32.]\n",
      " [  2.   8.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 251\n",
      "Total Reward: 250\n",
      "Total episodes 264\n",
      "Eps_threshold: 0.13891521537529425\n",
      "Loss ep: 0.03804051514827844\n",
      "Score: 3184\n",
      "Highest: 256.0\n",
      "[[  2.   8.  32.  16.]\n",
      " [  4.  16.  64.   2.]\n",
      " [128.  32. 256.   8.]\n",
      " [  4.   8.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 252\n",
      "Total Reward: 106\n",
      "Total episodes 120\n",
      "Eps_threshold: 0.1381440399229246\n",
      "Loss ep: 0.03712954123814901\n",
      "Score: 1124\n",
      "Highest: 128.0\n",
      "[[  2.  16.  32.   4.]\n",
      " [  4.  32. 128.   2.]\n",
      " [  8.   4.  16.   4.]\n",
      " [  4.   2.   4.   8.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 253\n",
      "Total Reward: 177\n",
      "Total episodes 191\n",
      "Eps_threshold: 0.1369260893124898\n",
      "Loss ep: 0.03788540625447378\n",
      "Score: 2056\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [ 32. 128.  16.   8.]\n",
      " [  8.  16.  64.   4.]\n",
      " [  2.   4. 128.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 254\n",
      "Total Reward: 110\n",
      "Total episodes 124\n",
      "Eps_threshold: 0.13614158204432034\n",
      "Loss ep: 0.03708603689747472\n",
      "Score: 1156\n",
      "Highest: 128.0\n",
      "[[ 32.  16.   4.   2.]\n",
      " [  2.   4. 128.  16.]\n",
      " [  8.  32.   2.   4.]\n",
      " [  2.   4.  16.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 255\n",
      "Total Reward: 86\n",
      "Total episodes 100\n",
      "Eps_threshold: 0.13551244827920633\n",
      "Loss ep: 0.03765269994735718\n",
      "Score: 836\n",
      "Highest: 64.0\n",
      "[[ 4.  2.  4.  2.]\n",
      " [64.  8.  2.  4.]\n",
      " [ 8. 32. 16.  8.]\n",
      " [ 4. 64.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 256\n",
      "Total Reward: 173\n",
      "Total episodes 187\n",
      "Eps_threshold: 0.13434437613470782\n",
      "Loss ep: 0.03823303028861469\n",
      "Score: 2296\n",
      "Highest: 256.0\n",
      "[[  2.   8.  64.   4.]\n",
      " [  4.  32.   4.  16.]\n",
      " [  8. 256.  16.   8.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 257\n",
      "Total Reward: 132\n",
      "Total episodes 146\n",
      "Eps_threshold: 0.1334399672975056\n",
      "Loss ep: 0.03777805093216569\n",
      "Score: 1408\n",
      "Highest: 128.0\n",
      "[[  2.   8.  64.   2.]\n",
      " [  4.  32.  16.   8.]\n",
      " [  2. 128.  32.   4.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 258\n",
      "Total Reward: 83\n",
      "Total episodes 97\n",
      "Eps_threshold: 0.132842732920181\n",
      "Loss ep: 0.036645837665833146\n",
      "Score: 824\n",
      "Highest: 64.0\n",
      "[[ 2.  4.  2.  8.]\n",
      " [ 8. 32. 64.  2.]\n",
      " [64.  2. 16.  4.]\n",
      " [ 2.  4.  8.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 259\n",
      "Total Reward: 150\n",
      "Total episodes 164\n",
      "Eps_threshold: 0.13183954121742802\n",
      "Loss ep: 0.03726573106719226\n",
      "Score: 2032\n",
      "Highest: 256.0\n",
      "[[  2. 256.  32.   4.]\n",
      " [  4.   2.   8.   2.]\n",
      " [  2.   8.  32.   4.]\n",
      " [  4.   2.   4.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 32\n",
      "---------------------------\n",
      "Episode: 260\n",
      "Total Reward: 125\n",
      "Total episodes 139\n",
      "Eps_threshold: 0.13099569217804424\n",
      "Loss ep: 0.03700412777688006\n",
      "Score: 1272\n",
      "Highest: 128.0\n",
      "[[ 32.   4.   8.   2.]\n",
      " [ 16.  32. 128.   4.]\n",
      " [ 32.   4.  16.   8.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 261\n",
      "Total Reward: 152\n",
      "Total episodes 166\n",
      "Eps_threshold: 0.12999558412284262\n",
      "Loss ep: 0.03880455982254212\n",
      "Score: 1636\n",
      "Highest: 128.0\n",
      "[[  2.   8.  64.   2.]\n",
      " [  4.  16. 128.  16.]\n",
      " [ 32.   8.  64.   4.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 262\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.12911089419021565\n",
      "Loss ep: 0.03720245490203033\n",
      "Score: 1432\n",
      "Highest: 128.0\n",
      "[[  2.   4.  16.   4.]\n",
      " [  8.  32.  64.  16.]\n",
      " [  4. 128.  32.   4.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 263\n",
      "Total Reward: 78\n",
      "Total episodes 92\n",
      "Eps_threshold: 0.12856424234012498\n",
      "Loss ep: 0.036678233872289245\n",
      "Score: 680\n",
      "Highest: 64.0\n",
      "[[ 8.  4.  2.  4.]\n",
      " [ 2.  8. 64.  8.]\n",
      " [32.  4. 16.  4.]\n",
      " [ 4.  8. 32.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 264\n",
      "Total Reward: 110\n",
      "Total episodes 124\n",
      "Eps_threshold: 0.12783141814011495\n",
      "Loss ep: 0.03650542228452621\n",
      "Score: 1144\n",
      "Highest: 128.0\n",
      "[[  2.  16.  32.   4.]\n",
      " [  4.  32.   4.   8.]\n",
      " [128.   4.  16.   4.]\n",
      " [  8.   2.   4.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 265\n",
      "Total Reward: 130\n",
      "Total episodes 144\n",
      "Eps_threshold: 0.12698607880298254\n",
      "Loss ep: 0.03661890824635824\n",
      "Score: 1376\n",
      "Highest: 128.0\n",
      "[[  2.  16.   8.   4.]\n",
      " [  4.   8.  64.   2.]\n",
      " [  8.  32. 128.  16.]\n",
      " [  4.  16.   4.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 266\n",
      "Total Reward: 224\n",
      "Total episodes 238\n",
      "Eps_threshold: 0.12560219490536256\n",
      "Loss ep: 0.0371063376675133\n",
      "Score: 2740\n",
      "Highest: 256.0\n",
      "[[  2.   4.  32.   4.]\n",
      " [  4.   8. 256.  64.]\n",
      " [  8.  32.  64.   4.]\n",
      " [  4.   8.   2.  16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 267\n",
      "Total Reward: 137\n",
      "Total episodes 151\n",
      "Eps_threshold: 0.12473268486458096\n",
      "Loss ep: 0.03785401148511874\n",
      "Score: 1512\n",
      "Highest: 128.0\n",
      "[[  2.   4.  64.   2.]\n",
      " [  4.   8. 128.   8.]\n",
      " [  8.  16.  64.  16.]\n",
      " [  2.   4.   2.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 268\n",
      "Total Reward: 133\n",
      "Total episodes 147\n",
      "Eps_threshold: 0.12389249112526204\n",
      "Loss ep: 0.03734106595824365\n",
      "Score: 1416\n",
      "Highest: 128.0\n",
      "[[  2.   8.  32.   2.]\n",
      " [  4.  64. 128.   4.]\n",
      " [  8.  32.   8.  16.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 269\n",
      "Total Reward: 189\n",
      "Total episodes 203\n",
      "Eps_threshold: 0.12274232928603679\n",
      "Loss ep: 0.03839913260173328\n",
      "Score: 2436\n",
      "Highest: 256.0\n",
      "[[  4.   2.   8.   2.]\n",
      " [ 32.   4.  16.   4.]\n",
      " [ 16. 256.  64.  16.]\n",
      " [  2.  32.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 270\n",
      "Total Reward: 175\n",
      "Total episodes 189\n",
      "Eps_threshold: 0.1216819325402359\n",
      "Loss ep: 0.03591061647606905\n",
      "Score: 2288\n",
      "Highest: 256.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [ 64.  16.  32.   2.]\n",
      " [  4. 256.   4.  16.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 271\n",
      "Total Reward: 123\n",
      "Total episodes 137\n",
      "Eps_threshold: 0.12091952552752176\n",
      "Loss ep: 0.03608767655644104\n",
      "Score: 1328\n",
      "Highest: 128.0\n",
      "[[  4.   2. 128.   8.]\n",
      " [  8.  64.  16.   2.]\n",
      " [  2.   4.  32.   8.]\n",
      " [  4.  16.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 272\n",
      "Total Reward: 47\n",
      "Total episodes 61\n",
      "Eps_threshold: 0.1205817363649926\n",
      "Loss ep: 0.03609681520305696\n",
      "Score: 396\n",
      "Highest: 32.0\n",
      "[[16.  2. 16.  2.]\n",
      " [ 4.  8. 32.  8.]\n",
      " [16. 32.  2.  4.]\n",
      " [ 2.  8.  4.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 273\n",
      "Total Reward: 103\n",
      "Total episodes 117\n",
      "Eps_threshold: 0.11993672171460991\n",
      "Loss ep: 0.0367678210266635\n",
      "Score: 1072\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.  16.]\n",
      " [  4.   8.  16.   8.]\n",
      " [  8.  16. 128.  32.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 274\n",
      "Total Reward: 234\n",
      "Total episodes 248\n",
      "Eps_threshold: 0.11858192347387826\n",
      "Loss ep: 0.0367916630160424\n",
      "Score: 3028\n",
      "Highest: 256.0\n",
      "[[  4.  32.   4.   8.]\n",
      " [  2. 128.  64.   4.]\n",
      " [  4.   2. 256.  16.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 275\n",
      "Total Reward: 102\n",
      "Total episodes 116\n",
      "Eps_threshold: 0.11795397113985713\n",
      "Loss ep: 0.036206985342091526\n",
      "Score: 972\n",
      "Highest: 64.0\n",
      "[[ 4.  8.  4.  2.]\n",
      " [ 2. 64. 32.  8.]\n",
      " [ 8. 32. 64.  2.]\n",
      " [ 2.  4.  8. 16.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 276\n",
      "Total Reward: 124\n",
      "Total episodes 138\n",
      "Eps_threshold: 0.11721165268281505\n",
      "Loss ep: 0.03611333473868992\n",
      "Score: 1344\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  4.   8.  16.  64.]\n",
      " [  8.   2. 128.   4.]\n",
      " [  4.  32.  16.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 277\n",
      "Total Reward: 67\n",
      "Total episodes 81\n",
      "Eps_threshold: 0.11677832357320318\n",
      "Loss ep: 0.03579112629831573\n",
      "Score: 584\n",
      "Highest: 64.0\n",
      "[[ 2. 16.  2.  8.]\n",
      " [ 4.  8. 32. 16.]\n",
      " [ 2. 64.  2.  4.]\n",
      " [ 4.  8.  4.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 278\n",
      "Total Reward: 104\n",
      "Total episodes 118\n",
      "Eps_threshold: 0.11615018629122363\n",
      "Loss ep: 0.03629360764713611\n",
      "Score: 1068\n",
      "Highest: 128.0\n",
      "[[  4.   2.   4.   2.]\n",
      " [  8.   4.  16. 128.]\n",
      " [  4.  32.   4.  16.]\n",
      " [  2.  16.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 279\n",
      "Total Reward: 159\n",
      "Total episodes 173\n",
      "Eps_threshold: 0.11523594696535447\n",
      "Loss ep: 0.035999989923025145\n",
      "Score: 1860\n",
      "Highest: 128.0\n",
      "[[  2.   8.  16.   2.]\n",
      " [  8.  16.   8. 128.]\n",
      " [  2. 128.  32.   4.]\n",
      " [  8.  32.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 280\n",
      "Total Reward: 135\n",
      "Total episodes 149\n",
      "Eps_threshold: 0.11445485235062443\n",
      "Loss ep: 0.036134335818706745\n",
      "Score: 1436\n",
      "Highest: 128.0\n",
      "[[  2. 128.  32.   4.]\n",
      " [  4.   8.  64.   2.]\n",
      " [ 16.   4.  32.  16.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 281\n",
      "Total Reward: 204\n",
      "Total episodes 218\n",
      "Eps_threshold: 0.11332247711646506\n",
      "Loss ep: 0.036951318793340564\n",
      "Score: 2608\n",
      "Highest: 256.0\n",
      "[[  2.  16.  64.   2.]\n",
      " [  4. 256.   4.   8.]\n",
      " [ 32.  16.  64.   2.]\n",
      " [  4.   2.   4.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 282\n",
      "Total Reward: 142\n",
      "Total episodes 156\n",
      "Eps_threshold: 0.1125196967086397\n",
      "Loss ep: 0.036585129224337064\n",
      "Score: 1548\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  8.  16.  64.   2.]\n",
      " [ 16.  64. 128.  16.]\n",
      " [  4.   8.   2.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 283\n",
      "Total Reward: 211\n",
      "Total episodes 225\n",
      "Eps_threshold: 0.11137281343509023\n",
      "Loss ep: 0.03616083780924479\n",
      "Score: 2656\n",
      "Highest: 256.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [ 16.   2.  64.   4.]\n",
      " [ 64. 256.  16.   8.]\n",
      " [  4.   8.  32.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 284\n",
      "Total Reward: 144\n",
      "Total episodes 158\n",
      "Eps_threshold: 0.11057512323389722\n",
      "Loss ep: 0.035529353950597066\n",
      "Score: 1536\n",
      "Highest: 128.0\n",
      "[[  4.  32.   4.   2.]\n",
      " [ 16.   2.   8.   4.]\n",
      " [  4.  64. 128.  32.]\n",
      " [  2.  32.  16.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 285\n",
      "Total Reward: 140\n",
      "Total episodes 154\n",
      "Eps_threshold: 0.10980366869658935\n",
      "Loss ep: 0.035917226370278894\n",
      "Score: 1464\n",
      "Highest: 128.0\n",
      "[[ 32.   4.   2.   4.]\n",
      " [  2.   8.  16.   8.]\n",
      " [  8.  64. 128.  32.]\n",
      " [  2.  16.   8.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 286\n",
      "Total Reward: 244\n",
      "Total episodes 258\n",
      "Eps_threshold: 0.10852446994161251\n",
      "Loss ep: 0.03562872908836187\n",
      "Score: 3132\n",
      "Highest: 256.0\n",
      "[[  2.  32.   2.  32.]\n",
      " [128.  64.   4.   2.]\n",
      " [  8.   4.   2. 256.]\n",
      " [  4.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 287\n",
      "Total Reward: 130\n",
      "Total episodes 144\n",
      "Eps_threshold: 0.1078176413942999\n",
      "Loss ep: 0.03602055377430386\n",
      "Score: 1444\n",
      "Highest: 128.0\n",
      "[[ 32.   2.  32.   2.]\n",
      " [  2.   4.  64.   4.]\n",
      " [  4. 128.  32.   2.]\n",
      " [  2.   8.   2.   8.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 288\n",
      "Total Reward: 145\n",
      "Total episodes 159\n",
      "Eps_threshold: 0.10704307412963691\n",
      "Loss ep: 0.03548306039294357\n",
      "Score: 1592\n",
      "Highest: 128.0\n",
      "[[  2.   8.   2.   8.]\n",
      " [  4.  32.   8.   2.]\n",
      " [ 64.  16. 128.   4.]\n",
      " [  8.  64.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 289\n",
      "Total Reward: 150\n",
      "Total episodes 164\n",
      "Eps_threshold: 0.10625057461043659\n",
      "Loss ep: 0.03624298805143775\n",
      "Score: 1564\n",
      "Highest: 128.0\n",
      "[[  4.  32.  16.   2.]\n",
      " [  8.   2.  32.   8.]\n",
      " [ 32.  64.  16.   4.]\n",
      " [  4. 128.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 290\n",
      "Total Reward: 95\n",
      "Total episodes 109\n",
      "Eps_threshold: 0.10572743582687176\n",
      "Loss ep: 0.03574922325414255\n",
      "Score: 836\n",
      "Highest: 64.0\n",
      "[[ 4. 32.  2.  4.]\n",
      " [ 8. 16. 32.  8.]\n",
      " [ 4. 32.  8. 16.]\n",
      " [ 2.  8. 64.  4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 291\n",
      "Total Reward: 191\n",
      "Total episodes 205\n",
      "Eps_threshold: 0.10475124115411698\n",
      "Loss ep: 0.03628310226812595\n",
      "Score: 2428\n",
      "Highest: 256.0\n",
      "[[  2.  32.   8.   4.]\n",
      " [  4. 256.  64.   8.]\n",
      " [ 16.  32.   4.   2.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 292\n",
      "Total Reward: 104\n",
      "Total episodes 118\n",
      "Eps_threshold: 0.10419385473811905\n",
      "Loss ep: 0.036204091573165634\n",
      "Score: 964\n",
      "Highest: 64.0\n",
      "[[16.  2. 16.  2.]\n",
      " [ 4. 64.  8. 64.]\n",
      " [ 2. 32. 16.  4.]\n",
      " [16.  8.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 293\n",
      "Total Reward: 195\n",
      "Total episodes 209\n",
      "Eps_threshold: 0.103214654189883\n",
      "Loss ep: 0.035224332763817895\n",
      "Score: 2448\n",
      "Highest: 256.0\n",
      "[[  4.   2.  32.   2.]\n",
      " [  8.  16. 256.   4.]\n",
      " [ 32.   8.  64.   8.]\n",
      " [  4.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 294\n",
      "Total Reward: 157\n",
      "Total episodes 171\n",
      "Eps_threshold: 0.10242106631913915\n",
      "Loss ep: 0.035958772514298645\n",
      "Score: 1656\n",
      "Highest: 128.0\n",
      "[[  2.  32.   8.   4.]\n",
      " [ 16.  64.  16.   2.]\n",
      " [  4. 128.  64.   8.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 295\n",
      "Total Reward: 131\n",
      "Total episodes 145\n",
      "Eps_threshold: 0.10175343667015735\n",
      "Loss ep: 0.03641272577746161\n",
      "Score: 1404\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  8.  16. 128.  32.]\n",
      " [  4.  64.   4.   2.]\n",
      " [  2.   8.  32.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 296\n",
      "Total Reward: 130\n",
      "Total episodes 144\n",
      "Eps_threshold: 0.10109518447767217\n",
      "Loss ep: 0.03594215710957845\n",
      "Score: 1368\n",
      "Highest: 128.0\n",
      "[[  2.  16. 128.   4.]\n",
      " [  4.  64.   2.   8.]\n",
      " [ 16.  32.  16.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 297\n",
      "Total Reward: 109\n",
      "Total episodes 123\n",
      "Eps_threshold: 0.10053666829078128\n",
      "Loss ep: 0.03568843903580332\n",
      "Score: 1112\n",
      "Highest: 128.0\n",
      "[[  2.   8.   2.  16.]\n",
      " [ 16. 128.  32.   2.]\n",
      " [  2.   8.  16.   4.]\n",
      " [  4.   2.   8.  16.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 298\n",
      "Total Reward: 110\n",
      "Total episodes 124\n",
      "Eps_threshold: 0.09997707747147305\n",
      "Loss ep: 0.03389110488276328\n",
      "Score: 1164\n",
      "Highest: 128.0\n",
      "[[ 16.   8.   4.   2.]\n",
      " [  4.  32. 128.   8.]\n",
      " [ 16.   4.  32.  16.]\n",
      " [  4.   8.   2.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 299\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.09931370460497892\n",
      "Loss ep: 0.03540651218311207\n",
      "Score: 1416\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  8.   4.  32.   4.]\n",
      " [  2.  32.  64.  16.]\n",
      " [  4.   8. 128.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 300\n",
      "Total Reward: 124\n",
      "Total episodes 138\n",
      "Eps_threshold: 0.09869956127430712\n",
      "Loss ep: 0.0352809671042622\n",
      "Score: 1344\n",
      "Highest: 128.0\n",
      "[[ 16.   2.   4.   2.]\n",
      " [  4. 128.  16.   4.]\n",
      " [  2.  16.  32.  64.]\n",
      " [  8.   4.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Update target_net\n",
      "Episode: 301\n",
      "Total Reward: 89\n",
      "Total episodes 103\n",
      "Eps_threshold: 0.09824393278414005\n",
      "Loss ep: 0.050633388815574276\n",
      "Score: 808\n",
      "Highest: 64.0\n",
      "[[ 2. 32.  4. 16.]\n",
      " [ 4. 16.  8.  4.]\n",
      " [ 8. 32.  2. 32.]\n",
      " [ 2. 64.  8.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 302\n",
      "Total Reward: 182\n",
      "Total episodes 196\n",
      "Eps_threshold: 0.09738336590794142\n",
      "Loss ep: 0.04619671373951192\n",
      "Score: 2344\n",
      "Highest: 256.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [  4.  64.   4.  32.]\n",
      " [ 16.   8.  16. 256.]\n",
      " [  4.   2.   8.  16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 303\n",
      "Total Reward: 130\n",
      "Total episodes 144\n",
      "Eps_threshold: 0.09675646522407476\n",
      "Loss ep: 0.04506320423550076\n",
      "Score: 1400\n",
      "Highest: 128.0\n",
      "[[  2.  32.   8.   2.]\n",
      " [  8. 128.   4.   8.]\n",
      " [ 16.  32.  64.   4.]\n",
      " [  4.   2.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 304\n",
      "Total Reward: 157\n",
      "Total episodes 171\n",
      "Eps_threshold: 0.09601785948542998\n",
      "Loss ep: 0.04503790537516276\n",
      "Score: 1672\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  4.   2.  16.  64.]\n",
      " [ 64.  32. 128.  16.]\n",
      " [  2.   4.  16.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 305\n",
      "Total Reward: 197\n",
      "Total episodes 211\n",
      "Eps_threshold: 0.09511514127928004\n",
      "Loss ep: 0.04410603148112365\n",
      "Score: 2236\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.  16.]\n",
      " [ 32. 128.  16.   4.]\n",
      " [  2.  16.  64.  32.]\n",
      " [  4.   2. 128.  16.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 306\n",
      "Total Reward: 382\n",
      "Total episodes 396\n",
      "Eps_threshold: 0.09344643617868562\n",
      "Loss ep: 0.04311041398481889\n",
      "Score: 5572\n",
      "Highest: 512.0\n",
      "[[  8.  16.   2.   8.]\n",
      " [ 16.  32.  64.  32.]\n",
      " [  4. 128. 512.   8.]\n",
      " [  2.  32.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 307\n",
      "Total Reward: 182\n",
      "Total episodes 196\n",
      "Eps_threshold: 0.09263265514415413\n",
      "Loss ep: 0.04327941427425462\n",
      "Score: 2380\n",
      "Highest: 256.0\n",
      "[[  2.   8.  32.   4.]\n",
      " [  8. 256.  64.   8.]\n",
      " [ 16.   8.  32.   2.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 308\n",
      "Total Reward: 124\n",
      "Total episodes 138\n",
      "Eps_threshold: 0.09206445237754696\n",
      "Loss ep: 0.04151636621226435\n",
      "Score: 1328\n",
      "Highest: 128.0\n",
      "[[  2.  32.   2.   4.]\n",
      " [  8.   4. 128.  16.]\n",
      " [  4.   8.  64.   4.]\n",
      " [ 16.   2.   8.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 309\n",
      "Total Reward: 231\n",
      "Total episodes 245\n",
      "Eps_threshold: 0.09106529516846544\n",
      "Loss ep: 0.04197744252730389\n",
      "Score: 2956\n",
      "Highest: 256.0\n",
      "[[  2.  32.   4.   2.]\n",
      " [  4. 128.  32.   4.]\n",
      " [ 32.  16. 256.   8.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 310\n",
      "Total Reward: 125\n",
      "Total episodes 139\n",
      "Eps_threshold: 0.0905038446674889\n",
      "Loss ep: 0.041100392238699275\n",
      "Score: 1352\n",
      "Highest: 128.0\n",
      "[[  2.  16.   8.   4.]\n",
      " [128.   2.  16.  32.]\n",
      " [  2.  64.   8.   4.]\n",
      " [  8.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 311\n",
      "Total Reward: 140\n",
      "Total episodes 154\n",
      "Eps_threshold: 0.08988634548635414\n",
      "Loss ep: 0.039582497113710875\n",
      "Score: 1476\n",
      "Highest: 128.0\n",
      "[[  2.  16.  32.  16.]\n",
      " [  8.  64. 128.   2.]\n",
      " [  4.  16.  32.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 312\n",
      "Total Reward: 308\n",
      "Total episodes 322\n",
      "Eps_threshold: 0.08861047365206563\n",
      "Loss ep: 0.040658186681522344\n",
      "Score: 3928\n",
      "Highest: 256.0\n",
      "[[  2.   4.  16.   4.]\n",
      " [  8. 128.  32.  64.]\n",
      " [ 32. 256.  16.   4.]\n",
      " [  2.   8. 128.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 313\n",
      "Total Reward: 143\n",
      "Total episodes 157\n",
      "Eps_threshold: 0.08799579719547745\n",
      "Loss ep: 0.040110111236572266\n",
      "Score: 1516\n",
      "Highest: 128.0\n",
      "[[128.   8.   4.  32.]\n",
      " [  2.  32.  64.   4.]\n",
      " [  4.  16.  32.   2.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 314\n",
      "Total Reward: 190\n",
      "Total episodes 204\n",
      "Eps_threshold: 0.08720428364559857\n",
      "Loss ep: 0.04026298429451737\n",
      "Score: 2488\n",
      "Highest: 256.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  4.  16.   2.  64.]\n",
      " [  8. 256.  16.   8.]\n",
      " [  4.   2.  64.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 315\n",
      "Total Reward: 269\n",
      "Total episodes 283\n",
      "Eps_threshold: 0.08611953572275217\n",
      "Loss ep: 0.03945754694854413\n",
      "Score: 3384\n",
      "Highest: 256.0\n",
      "[[  8. 256.   4.   2.]\n",
      " [ 32.  64.  16.   4.]\n",
      " [  8.  16. 128.   2.]\n",
      " [  4.   2.  64.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 316\n",
      "Total Reward: 107\n",
      "Total episodes 121\n",
      "Eps_threshold: 0.08566040280914336\n",
      "Loss ep: 0.03931835269139818\n",
      "Score: 952\n",
      "Highest: 64.0\n",
      "[[16.  8.  4. 32.]\n",
      " [ 2. 32. 64.  8.]\n",
      " [ 8. 16. 32.  4.]\n",
      " [ 4. 32.  8.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 317\n",
      "Total Reward: 125\n",
      "Total episodes 139\n",
      "Eps_threshold: 0.08513638607703869\n",
      "Loss ep: 0.039496854054842066\n",
      "Score: 1336\n",
      "Highest: 128.0\n",
      "[[  4.   8.   2.   8.]\n",
      " [  2. 128.  32.  16.]\n",
      " [ 16.  64.   8.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 318\n",
      "Total Reward: 117\n",
      "Total episodes 131\n",
      "Eps_threshold: 0.08464585100436094\n",
      "Loss ep: 0.037333037107045414\n",
      "Score: 1284\n",
      "Highest: 128.0\n",
      "[[  2.  64.   2.   4.]\n",
      " [  8.   4.  32.   8.]\n",
      " [  4. 128.  16.   2.]\n",
      " [  2.   8.   4.   8.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 319\n",
      "Total Reward: 129\n",
      "Total episodes 143\n",
      "Eps_threshold: 0.08411403667155744\n",
      "Loss ep: 0.03835762797535716\n",
      "Score: 1368\n",
      "Highest: 128.0\n",
      "[[  2.   8.  16.   4.]\n",
      " [  4.  32. 128.  64.]\n",
      " [  8.  16.   8.  16.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 320\n",
      "Total Reward: 97\n",
      "Total episodes 111\n",
      "Eps_threshold: 0.08370384310808399\n",
      "Loss ep: 0.037775765668164506\n",
      "Score: 1028\n",
      "Highest: 128.0\n",
      "[[  2.   8.   2.  16.]\n",
      " [  8. 128.   4.   2.]\n",
      " [ 16.  32.   2.   8.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 321\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.08316044771174269\n",
      "Loss ep: 0.03720866667257773\n",
      "Score: 1496\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   8.]\n",
      " [ 64.  16.  64.   2.]\n",
      " [  4.   8. 128.   4.]\n",
      " [  8.   2.   4.  16.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 322\n",
      "Total Reward: 121\n",
      "Total episodes 135\n",
      "Eps_threshold: 0.08266827763241302\n",
      "Loss ep: 0.03775493480541088\n",
      "Score: 1288\n",
      "Highest: 128.0\n",
      "[[  2.  16.   8.   2.]\n",
      " [  4.   2. 128.   4.]\n",
      " [  8.  64.   8.  16.]\n",
      " [ 16.   2.  16.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 323\n",
      "Total Reward: 149\n",
      "Total episodes 163\n",
      "Eps_threshold: 0.08207843803096622\n",
      "Loss ep: 0.03751667584378295\n",
      "Score: 1580\n",
      "Highest: 128.0\n",
      "[[ 16.   2.   8.   2.]\n",
      " [  4.   8. 128.  16.]\n",
      " [  2.  64.  16.  64.]\n",
      " [  8.   2.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 324\n",
      "Total Reward: 67\n",
      "Total episodes 81\n",
      "Eps_threshold: 0.08178711069300812\n",
      "Loss ep: 0.0369474681807153\n",
      "Score: 628\n",
      "Highest: 64.0\n",
      "[[32.  4.  2.  8.]\n",
      " [ 4.  2. 32.  4.]\n",
      " [ 2.  8. 16. 64.]\n",
      " [ 4.  2.  4.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 325\n",
      "Total Reward: 160\n",
      "Total episodes 174\n",
      "Eps_threshold: 0.08116527175161815\n",
      "Loss ep: 0.0383623578082556\n",
      "Score: 1672\n",
      "Highest: 128.0\n",
      "[[  4.   8.  16.   4.]\n",
      " [ 32. 128.  32.   2.]\n",
      " [  8.  16.  64.  32.]\n",
      " [  2.   4.  32.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 326\n",
      "Total Reward: 228\n",
      "Total episodes 242\n",
      "Eps_threshold: 0.08030936066828079\n",
      "Loss ep: 0.03727584239865137\n",
      "Score: 2932\n",
      "Highest: 256.0\n",
      "[[  8.  16.   4.  16.]\n",
      " [ 16. 256.  32.   4.]\n",
      " [ 32. 128.  16.   2.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 327\n",
      "Total Reward: 173\n",
      "Total episodes 187\n",
      "Eps_threshold: 0.07965503189993882\n",
      "Loss ep: 0.03803685132194968\n",
      "Score: 2028\n",
      "Highest: 128.0\n",
      "[[  4.  16.   2.   4.]\n",
      " [  2. 128.   4.  16.]\n",
      " [ 32.   4.  64. 128.]\n",
      " [  4.   2.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 32\n",
      "---------------------------\n",
      "Episode: 328\n",
      "Total Reward: 56\n",
      "Total episodes 70\n",
      "Eps_threshold: 0.07941166542805136\n",
      "Loss ep: 0.03760075569152832\n",
      "Score: 504\n",
      "Highest: 64.0\n",
      "[[ 2.  8.  4.  2.]\n",
      " [ 4.  2.  8.  4.]\n",
      " [ 8. 32.  2.  8.]\n",
      " [ 4. 64.  4.  2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 329\n",
      "Total Reward: 230\n",
      "Total episodes 244\n",
      "Eps_threshold: 0.07856998778304616\n",
      "Loss ep: 0.037449219187752146\n",
      "Score: 2920\n",
      "Highest: 256.0\n",
      "[[  2.  32.   8.   2.]\n",
      " [  4.  16. 128.  16.]\n",
      " [ 32.   4. 256.   4.]\n",
      " [  4.   2.  16.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 330\n",
      "Total Reward: 69\n",
      "Total episodes 83\n",
      "Eps_threshold: 0.07828601199107918\n",
      "Loss ep: 0.038606939545596936\n",
      "Score: 640\n",
      "Highest: 64.0\n",
      "[[ 8.  4.  2.  4.]\n",
      " [ 4. 32.  4. 16.]\n",
      " [ 2.  8. 64. 32.]\n",
      " [ 8.  2.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 331\n",
      "Total Reward: 83\n",
      "Total episodes 97\n",
      "Eps_threshold: 0.07795562666496209\n",
      "Loss ep: 0.03640222057853777\n",
      "Score: 784\n",
      "Highest: 64.0\n",
      "[[ 4.  2.  8.  2.]\n",
      " [16.  8. 64.  8.]\n",
      " [ 2. 16.  8. 64.]\n",
      " [ 4.  8.  4.  2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 332\n",
      "Total Reward: 106\n",
      "Total episodes 120\n",
      "Eps_threshold: 0.07754911366351494\n",
      "Loss ep: 0.03775818347930908\n",
      "Score: 1112\n",
      "Highest: 128.0\n",
      "[[  4.   8.   4.   2.]\n",
      " [  8.  16.  32.   8.]\n",
      " [  4.   2.   8. 128.]\n",
      " [  2.   4.  32.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 333\n",
      "Total Reward: 150\n",
      "Total episodes 164\n",
      "Eps_threshold: 0.07699747573797654\n",
      "Loss ep: 0.03481936454772949\n",
      "Score: 1648\n",
      "Highest: 128.0\n",
      "[[  2.   4.  32.   2.]\n",
      " [ 64.  32.   4. 128.]\n",
      " [  2.   4.  64.   8.]\n",
      " [  4.   2.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 334\n",
      "Total Reward: 168\n",
      "Total episodes 182\n",
      "Eps_threshold: 0.07639056434379307\n",
      "Loss ep: 0.03615541772528009\n",
      "Score: 2208\n",
      "Highest: 256.0\n",
      "[[  4.  64.   8.  16.]\n",
      " [  2.   8.   2.   8.]\n",
      " [  4.  16. 256.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 335\n",
      "Total Reward: 194\n",
      "Total episodes 208\n",
      "Eps_threshold: 0.07570368046190565\n",
      "Loss ep: 0.037546359575711764\n",
      "Score: 2420\n",
      "Highest: 256.0\n",
      "[[  8.   2.   4. 256.]\n",
      " [ 32.  64.   8.   2.]\n",
      " [  4.   2.  16.   4.]\n",
      " [  2.  32.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 336\n",
      "Total Reward: 248\n",
      "Total episodes 262\n",
      "Eps_threshold: 0.07484857541459436\n",
      "Loss ep: 0.0365582640844447\n",
      "Score: 3176\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.  16.]\n",
      " [  4. 256.  32.   4.]\n",
      " [ 32.   4.  16.  64.]\n",
      " [  8. 128.   4.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 337\n",
      "Total Reward: 213\n",
      "Total episodes 227\n",
      "Eps_threshold: 0.07411670530328168\n",
      "Loss ep: 0.036370037935903946\n",
      "Score: 2824\n",
      "Highest: 256.0\n",
      "[[  2.   8.   2.  32.]\n",
      " [  8.  16. 128.   4.]\n",
      " [  4.   8.  32. 256.]\n",
      " [  2.   4.   2.   8.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 338\n",
      "Total Reward: 186\n",
      "Total episodes 200\n",
      "Eps_threshold: 0.07347873342605843\n",
      "Loss ep: 0.036748223304748535\n",
      "Score: 2364\n",
      "Highest: 256.0\n",
      "[[  4.   2.   8.  16.]\n",
      " [  2.   4.  16.   8.]\n",
      " [ 16.  64. 256.   4.]\n",
      " [  4.   8.   4.  32.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 339\n",
      "Total Reward: 189\n",
      "Total episodes 203\n",
      "Eps_threshold: 0.07283768311565027\n",
      "Loss ep: 0.03555202953921163\n",
      "Score: 2404\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  4.   8.  32.   4.]\n",
      " [  8. 256.   2.  64.]\n",
      " [  4.  32.   4.  16.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 340\n",
      "Total Reward: 220\n",
      "Total episodes 234\n",
      "Eps_threshold: 0.07210676642375789\n",
      "Loss ep: 0.035397415487175315\n",
      "Score: 2764\n",
      "Highest: 256.0\n",
      "[[  8.   2.  16.   2.]\n",
      " [ 16.  32.   8.   4.]\n",
      " [  8.  64. 256.  32.]\n",
      " [  2.  16.  64.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 341\n",
      "Total Reward: 171\n",
      "Total episodes 185\n",
      "Eps_threshold: 0.07153492766591679\n",
      "Loss ep: 0.03644273345534866\n",
      "Score: 2280\n",
      "Highest: 256.0\n",
      "[[  4.   2.  32.   4.]\n",
      " [  2.   4.  64.   8.]\n",
      " [  4.  16. 256.   4.]\n",
      " [  2.   8.  16.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 342\n",
      "Total Reward: 192\n",
      "Total episodes 206\n",
      "Eps_threshold: 0.07090437085318127\n",
      "Loss ep: 0.0353615538587848\n",
      "Score: 2404\n",
      "Highest: 256.0\n",
      "[[  2.  16.   2.  16.]\n",
      " [  4.  64.  16.   2.]\n",
      " [  8.  16. 256.   4.]\n",
      " [  2.  32.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 343\n",
      "Total Reward: 250\n",
      "Total episodes 264\n",
      "Eps_threshold: 0.07010571587719736\n",
      "Loss ep: 0.03558166821797689\n",
      "Score: 3132\n",
      "Highest: 256.0\n",
      "[[ 16.   4.   8.   4.]\n",
      " [  4.  32.  64. 128.]\n",
      " [ 16.   4. 256.  16.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 344\n",
      "Total Reward: 142\n",
      "Total episodes 156\n",
      "Eps_threshold: 0.06963871496460654\n",
      "Loss ep: 0.03571859078529554\n",
      "Score: 1548\n",
      "Highest: 128.0\n",
      "[[  4.  64.   8.   4.]\n",
      " [ 16.   2.  16.   8.]\n",
      " [  2.  64. 128.   4.]\n",
      " [  8.   2.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 345\n",
      "Total Reward: 141\n",
      "Total episodes 155\n",
      "Eps_threshold: 0.06917830133092519\n",
      "Loss ep: 0.035029580516199914\n",
      "Score: 1508\n",
      "Highest: 128.0\n",
      "[[  4.   2.   4.   2.]\n",
      " [  8. 128.  16.   8.]\n",
      " [  4.  32.  64.  32.]\n",
      " [  2.   4.  32.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 346\n",
      "Total Reward: 135\n",
      "Total episodes 149\n",
      "Eps_threshold: 0.06873906118712077\n",
      "Loss ep: 0.034490246100713745\n",
      "Score: 1440\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  8.  16.  64.   4.]\n",
      " [ 32. 128.   8.  32.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 347\n",
      "Total Reward: 130\n",
      "Total episodes 144\n",
      "Eps_threshold: 0.06831765881556776\n",
      "Loss ep: 0.0356637438138326\n",
      "Score: 1380\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [ 32.   2.   4.   2.]\n",
      " [  2.   8. 128.   4.]\n",
      " [ 64.  32.   8.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 348\n",
      "Total Reward: 124\n",
      "Total episodes 138\n",
      "Eps_threshold: 0.06791665203412944\n",
      "Loss ep: 0.03479208116946013\n",
      "Score: 1440\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   8.]\n",
      " [  4. 128.   4.   2.]\n",
      " [ 16.   8.  64.   4.]\n",
      " [  8.  64.   8.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 349\n",
      "Total Reward: 168\n",
      "Total episodes 182\n",
      "Eps_threshold: 0.06739200128206317\n",
      "Loss ep: 0.03519533230708195\n",
      "Score: 1768\n",
      "Highest: 128.0\n",
      "[[  2.  32.  16.   2.]\n",
      " [  4.   8.  64.   8.]\n",
      " [ 16.  32.   8.  64.]\n",
      " [128.   4.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 350\n",
      "Total Reward: 119\n",
      "Total episodes 133\n",
      "Eps_threshold: 0.06701161067412646\n",
      "Loss ep: 0.034884624911430184\n",
      "Score: 1312\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [ 64. 128.  16.   8.]\n",
      " [  8.   2.   8.   4.]\n",
      " [  2.   4.  16.  32.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 351\n",
      "Total Reward: 123\n",
      "Total episodes 137\n",
      "Eps_threshold: 0.06662241565577895\n",
      "Loss ep: 0.035240549240669196\n",
      "Score: 1340\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  8. 128.   2.  32.]\n",
      " [ 16.   2.  64.   8.]\n",
      " [  2.   4.  16.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 352\n",
      "Total Reward: 232\n",
      "Total episodes 246\n",
      "Eps_threshold: 0.06593022563858225\n",
      "Loss ep: 0.03445556687145698\n",
      "Score: 3012\n",
      "Highest: 256.0\n",
      "[[  4. 128.   8.   4.]\n",
      " [ 64.  16.   2.  16.]\n",
      " [ 16. 256.   8.   4.]\n",
      " [  4.   2.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 353\n",
      "Total Reward: 252\n",
      "Total episodes 266\n",
      "Eps_threshold: 0.065191278528535\n",
      "Loss ep: 0.03550977993728523\n",
      "Score: 3184\n",
      "Highest: 256.0\n",
      "[[  4.  32.   2.   4.]\n",
      " [  8.   4.  16.  64.]\n",
      " [256. 128.  32.   4.]\n",
      " [  2.   4.  16.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 354\n",
      "Total Reward: 130\n",
      "Total episodes 144\n",
      "Eps_threshold: 0.06479532845390107\n",
      "Loss ep: 0.03511009944809808\n",
      "Score: 1376\n",
      "Highest: 128.0\n",
      "[[  2.   4.  32.  16.]\n",
      " [ 16.   8.  64.   8.]\n",
      " [  8. 128.  16.   4.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 355\n",
      "Total Reward: 126\n",
      "Total episodes 140\n",
      "Eps_threshold: 0.06441310051327878\n",
      "Loss ep: 0.03477888107299805\n",
      "Score: 1336\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [  4.  64.   8.  32.]\n",
      " [ 16.   8. 128.   8.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 356\n",
      "Total Reward: 203\n",
      "Total episodes 217\n",
      "Eps_threshold: 0.063825909643631\n",
      "Loss ep: 0.0349997177651401\n",
      "Score: 2588\n",
      "Highest: 256.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  4.  32.  64.   4.]\n",
      " [  8. 256.   4.   8.]\n",
      " [  2.  16.  64.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 357\n",
      "Total Reward: 123\n",
      "Total episodes 137\n",
      "Eps_threshold: 0.06345846210717977\n",
      "Loss ep: 0.03492888568961707\n",
      "Score: 1328\n",
      "Highest: 128.0\n",
      "[[  8.   2.   8.   4.]\n",
      " [  2.  64.  16.   2.]\n",
      " [ 16. 128.  32.   8.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 358\n",
      "Total Reward: 215\n",
      "Total episodes 229\n",
      "Eps_threshold: 0.06284985364863739\n",
      "Loss ep: 0.03546091354570014\n",
      "Score: 2800\n",
      "Highest: 256.0\n",
      "[[ 32.   2.   8.   2.]\n",
      " [  2.  16. 128.  16.]\n",
      " [  8. 256.  16.   8.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 359\n",
      "Total Reward: 154\n",
      "Total episodes 168\n",
      "Eps_threshold: 0.062407774211050746\n",
      "Loss ep: 0.034303500538780576\n",
      "Score: 1664\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  4.  32.  16.   2.]\n",
      " [ 16.  64. 128.  16.]\n",
      " [  4.   8.  64.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 360\n",
      "Total Reward: 166\n",
      "Total episodes 180\n",
      "Eps_threshold: 0.061938220404763475\n",
      "Loss ep: 0.03473413785298665\n",
      "Score: 1948\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   8.]\n",
      " [  4. 128.  64. 128.]\n",
      " [ 16.   8.   4.   8.]\n",
      " [  2.   4.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 361\n",
      "Total Reward: 130\n",
      "Total episodes 144\n",
      "Eps_threshold: 0.061565608231356664\n",
      "Loss ep: 0.033852994441986084\n",
      "Score: 1404\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  4.  32.  16.   8.]\n",
      " [  2.  64.  32. 128.]\n",
      " [  4.   8.   4.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 362\n",
      "Total Reward: 200\n",
      "Total episodes 214\n",
      "Eps_threshold: 0.06101679759627959\n",
      "Loss ep: 0.03410068850650966\n",
      "Score: 2488\n",
      "Highest: 256.0\n",
      "[[  2.   8.  16.   2.]\n",
      " [ 32. 256.   2.   4.]\n",
      " [  4.   8.  32.  16.]\n",
      " [  2.  16.  64.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 363\n",
      "Total Reward: 87\n",
      "Total episodes 101\n",
      "Eps_threshold: 0.06075981220268449\n",
      "Loss ep: 0.03434400983376078\n",
      "Score: 784\n",
      "Highest: 64.0\n",
      "[[32.  4.  8.  2.]\n",
      " [ 8. 16. 64. 32.]\n",
      " [ 4. 32.  8.  4.]\n",
      " [ 2.  8.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 364\n",
      "Total Reward: 71\n",
      "Total episodes 85\n",
      "Eps_threshold: 0.0605445407766317\n",
      "Loss ep: 0.03285019537981819\n",
      "Score: 648\n",
      "Highest: 64.0\n",
      "[[ 4. 32.  4.  2.]\n",
      " [ 8.  2. 64.  8.]\n",
      " [16.  4. 32.  4.]\n",
      " [ 2.  8.  4.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 365\n",
      "Total Reward: 126\n",
      "Total episodes 140\n",
      "Eps_threshold: 0.06019196444803087\n",
      "Loss ep: 0.03459534985678536\n",
      "Score: 1344\n",
      "Highest: 128.0\n",
      "[[  4.   8.   2.   8.]\n",
      " [  8. 128.  16.   2.]\n",
      " [ 16.  32.  64.   8.]\n",
      " [  2.   8.   2.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 366\n",
      "Total Reward: 123\n",
      "Total episodes 137\n",
      "Eps_threshold: 0.05984932437360978\n",
      "Loss ep: 0.033951860274711664\n",
      "Score: 1340\n",
      "Highest: 128.0\n",
      "[[  4.   2.   4.   2.]\n",
      " [  2.   8.   2.  16.]\n",
      " [  8.  64.  16.  32.]\n",
      " [ 16.   2. 128.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 367\n",
      "Total Reward: 76\n",
      "Total episodes 90\n",
      "Eps_threshold: 0.05962550638210215\n",
      "Loss ep: 0.03465749952528212\n",
      "Score: 640\n",
      "Highest: 64.0\n",
      "[[ 4.  8.  4.  2.]\n",
      " [ 8. 32. 16.  4.]\n",
      " [64.  4.  8. 16.]\n",
      " [ 4.  2. 16.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 368\n",
      "Total Reward: 133\n",
      "Total episodes 147\n",
      "Eps_threshold: 0.05926209607908359\n",
      "Loss ep: 0.03408381403708945\n",
      "Score: 1432\n",
      "Highest: 128.0\n",
      "[[  4.  16.   8.   4.]\n",
      " [  2.  32.  16.   8.]\n",
      " [  8.  64. 128.   4.]\n",
      " [  2.   4.  32.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 369\n",
      "Total Reward: 166\n",
      "Total episodes 180\n",
      "Eps_threshold: 0.05882072635736119\n",
      "Loss ep: 0.033902430534362794\n",
      "Score: 1984\n",
      "Highest: 128.0\n",
      "[[  4.   2.   4.   2.]\n",
      " [  2.   4. 128.   4.]\n",
      " [ 64.   2.  32.   8.]\n",
      " [  4.  16. 128.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 370\n",
      "Total Reward: 153\n",
      "Total episodes 167\n",
      "Eps_threshold: 0.05841477051659768\n",
      "Loss ep: 0.0342583056695447\n",
      "Score: 1652\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  4. 128.  16.  64.]\n",
      " [  2.   8.  64.   4.]\n",
      " [ 16.   2.   4.  32.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 371\n",
      "Total Reward: 151\n",
      "Total episodes 165\n",
      "Eps_threshold: 0.05801699175338285\n",
      "Loss ep: 0.03430307272708777\n",
      "Score: 1572\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [ 32.  64.  32.   8.]\n",
      " [  8.  16. 128.  16.]\n",
      " [  2.  32.   8.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 372\n",
      "Total Reward: 237\n",
      "Total episodes 251\n",
      "Eps_threshold: 0.05741814413565825\n",
      "Loss ep: 0.03434998105721645\n",
      "Score: 3056\n",
      "Highest: 256.0\n",
      "[[  2.   4.  16.   2.]\n",
      " [ 64.  32. 128.   4.]\n",
      " [  8. 256.  16.   2.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 373\n",
      "Total Reward: 195\n",
      "Total episodes 209\n",
      "Eps_threshold: 0.05692520462423191\n",
      "Loss ep: 0.03551280555542576\n",
      "Score: 2464\n",
      "Highest: 256.0\n",
      "[[  4.   2.  32.  16.]\n",
      " [ 16.   4. 256.   2.]\n",
      " [  8.  32.  16.   8.]\n",
      " [  4.  64.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 374\n",
      "Total Reward: 240\n",
      "Total episodes 254\n",
      "Eps_threshold: 0.05633302283923417\n",
      "Loss ep: 0.03425047341294176\n",
      "Score: 2956\n",
      "Highest: 256.0\n",
      "[[ 16.   2.   8.   2.]\n",
      " [ 64.   8.  64.   8.]\n",
      " [ 16. 256.  32.   2.]\n",
      " [  4.  64.   8.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 375\n",
      "Total Reward: 153\n",
      "Total episodes 167\n",
      "Eps_threshold: 0.055947752839272766\n",
      "Loss ep: 0.033860180906192985\n",
      "Score: 2080\n",
      "Highest: 256.0\n",
      "[[  4.  16.  32.  16.]\n",
      " [  8.   4. 256.   8.]\n",
      " [  4.   2.  32.   2.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 376\n",
      "Total Reward: 166\n",
      "Total episodes 180\n",
      "Eps_threshold: 0.05553607837759573\n",
      "Loss ep: 0.033689726723564996\n",
      "Score: 1772\n",
      "Highest: 128.0\n",
      "[[  4.   2.  32.   2.]\n",
      " [  8. 128.   2.  16.]\n",
      " [ 16.  64.  32.  64.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 377\n",
      "Total Reward: 254\n",
      "Total episodes 268\n",
      "Eps_threshold: 0.05492996495670592\n",
      "Loss ep: 0.03454137915995584\n",
      "Score: 3260\n",
      "Highest: 256.0\n",
      "[[  2.   4.  16.   2.]\n",
      " [  4. 256.  64.   8.]\n",
      " [  2. 128.   8.  16.]\n",
      " [  8.  64.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 378\n",
      "Total Reward: 83\n",
      "Total episodes 97\n",
      "Eps_threshold: 0.05471258220595178\n",
      "Loss ep: 0.03428484729884826\n",
      "Score: 732\n",
      "Highest: 64.0\n",
      "[[ 4.  2. 16.  4.]\n",
      " [16. 32.  4.  8.]\n",
      " [ 4. 64. 16.  2.]\n",
      " [ 2. 32.  8.  4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 379\n",
      "Total Reward: 139\n",
      "Total episodes 153\n",
      "Eps_threshold: 0.0543718359682108\n",
      "Loss ep: 0.03316494062835095\n",
      "Score: 1476\n",
      "Highest: 128.0\n",
      "[[  2.   8.  32.   8.]\n",
      " [ 16.  64. 128.   2.]\n",
      " [  4.  32.  16.   4.]\n",
      " [  2.  16.   4.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 380\n",
      "Total Reward: 127\n",
      "Total episodes 141\n",
      "Eps_threshold: 0.05406011463344968\n",
      "Loss ep: 0.03337088375226826\n",
      "Score: 1384\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  4.   8.  16.   4.]\n",
      " [ 64. 128.   4.  32.]\n",
      " [  2.   4.  32.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 381\n",
      "Total Reward: 135\n",
      "Total episodes 149\n",
      "Eps_threshold: 0.053733086471904216\n",
      "Loss ep: 0.03518802847638226\n",
      "Score: 1456\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  4.  16.  32.  64.]\n",
      " [  8. 128.  16.   2.]\n",
      " [  2.  16.  32.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 382\n",
      "Total Reward: 217\n",
      "Total episodes 231\n",
      "Eps_threshold: 0.05323087517639308\n",
      "Loss ep: 0.03319501670408043\n",
      "Score: 2680\n",
      "Highest: 256.0\n",
      "[[  2.   4.  16.   2.]\n",
      " [  4.  32.  64.   4.]\n",
      " [  8.  64. 256.  16.]\n",
      " [  4.  16.   2.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 383\n",
      "Total Reward: 123\n",
      "Total episodes 137\n",
      "Eps_threshold: 0.05293575561989384\n",
      "Loss ep: 0.03325781160897582\n",
      "Score: 1328\n",
      "Highest: 128.0\n",
      "[[  2.   4.  32.   2.]\n",
      " [  4. 128.   8.   4.]\n",
      " [  8.  64.  16.   8.]\n",
      " [  2.  16.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 384\n",
      "Total Reward: 67\n",
      "Total episodes 81\n",
      "Eps_threshold: 0.0527622174616087\n",
      "Loss ep: 0.033891766159622756\n",
      "Score: 596\n",
      "Highest: 64.0\n",
      "[[ 2. 16.  4.  2.]\n",
      " [ 4. 32. 16.  4.]\n",
      " [ 2.  4.  8. 16.]\n",
      " [64.  2.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 385\n",
      "Total Reward: 143\n",
      "Total episodes 157\n",
      "Eps_threshold: 0.052427848171054704\n",
      "Loss ep: 0.03276643935282519\n",
      "Score: 1504\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  8.   2.  32.   4.]\n",
      " [ 32. 128.   8.  64.]\n",
      " [  2.   8.  32.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 386\n",
      "Total Reward: 225\n",
      "Total episodes 239\n",
      "Eps_threshold: 0.05192385275565379\n",
      "Loss ep: 0.03259845358557282\n",
      "Score: 2884\n",
      "Highest: 256.0\n",
      "[[ 32.   2.   4.   2.]\n",
      " [  2. 256.   8.  16.]\n",
      " [  8.  16.  32.   4.]\n",
      " [  4. 128.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 387\n",
      "Total Reward: 218\n",
      "Total episodes 232\n",
      "Eps_threshold: 0.051440345825594765\n",
      "Loss ep: 0.0332502661080196\n",
      "Score: 2676\n",
      "Highest: 256.0\n",
      "[[  8.  64.   8.   4.]\n",
      " [ 16.   4.  16.  32.]\n",
      " [  8.  64. 256.   8.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 388\n",
      "Total Reward: 152\n",
      "Total episodes 166\n",
      "Eps_threshold: 0.051097814426960084\n",
      "Loss ep: 0.03252256060221109\n",
      "Score: 1636\n",
      "Highest: 128.0\n",
      "[[  4.   2.   4.  64.]\n",
      " [  2.  16.   8.   4.]\n",
      " [  8.  64. 128.  32.]\n",
      " [ 16.   8.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 389\n",
      "Total Reward: 191\n",
      "Total episodes 205\n",
      "Eps_threshold: 0.050678713391202446\n",
      "Loss ep: 0.03272736246992902\n",
      "Score: 2416\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  8.  64.  32.   4.]\n",
      " [  4.  32. 256.   8.]\n",
      " [  2.  16.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 390\n",
      "Total Reward: 160\n",
      "Total episodes 174\n",
      "Eps_threshold: 0.05032634361579157\n",
      "Loss ep: 0.033567231276939655\n",
      "Score: 1708\n",
      "Highest: 128.0\n",
      "[[  2.   8.  16.  32.]\n",
      " [  8.   4.  64.  16.]\n",
      " [ 64. 128.  16.   2.]\n",
      " [  2.   8.   2.  16.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 391\n",
      "Total Reward: 246\n",
      "Total episodes 260\n",
      "Eps_threshold: 0.04980549400652452\n",
      "Loss ep: 0.03317279448876014\n",
      "Score: 3148\n",
      "Highest: 256.0\n",
      "[[  8.  16.   8.   4.]\n",
      " [  2.  32.  64.  32.]\n",
      " [  4. 256.   8.   4.]\n",
      " [  2.   4. 128.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 392\n",
      "Total Reward: 173\n",
      "Total episodes 187\n",
      "Eps_threshold: 0.04943504717527802\n",
      "Loss ep: 0.03255891799926758\n",
      "Score: 2244\n",
      "Highest: 256.0\n",
      "[[  2.   8.   2.  16.]\n",
      " [  4. 256.   8.   2.]\n",
      " [ 16.   4.  16.  64.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 393\n",
      "Total Reward: 232\n",
      "Total episodes 246\n",
      "Eps_threshold: 0.048952966966119345\n",
      "Loss ep: 0.033045268640285584\n",
      "Score: 3076\n",
      "Highest: 256.0\n",
      "[[  4.  32.   8.   4.]\n",
      " [  2. 128. 256.   8.]\n",
      " [  8.  64.  32.   2.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 394\n",
      "Total Reward: 120\n",
      "Total episodes 134\n",
      "Eps_threshold: 0.04869285443745424\n",
      "Loss ep: 0.03211587934351679\n",
      "Score: 1276\n",
      "Highest: 128.0\n",
      "[[  2.   4.  32.   4.]\n",
      " [  4.  32.   8.   2.]\n",
      " [ 32. 128.  32.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 395\n",
      "Total Reward: 196\n",
      "Total episodes 210\n",
      "Eps_threshold: 0.048288704963714575\n",
      "Loss ep: 0.0330571038382394\n",
      "Score: 2452\n",
      "Highest: 256.0\n",
      "[[ 16.   2.  32.   2.]\n",
      " [  8.   4. 256.   8.]\n",
      " [  2.  16.  32.  64.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 396\n",
      "Total Reward: 138\n",
      "Total episodes 152\n",
      "Eps_threshold: 0.04799881378780033\n",
      "Loss ep: 0.03420080009259676\n",
      "Score: 1680\n",
      "Highest: 128.0\n",
      "[[  2.  32. 128.   2.]\n",
      " [128.   8.   4.   8.]\n",
      " [  4.   2.  16.   2.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 397\n",
      "Total Reward: 137\n",
      "Total episodes 151\n",
      "Eps_threshold: 0.04771300303694625\n",
      "Loss ep: 0.03363948468340943\n",
      "Score: 1556\n",
      "Highest: 128.0\n",
      "[[ 64.   4.   8.   4.]\n",
      " [  4.   8.  64.   8.]\n",
      " [  2.  32. 128.   4.]\n",
      " [  4.   2.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 398\n",
      "Total Reward: 137\n",
      "Total episodes 151\n",
      "Eps_threshold: 0.04742934203175947\n",
      "Loss ep: 0.0328881156365603\n",
      "Score: 1468\n",
      "Highest: 128.0\n",
      "[[  8. 128.   8.   2.]\n",
      " [ 16.  64.  32.   4.]\n",
      " [ 32.  16.   4.   2.]\n",
      " [  8.   4.   2.  16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 399\n",
      "Total Reward: 240\n",
      "Total episodes 254\n",
      "Eps_threshold: 0.04695699513944113\n",
      "Loss ep: 0.033039690002681706\n",
      "Score: 3080\n",
      "Highest: 256.0\n",
      "[[  8. 256.   8.  16.]\n",
      " [  2.   8. 128.   2.]\n",
      " [  4.  64.  32.  16.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 400\n",
      "Total Reward: 211\n",
      "Total episodes 225\n",
      "Eps_threshold: 0.046543558883513324\n",
      "Loss ep: 0.03300763448079427\n",
      "Score: 2644\n",
      "Highest: 256.0\n",
      "[[  2.  16.  32.   4.]\n",
      " [  4. 256.   8.  64.]\n",
      " [  2.  16.  64.   8.]\n",
      " [  8.   2.   8.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Update target_net\n",
      "Episode: 401\n",
      "Total Reward: 244\n",
      "Total episodes 258\n",
      "Eps_threshold: 0.046075174548180664\n",
      "Loss ep: 0.04638005781543347\n",
      "Score: 3196\n",
      "Highest: 256.0\n",
      "[[  8.  64.   2.   4.]\n",
      " [  2.   4. 128.   2.]\n",
      " [  4. 256.  64.   4.]\n",
      " [  2.   4.   8.  16.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 402\n",
      "Total Reward: 208\n",
      "Total episodes 222\n",
      "Eps_threshold: 0.04567695432167075\n",
      "Loss ep: 0.04302839330724768\n",
      "Score: 2736\n",
      "Highest: 256.0\n",
      "[[  4.   8.  16.   2.]\n",
      " [  8.   2. 256.   4.]\n",
      " [  2. 128.   8.  32.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 403\n",
      "Total Reward: 139\n",
      "Total episodes 153\n",
      "Eps_threshold: 0.04540506691639475\n",
      "Loss ep: 0.042659616158678644\n",
      "Score: 1428\n",
      "Highest: 128.0\n",
      "[[  2.   8.  16.   4.]\n",
      " [ 16.  32. 128.   8.]\n",
      " [  8.  64.   4.  16.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 404\n",
      "Total Reward: 179\n",
      "Total episodes 193\n",
      "Eps_threshold: 0.04506505123490318\n",
      "Loss ep: 0.04194969216776635\n",
      "Score: 2424\n",
      "Highest: 256.0\n",
      "[[  2.   4.  64.   2.]\n",
      " [  4.   8.   2.   8.]\n",
      " [  8. 256.   4.   2.]\n",
      " [  2.   4.  16.  64.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 405\n",
      "Total Reward: 147\n",
      "Total episodes 161\n",
      "Eps_threshold: 0.04478391068140594\n",
      "Loss ep: 0.04053737213892966\n",
      "Score: 1552\n",
      "Highest: 128.0\n",
      "[[  2.  16.   2.   8.]\n",
      " [ 64.   4.  16.   2.]\n",
      " [  8.  64. 128.   8.]\n",
      " [  4.   2.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 406\n",
      "Total Reward: 165\n",
      "Total episodes 179\n",
      "Eps_threshold: 0.044473983672994585\n",
      "Loss ep: 0.04013773848890592\n",
      "Score: 1752\n",
      "Highest: 128.0\n",
      "[[  4.  64.   4.   2.]\n",
      " [ 64.  16.  32.   8.]\n",
      " [  4.  32. 128.   2.]\n",
      " [ 16.   4.   2.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 407\n",
      "Total Reward: 145\n",
      "Total episodes 159\n",
      "Eps_threshold: 0.04420100204253398\n",
      "Loss ep: 0.04036764228868785\n",
      "Score: 1596\n",
      "Highest: 128.0\n",
      "[[  4.   8.  16.   8.]\n",
      " [  8.  64. 128.   2.]\n",
      " [  4.  32.   8.  64.]\n",
      " [  2.   4.   2.   8.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 408\n",
      "Total Reward: 119\n",
      "Total episodes 133\n",
      "Eps_threshold: 0.043974319932337726\n",
      "Loss ep: 0.03863156827768885\n",
      "Score: 1304\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  4.  16. 128.   8.]\n",
      " [  2.  64.   4.  16.]\n",
      " [  4.   2.  32.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 409\n",
      "Total Reward: 240\n",
      "Total episodes 254\n",
      "Eps_threshold: 0.043545574366224055\n",
      "Loss ep: 0.0394454565573865\n",
      "Score: 3056\n",
      "Highest: 256.0\n",
      "[[  4.  16.   4.   2.]\n",
      " [  8.   4.  32.   8.]\n",
      " [ 64. 256. 128.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 410\n",
      "Total Reward: 121\n",
      "Total episodes 135\n",
      "Eps_threshold: 0.04331990423279301\n",
      "Loss ep: 0.03849013646443685\n",
      "Score: 1312\n",
      "Highest: 128.0\n",
      "[[  4.  16.   2.   4.]\n",
      " [  8. 128.   4.  32.]\n",
      " [  2.  16.  64.   8.]\n",
      " [  4.   2.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 411\n",
      "Total Reward: 135\n",
      "Total episodes 149\n",
      "Eps_threshold: 0.04307259332326014\n",
      "Loss ep: 0.03771280762333198\n",
      "Score: 1472\n",
      "Highest: 128.0\n",
      "[[  2. 128.  32.   8.]\n",
      " [  4.   8.   2.  32.]\n",
      " [  8.  32.  64.   2.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 412\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.04282875943076456\n",
      "Loss ep: 0.03813894052763243\n",
      "Score: 1436\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  8.  16.  32.  16.]\n",
      " [  4. 128.  64.   4.]\n",
      " [  2.   4.   8.  32.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 413\n",
      "Total Reward: 139\n",
      "Total episodes 153\n",
      "Eps_threshold: 0.042578577586776856\n",
      "Loss ep: 0.038502605911952995\n",
      "Score: 1500\n",
      "Highest: 128.0\n",
      "[[  2.  16.   2.   4.]\n",
      " [  8.  32. 128.   2.]\n",
      " [  4.  64.   8.  32.]\n",
      " [  2.  32.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 414\n",
      "Total Reward: 145\n",
      "Total episodes 159\n",
      "Eps_threshold: 0.0423206046959127\n",
      "Loss ep: 0.03620748999733595\n",
      "Score: 1600\n",
      "Highest: 128.0\n",
      "[[  4.  16.   4.   2.]\n",
      " [  2.  32. 128.   4.]\n",
      " [  4.  16.  64.   2.]\n",
      " [ 64.   4.   8.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 415\n",
      "Total Reward: 184\n",
      "Total episodes 198\n",
      "Eps_threshold: 0.042002209366791915\n",
      "Loss ep: 0.0369913602116132\n",
      "Score: 2336\n",
      "Highest: 256.0\n",
      "[[  4.  32.   4.   2.]\n",
      " [  8.  64.   8.   4.]\n",
      " [  4. 256.  16.   8.]\n",
      " [  2.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 416\n",
      "Total Reward: 129\n",
      "Total episodes 143\n",
      "Eps_threshold: 0.04177420964016754\n",
      "Loss ep: 0.03659762202442943\n",
      "Score: 1412\n",
      "Highest: 128.0\n",
      "[[ 64.  32.   8.   2.]\n",
      " [  2.   4. 128.   4.]\n",
      " [  8.   2.  32.  16.]\n",
      " [  4.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 417\n",
      "Total Reward: 135\n",
      "Total episodes 149\n",
      "Eps_threshold: 0.041538371366717036\n",
      "Loss ep: 0.038009112313289774\n",
      "Score: 1424\n",
      "Highest: 128.0\n",
      "[[  2.   8.  16.   4.]\n",
      " [  8.  32.   2.   8.]\n",
      " [  4.   2. 128.  64.]\n",
      " [  2.  32.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 418\n",
      "Total Reward: 156\n",
      "Total episodes 170\n",
      "Eps_threshold: 0.04127143131252988\n",
      "Loss ep: 0.036121396457447726\n",
      "Score: 1828\n",
      "Highest: 128.0\n",
      "[[  8.   2.   8.   4.]\n",
      " [ 32.  16.  32.   2.]\n",
      " [  4. 128.   8. 128.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 419\n",
      "Total Reward: 183\n",
      "Total episodes 197\n",
      "Eps_threshold: 0.04096491976169505\n",
      "Loss ep: 0.0356210234201499\n",
      "Score: 2332\n",
      "Highest: 256.0\n",
      "[[  2.   8.   2.   8.]\n",
      " [  4.  16.   4.   2.]\n",
      " [  2. 256.   8.  32.]\n",
      " [ 16.   4.  64.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 420\n",
      "Total Reward: 160\n",
      "Total episodes 174\n",
      "Eps_threshold: 0.040696693436119966\n",
      "Loss ep: 0.03512417585000224\n",
      "Score: 1832\n",
      "Highest: 128.0\n",
      "[[  2.   8.   2.   4.]\n",
      " [ 16. 128.   4.  16.]\n",
      " [128.  16.   8.   4.]\n",
      " [  2.  32.  16.   8.]]\n",
      "Last action: UP\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 421\n",
      "Total Reward: 122\n",
      "Total episodes 136\n",
      "Eps_threshold: 0.04048866402236718\n",
      "Loss ep: 0.03659349329331342\n",
      "Score: 1320\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [  4.   8.  64.   8.]\n",
      " [ 32.  16.   4.  16.]\n",
      " [  8.   2. 128.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 422\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.04026388063290327\n",
      "Loss ep: 0.03605471108410809\n",
      "Score: 1436\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  4.   8.  16.   4.]\n",
      " [128.  32.   4.   2.]\n",
      " [ 32.   8.  64.  16.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 423\n",
      "Total Reward: 138\n",
      "Total episodes 152\n",
      "Eps_threshold: 0.04003474695098024\n",
      "Loss ep: 0.03439806009593763\n",
      "Score: 1468\n",
      "Highest: 128.0\n",
      "[[  2.   4.  16.   4.]\n",
      " [ 16. 128.  32.  64.]\n",
      " [  8.  32.   8.   4.]\n",
      " [  2.   4.  16.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 424\n",
      "Total Reward: 132\n",
      "Total episodes 146\n",
      "Eps_threshold: 0.03981629163028145\n",
      "Loss ep: 0.03590405477236395\n",
      "Score: 1428\n",
      "Highest: 128.0\n",
      "[[  4.   2.   8.   2.]\n",
      " [  8.  64.  16.   4.]\n",
      " [128.  32.   4.  16.]\n",
      " [  8.   4.   2.  32.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 425\n",
      "Total Reward: 138\n",
      "Total episodes 152\n",
      "Eps_threshold: 0.03959054673109263\n",
      "Loss ep: 0.035038540237828306\n",
      "Score: 1496\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  8.   2.  32.   4.]\n",
      " [ 32.   4.  64.  16.]\n",
      " [  4. 128.  32.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 426\n",
      "Total Reward: 135\n",
      "Total episodes 149\n",
      "Eps_threshold: 0.039370916297148006\n",
      "Loss ep: 0.03509637973452574\n",
      "Score: 1440\n",
      "Highest: 128.0\n",
      "[[  4.   8.   2.   4.]\n",
      " [  8.  64.  16.   2.]\n",
      " [ 16. 128.  32.   4.]\n",
      " [  4.  32.   4.   8.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 427\n",
      "Total Reward: 217\n",
      "Total episodes 231\n",
      "Eps_threshold: 0.039033633770029406\n",
      "Loss ep: 0.034174902614576994\n",
      "Score: 2712\n",
      "Highest: 256.0\n",
      "[[  4.  64.   8.   2.]\n",
      " [  2.   8.   2. 256.]\n",
      " [  8.  64.  32.   4.]\n",
      " [  2.   4.  16.  32.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 428\n",
      "Total Reward: 220\n",
      "Total episodes 234\n",
      "Eps_threshold: 0.03869591973449203\n",
      "Loss ep: 0.035385319310375765\n",
      "Score: 2880\n",
      "Highest: 256.0\n",
      "[[  4.   2.   4.   2.]\n",
      " [ 32.  16.   2. 256.]\n",
      " [ 16. 128.  16.   8.]\n",
      " [  2.  32.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 429\n",
      "Total Reward: 233\n",
      "Total episodes 247\n",
      "Eps_threshold: 0.03834370453136758\n",
      "Loss ep: 0.03337546591816643\n",
      "Score: 3044\n",
      "Highest: 256.0\n",
      "[[  4.  16. 128.   2.]\n",
      " [ 32.   8.  64.   4.]\n",
      " [  4. 256.   8.   2.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 430\n",
      "Total Reward: 210\n",
      "Total episodes 224\n",
      "Eps_threshold: 0.038028026139495304\n",
      "Loss ep: 0.03394812345504761\n",
      "Score: 2652\n",
      "Highest: 256.0\n",
      "[[  2.   4.  64.   2.]\n",
      " [ 16.  64.  16.   4.]\n",
      " [  8. 256.  32.   8.]\n",
      " [  4.  16.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 431\n",
      "Total Reward: 253\n",
      "Total episodes 267\n",
      "Eps_threshold: 0.03765633852559739\n",
      "Loss ep: 0.03400357564290365\n",
      "Score: 3196\n",
      "Highest: 256.0\n",
      "[[  4.  16.   8.   2.]\n",
      " [  8. 128.  64.   4.]\n",
      " [ 32.  16. 256.  32.]\n",
      " [  8.   4.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 432\n",
      "Total Reward: 175\n",
      "Total episodes 189\n",
      "Eps_threshold: 0.03739621713588487\n",
      "Loss ep: 0.03327473130806413\n",
      "Score: 2296\n",
      "Highest: 256.0\n",
      "[[  2. 256.   8.   4.]\n",
      " [  4.  64.  16.   2.]\n",
      " [ 16.  32.   2.   4.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 433\n",
      "Total Reward: 183\n",
      "Total episodes 197\n",
      "Eps_threshold: 0.03712768906892803\n",
      "Loss ep: 0.03281232427219449\n",
      "Score: 2364\n",
      "Highest: 256.0\n",
      "[[  4.   2.  16.   8.]\n",
      " [ 16.  64.   4.   2.]\n",
      " [  4.  32. 256.  16.]\n",
      " [  2.  16.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 434\n",
      "Total Reward: 136\n",
      "Total episodes 150\n",
      "Eps_threshold: 0.03692499246332153\n",
      "Loss ep: 0.032856680552164716\n",
      "Score: 1448\n",
      "Highest: 128.0\n",
      "[[  8.  64.   8.   2.]\n",
      " [  4.   8.  32.  16.]\n",
      " [ 32.  16. 128.   4.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 435\n",
      "Total Reward: 74\n",
      "Total episodes 88\n",
      "Eps_threshold: 0.03680678274856699\n",
      "Loss ep: 0.03409726511348377\n",
      "Score: 844\n",
      "Highest: 128.0\n",
      "[[  4.  16.   2.   4.]\n",
      " [  2.   8.   4.   2.]\n",
      " [  8.   2. 128.   4.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 436\n",
      "Total Reward: 153\n",
      "Total episodes 167\n",
      "Eps_threshold: 0.036583878034917264\n",
      "Loss ep: 0.03291788500940015\n",
      "Score: 1788\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [ 32.   2.   4.   8.]\n",
      " [  4. 128.  32. 128.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 437\n",
      "Total Reward: 192\n",
      "Total episodes 206\n",
      "Eps_threshold: 0.036311469403922284\n",
      "Loss ep: 0.03359537680172226\n",
      "Score: 2392\n",
      "Highest: 256.0\n",
      "[[  4.   8.  32.   2.]\n",
      " [ 16.  64.   8. 256.]\n",
      " [  4.   8.  16.   8.]\n",
      " [  2.  16.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 438\n",
      "Total Reward: 118\n",
      "Total episodes 132\n",
      "Eps_threshold: 0.036138385510997136\n",
      "Loss ep: 0.03411251125913678\n",
      "Score: 1280\n",
      "Highest: 128.0\n",
      "[[  2.   4.  16.   4.]\n",
      " [  8.  64.   2. 128.]\n",
      " [  2.   4.  32.   4.]\n",
      " [  8.   2.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 439\n",
      "Total Reward: 88\n",
      "Total episodes 102\n",
      "Eps_threshold: 0.03600541909745017\n",
      "Loss ep: 0.0327606995900472\n",
      "Score: 792\n",
      "Highest: 64.0\n",
      "[[ 4.  8.  4.  2.]\n",
      " [32.  4.  2.  8.]\n",
      " [64.  8. 32.  2.]\n",
      " [ 8. 32. 16.  8.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 440\n",
      "Total Reward: 77\n",
      "Total episodes 91\n",
      "Eps_threshold: 0.035887363221345815\n",
      "Loss ep: 0.03468024599683154\n",
      "Score: 672\n",
      "Highest: 64.0\n",
      "[[ 4.  2.  8.  4.]\n",
      " [ 2.  8.  4.  2.]\n",
      " [ 4. 32.  8. 32.]\n",
      " [64.  4. 16.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 441\n",
      "Total Reward: 99\n",
      "Total episodes 113\n",
      "Eps_threshold: 0.03574151203673607\n",
      "Loss ep: 0.03132009928205372\n",
      "Score: 912\n",
      "Highest: 64.0\n",
      "[[ 2.  4.  8. 16.]\n",
      " [ 4.  8. 64.  4.]\n",
      " [ 8. 32.  2. 16.]\n",
      " [ 4.  8. 64.  2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 442\n",
      "Total Reward: 177\n",
      "Total episodes 191\n",
      "Eps_threshold: 0.035496850714075136\n",
      "Loss ep: 0.033331978383488683\n",
      "Score: 2304\n",
      "Highest: 256.0\n",
      "[[ 16.  32.  64.   8.]\n",
      " [  4. 256.   4.   2.]\n",
      " [  2.  16.   8.   4.]\n",
      " [  4.   2.   4.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 443\n",
      "Total Reward: 133\n",
      "Total episodes 147\n",
      "Eps_threshold: 0.035310135878912005\n",
      "Loss ep: 0.03274699619838169\n",
      "Score: 1432\n",
      "Highest: 128.0\n",
      "[[  2.  64.   4.   2.]\n",
      " [  8.   2.   8.  32.]\n",
      " [  2. 128.  16.   8.]\n",
      " [ 16.  32.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 444\n",
      "Total Reward: 140\n",
      "Total episodes 154\n",
      "Eps_threshold: 0.03511599622950529\n",
      "Loss ep: 0.03183649112651875\n",
      "Score: 1464\n",
      "Highest: 128.0\n",
      "[[  4.   2.   8.   2.]\n",
      " [ 64.  32.  16.   8.]\n",
      " [  8.  16. 128.   4.]\n",
      " [  4.  32.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 445\n",
      "Total Reward: 175\n",
      "Total episodes 189\n",
      "Eps_threshold: 0.034879768001492166\n",
      "Loss ep: 0.033140798094411374\n",
      "Score: 2324\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  4.  32.   2. 256.]\n",
      " [  2.  64.  32.   2.]\n",
      " [  4.   2.   8.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 446\n",
      "Total Reward: 152\n",
      "Total episodes 166\n",
      "Eps_threshold: 0.03467412054461225\n",
      "Loss ep: 0.032840306500354445\n",
      "Score: 1624\n",
      "Highest: 128.0\n",
      "[[  8.  16.   2.   8.]\n",
      " [  2.   8.  64.  32.]\n",
      " [  8.  64. 128.   4.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 447\n",
      "Total Reward: 127\n",
      "Total episodes 141\n",
      "Eps_threshold: 0.03450077973906763\n",
      "Loss ep: 0.03351524704737021\n",
      "Score: 1388\n",
      "Highest: 128.0\n",
      "[[  2.   4.  32.   4.]\n",
      " [  4.  64.   8.   2.]\n",
      " [ 32.   8. 128.  16.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 448\n",
      "Total Reward: 131\n",
      "Total episodes 145\n",
      "Eps_threshold: 0.03432379144377476\n",
      "Loss ep: 0.03349769855367726\n",
      "Score: 1456\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [ 32.   8.  64.   2.]\n",
      " [  8.   2.  32.   8.]\n",
      " [  2.  32. 128.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 449\n",
      "Total Reward: 133\n",
      "Total episodes 147\n",
      "Eps_threshold: 0.034145666985938884\n",
      "Loss ep: 0.03201472353773052\n",
      "Score: 1536\n",
      "Highest: 128.0\n",
      "[[  4.   2.   4. 128.]\n",
      " [  2.  64.   8.   4.]\n",
      " [  4.   8.  32.  64.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 450\n",
      "Total Reward: 237\n",
      "Total episodes 251\n",
      "Eps_threshold: 0.033844532437003236\n",
      "Loss ep: 0.03333728531917253\n",
      "Score: 3000\n",
      "Highest: 256.0\n",
      "[[  2.   4.  32.   4.]\n",
      " [ 16.   8. 256.  16.]\n",
      " [ 32. 128.   8.   4.]\n",
      " [  4.   2.  32.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 451\n",
      "Total Reward: 226\n",
      "Total episodes 240\n",
      "Eps_threshold: 0.03356010800742165\n",
      "Loss ep: 0.03144658009211222\n",
      "Score: 2960\n",
      "Highest: 256.0\n",
      "[[  2.   8.   4.  64.]\n",
      " [  8.  16.   8.   2.]\n",
      " [  4.   8. 256. 128.]\n",
      " [  2.  16.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 452\n",
      "Total Reward: 212\n",
      "Total episodes 226\n",
      "Eps_threshold: 0.03329537733220177\n",
      "Loss ep: 0.033190233517537075\n",
      "Score: 2648\n",
      "Highest: 256.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  8.  32.   8.  16.]\n",
      " [256.  16.  64.   4.]\n",
      " [  4.  64.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 453\n",
      "Total Reward: 182\n",
      "Total episodes 196\n",
      "Eps_threshold: 0.03306819763306392\n",
      "Loss ep: 0.03128970885763363\n",
      "Score: 1908\n",
      "Highest: 128.0\n",
      "[[  4.  32.   4.   2.]\n",
      " [  8.  16.   8.  16.]\n",
      " [ 64. 128.  64.  32.]\n",
      " [  4.  16.  32.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 454\n",
      "Total Reward: 287\n",
      "Total episodes 301\n",
      "Eps_threshold: 0.032723620704014175\n",
      "Loss ep: 0.03217773817702385\n",
      "Score: 4476\n",
      "Highest: 512.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  8.  64.   8.  16.]\n",
      " [ 16. 512.   2.   4.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 455\n",
      "Total Reward: 111\n",
      "Total episodes 125\n",
      "Eps_threshold: 0.03258204097214739\n",
      "Loss ep: 0.0321408576965332\n",
      "Score: 1212\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  8. 128.  16.   8.]\n",
      " [  2.   4.  64.   4.]\n",
      " [  4.   8.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 456\n",
      "Total Reward: 201\n",
      "Total episodes 215\n",
      "Eps_threshold: 0.03234058418719062\n",
      "Loss ep: 0.03116397414096566\n",
      "Score: 2700\n",
      "Highest: 256.0\n",
      "[[  4.   8.  32.   2.]\n",
      " [  2. 128.   2.   4.]\n",
      " [  4.   8.  16. 256.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 32\n",
      "---------------------------\n",
      "Episode: 457\n",
      "Total Reward: 261\n",
      "Total episodes 275\n",
      "Eps_threshold: 0.032035503391682214\n",
      "Loss ep: 0.03193153381347656\n",
      "Score: 3336\n",
      "Highest: 256.0\n",
      "[[ 16.   2.   4.   2.]\n",
      " [  4.   8.  64. 256.]\n",
      " [  2.  64.  32.   8.]\n",
      " [  8. 128.   2.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 32\n",
      "---------------------------\n",
      "Episode: 458\n",
      "Total Reward: 139\n",
      "Total episodes 153\n",
      "Eps_threshold: 0.03186757493604395\n",
      "Loss ep: 0.03137968724070032\n",
      "Score: 1472\n",
      "Highest: 128.0\n",
      "[[  2.  32.   4.   2.]\n",
      " [  4.  16. 128.   8.]\n",
      " [ 16.  64.   8.  32.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 459\n",
      "Total Reward: 222\n",
      "Total episodes 236\n",
      "Eps_threshold: 0.03161105400180166\n",
      "Loss ep: 0.030559400380667994\n",
      "Score: 2772\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.  16.]\n",
      " [ 16.   8.  32.  64.]\n",
      " [  4.  64.   8. 256.]\n",
      " [  2.  32.   4.  16.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 460\n",
      "Total Reward: 137\n",
      "Total episodes 151\n",
      "Eps_threshold: 0.03144850493894153\n",
      "Loss ep: 0.03198701340631144\n",
      "Score: 1504\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  8.  64.  16.  64.]\n",
      " [  4.  16.   4. 128.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 461\n",
      "Total Reward: 171\n",
      "Total episodes 185\n",
      "Eps_threshold: 0.03125102103939108\n",
      "Loss ep: 0.032196233079240126\n",
      "Score: 2216\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [ 16.  64.   4.   8.]\n",
      " [  4.   8. 256.   4.]\n",
      " [  2.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 462\n",
      "Total Reward: 150\n",
      "Total episodes 164\n",
      "Eps_threshold: 0.031077475177336722\n",
      "Loss ep: 0.03088668497597299\n",
      "Score: 1564\n",
      "Highest: 128.0\n",
      "[[  2.  32.   4.   2.]\n",
      " [  4. 128.  64.   8.]\n",
      " [ 32.   8.  32.  16.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 463\n",
      "Total Reward: 140\n",
      "Total episodes 154\n",
      "Eps_threshold: 0.03091580185954486\n",
      "Loss ep: 0.030657285219663148\n",
      "Score: 1568\n",
      "Highest: 128.0\n",
      "[[  2.   4.  64.   2.]\n",
      " [ 64.   8.  32.   4.]\n",
      " [  8. 128.   2.   8.]\n",
      " [  2.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 464\n",
      "Total Reward: 191\n",
      "Total episodes 205\n",
      "Eps_threshold: 0.03070250987929575\n",
      "Loss ep: 0.031847381591796876\n",
      "Score: 2476\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  8.  64. 256.   4.]\n",
      " [  4.   8.  64.   8.]\n",
      " [  2.   4.   2.  16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 465\n",
      "Total Reward: 201\n",
      "Total episodes 215\n",
      "Eps_threshold: 0.0304811498400435\n",
      "Loss ep: 0.03138369626777117\n",
      "Score: 2496\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.  16.]\n",
      " [  4.   8.  32.   4.]\n",
      " [ 16.  32.  64.  16.]\n",
      " [  8. 256.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 466\n",
      "Total Reward: 87\n",
      "Total episodes 101\n",
      "Eps_threshold: 0.030377980754547854\n",
      "Loss ep: 0.03234788686922281\n",
      "Score: 836\n",
      "Highest: 64.0\n",
      "[[ 4.  2.  8.  4.]\n",
      " [ 2. 16. 64. 32.]\n",
      " [ 4. 64.  4.  2.]\n",
      " [ 2.  4.  2.  8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 467\n",
      "Total Reward: 110\n",
      "Total episodes 124\n",
      "Eps_threshold: 0.03025202813047228\n",
      "Loss ep: 0.03212138722019811\n",
      "Score: 1164\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  4.  32.   8.   4.]\n",
      " [  8. 128.  16.  32.]\n",
      " [  4.  16.   8.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 468\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.030102716257595655\n",
      "Loss ep: 0.03263022448565509\n",
      "Score: 1496\n",
      "Highest: 128.0\n",
      "[[  2.  16.   2.   4.]\n",
      " [  4.  64.   8.  64.]\n",
      " [  2.   8.  16.   4.]\n",
      " [  4.   2. 128.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 469\n",
      "Total Reward: 229\n",
      "Total episodes 243\n",
      "Eps_threshold: 0.02985994607047377\n",
      "Loss ep: 0.03109341491887599\n",
      "Score: 2908\n",
      "Highest: 256.0\n",
      "[[  2.   4.  16.   2.]\n",
      " [  8. 128.  32.   8.]\n",
      " [  4. 256.   8.  16.]\n",
      " [  2.   4.  32.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 470\n",
      "Total Reward: 145\n",
      "Total episodes 159\n",
      "Eps_threshold: 0.02970268543849683\n",
      "Loss ep: 0.03124293441292625\n",
      "Score: 1548\n",
      "Highest: 128.0\n",
      "[[  2.   8.  16.   4.]\n",
      " [ 32. 128.   2.  32.]\n",
      " [  8.  32.  16.   8.]\n",
      " [  4.  64.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 471\n",
      "Total Reward: 197\n",
      "Total episodes 211\n",
      "Eps_threshold: 0.029495914740390948\n",
      "Loss ep: 0.031165190782592195\n",
      "Score: 2412\n",
      "Highest: 256.0\n",
      "[[ 16.   4.  16.   2.]\n",
      " [  8.  64.  32.   8.]\n",
      " [  2.  16.   8.   4.]\n",
      " [  8.   2. 256.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 472\n",
      "Total Reward: 166\n",
      "Total episodes 180\n",
      "Eps_threshold: 0.02932123872884089\n",
      "Loss ep: 0.030816033151414658\n",
      "Score: 2156\n",
      "Highest: 256.0\n",
      "[[  2.   8.  32.   2.]\n",
      " [  4. 256.  16.   4.]\n",
      " [ 32.  16.   2.  16.]\n",
      " [  8.   2.   4.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 473\n",
      "Total Reward: 95\n",
      "Total episodes 109\n",
      "Eps_threshold: 0.029216224401742256\n",
      "Loss ep: 0.03053874050805328\n",
      "Score: 892\n",
      "Highest: 64.0\n",
      "[[ 8.  2.  4.  2.]\n",
      " [ 4. 32. 16.  8.]\n",
      " [ 2. 64.  8.  4.]\n",
      " [64. 16.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 474\n",
      "Total Reward: 203\n",
      "Total episodes 217\n",
      "Eps_threshold: 0.02900885537826505\n",
      "Loss ep: 0.0305293210640481\n",
      "Score: 2604\n",
      "Highest: 256.0\n",
      "[[  4.  64.   2.   4.]\n",
      " [  2.  16.   4.   2.]\n",
      " [  4.  32. 256.   8.]\n",
      " [  8.  64.  16.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 475\n",
      "Total Reward: 245\n",
      "Total episodes 259\n",
      "Eps_threshold: 0.028764277759213502\n",
      "Loss ep: 0.030855837936106797\n",
      "Score: 3160\n",
      "Highest: 256.0\n",
      "[[  4.  32.   4.   2.]\n",
      " [256. 128.   8.   4.]\n",
      " [  4.  16.  64.   8.]\n",
      " [  2.  32.  16.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 476\n",
      "Total Reward: 236\n",
      "Total episodes 250\n",
      "Eps_threshold: 0.028531184157300334\n",
      "Loss ep: 0.030263332366943358\n",
      "Score: 2996\n",
      "Highest: 256.0\n",
      "[[  8.  32.   4.   8.]\n",
      " [  4. 128.  16.   2.]\n",
      " [ 32.  16. 256.   4.]\n",
      " [  4.  32.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 477\n",
      "Total Reward: 151\n",
      "Total episodes 165\n",
      "Eps_threshold: 0.02837893079667622\n",
      "Loss ep: 0.030424999468254322\n",
      "Score: 1632\n",
      "Highest: 128.0\n",
      "[[  4.   2.   8.   4.]\n",
      " [  8.   4.  16.  64.]\n",
      " [ 64. 128.   4.  32.]\n",
      " [  2.  16.   8.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 478\n",
      "Total Reward: 201\n",
      "Total episodes 215\n",
      "Eps_threshold: 0.02818241545306393\n",
      "Loss ep: 0.030507770804471746\n",
      "Score: 2488\n",
      "Highest: 256.0\n",
      "[[  2.   4.  16.   2.]\n",
      " [  4.   8. 256.  32.]\n",
      " [ 64.   2.  32.  16.]\n",
      " [  2.   4.  16.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 479\n",
      "Total Reward: 244\n",
      "Total episodes 258\n",
      "Eps_threshold: 0.02794936867719098\n",
      "Loss ep: 0.03121980400972588\n",
      "Score: 3156\n",
      "Highest: 256.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [ 32.   2. 256.  32.]\n",
      " [  8. 128.  64.   8.]\n",
      " [  2.  16.   4.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 480\n",
      "Total Reward: 240\n",
      "Total episodes 254\n",
      "Eps_threshold: 0.02772285311337068\n",
      "Loss ep: 0.030284352189912572\n",
      "Score: 3076\n",
      "Highest: 256.0\n",
      "[[  4.   8.   4.   2.]\n",
      " [  2.  16.   8.  32.]\n",
      " [  8. 128.  64. 256.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 481\n",
      "Total Reward: 80\n",
      "Total episodes 94\n",
      "Eps_threshold: 0.02763975114633717\n",
      "Loss ep: 0.03013120306299088\n",
      "Score: 716\n",
      "Highest: 64.0\n",
      "[[ 2. 16.  4.  2.]\n",
      " [32.  2. 16.  4.]\n",
      " [16. 64. 32.  2.]\n",
      " [ 2.  4.  8.  4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 482\n",
      "Total Reward: 221\n",
      "Total episodes 235\n",
      "Eps_threshold: 0.027433697009114223\n",
      "Loss ep: 0.030880240176586395\n",
      "Score: 2748\n",
      "Highest: 256.0\n",
      "[[  2.   8.  16.  32.]\n",
      " [  4.  64. 256.   4.]\n",
      " [  8.   2.  64.   8.]\n",
      " [  2.  32.   4.  16.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 483\n",
      "Total Reward: 226\n",
      "Total episodes 240\n",
      "Eps_threshold: 0.027225742865311403\n",
      "Loss ep: 0.029942158857981363\n",
      "Score: 2940\n",
      "Highest: 256.0\n",
      "[[ 32.   4.   8.   2.]\n",
      " [128.  32. 256.  16.]\n",
      " [ 32.   8.   4.   8.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 484\n",
      "Total Reward: 208\n",
      "Total episodes 222\n",
      "Eps_threshold: 0.027035594395857315\n",
      "Loss ep: 0.03078217549366994\n",
      "Score: 2624\n",
      "Highest: 256.0\n",
      "[[  2.   8.   2.   4.]\n",
      " [ 16.  64.   4.   8.]\n",
      " [  2.  16. 256.   4.]\n",
      " [ 64.   4.  32.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 485\n",
      "Total Reward: 116\n",
      "Total episodes 130\n",
      "Eps_threshold: 0.026925222130747925\n",
      "Loss ep: 0.031200144841120794\n",
      "Score: 1232\n",
      "Highest: 128.0\n",
      "[[ 32.   4.   2.   8.]\n",
      " [  2.  16.  32.   4.]\n",
      " [  8.   4. 128.   2.]\n",
      " [ 16.  32.   2.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 486\n",
      "Total Reward: 143\n",
      "Total episodes 157\n",
      "Eps_threshold: 0.026792879262387367\n",
      "Loss ep: 0.030047027928054713\n",
      "Score: 1536\n",
      "Highest: 128.0\n",
      "[[  8.  16.   4.   2.]\n",
      " [ 16.  32.  64.  32.]\n",
      " [  4.   8. 128.   4.]\n",
      " [  2.   4.  32.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 487\n",
      "Total Reward: 151\n",
      "Total episodes 165\n",
      "Eps_threshold: 0.02665490792280377\n",
      "Loss ep: 0.030191340590968275\n",
      "Score: 1652\n",
      "Highest: 128.0\n",
      "[[ 64.   4.   8.   4.]\n",
      " [  8.  16.  32.  16.]\n",
      " [  4.  64.   8.   2.]\n",
      " [  2.  16. 128.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 488\n",
      "Total Reward: 201\n",
      "Total episodes 215\n",
      "Eps_threshold: 0.026476826564889692\n",
      "Loss ep: 0.029217515989791516\n",
      "Score: 2300\n",
      "Highest: 128.0\n",
      "[[  4.  16. 128.   2.]\n",
      " [  2.   8.   2.   4.]\n",
      " [  8.  16.  64.   2.]\n",
      " [ 16.  64.   8. 128.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 489\n",
      "Total Reward: 183\n",
      "Total episodes 197\n",
      "Eps_threshold: 0.02631532651672218\n",
      "Loss ep: 0.03147907063440623\n",
      "Score: 2300\n",
      "Highest: 256.0\n",
      "[[  4.   8.   4.   2.]\n",
      " [  2.  16. 256.  16.]\n",
      " [ 16.  64.  16.   4.]\n",
      " [  4.   2.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 490\n",
      "Total Reward: 298\n",
      "Total episodes 312\n",
      "Eps_threshold: 0.026062782388832986\n",
      "Loss ep: 0.03002760349175869\n",
      "Score: 4064\n",
      "Highest: 256.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [ 32. 256.   8.   4.]\n",
      " [  8.  16. 256.   8.]\n",
      " [  2.  64.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 491\n",
      "Total Reward: 210\n",
      "Total episodes 224\n",
      "Eps_threshold: 0.025883882933121764\n",
      "Loss ep: 0.030348752226148332\n",
      "Score: 2640\n",
      "Highest: 256.0\n",
      "[[  8.  64.   2.   4.]\n",
      " [ 32. 256.   8.   2.]\n",
      " [ 64.   8.  16.   8.]\n",
      " [  2.  16.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 492\n",
      "Total Reward: 204\n",
      "Total episodes 218\n",
      "Eps_threshold: 0.025711688772190135\n",
      "Loss ep: 0.03089572311541356\n",
      "Score: 2544\n",
      "Highest: 256.0\n",
      "[[  4.   8.   2.  32.]\n",
      " [ 32. 256.   4.   2.]\n",
      " [  4.  16.  32.  16.]\n",
      " [  2.  64.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 493\n",
      "Total Reward: 159\n",
      "Total episodes 173\n",
      "Eps_threshold: 0.02557636876708016\n",
      "Loss ep: 0.029836671200790848\n",
      "Score: 1708\n",
      "Highest: 128.0\n",
      "[[  4.   2. 128.   2.]\n",
      " [ 32.   8.  16.   4.]\n",
      " [  8.  32.   2.  64.]\n",
      " [  4.   2.  64.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 494\n",
      "Total Reward: 224\n",
      "Total episodes 238\n",
      "Eps_threshold: 0.02539210850175017\n",
      "Loss ep: 0.03027596593904896\n",
      "Score: 2756\n",
      "Highest: 256.0\n",
      "[[  2.   4.  64.   4.]\n",
      " [ 32.   8.   4.  32.]\n",
      " [  4.  64. 256.   8.]\n",
      " [ 16.   4.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 495\n",
      "Total Reward: 233\n",
      "Total episodes 247\n",
      "Eps_threshold: 0.025203184965839193\n",
      "Loss ep: 0.030268084182430377\n",
      "Score: 2964\n",
      "Highest: 256.0\n",
      "[[  4.  16.   4.   2.]\n",
      " [  8.   4.  32.   4.]\n",
      " [256.  32. 128.   8.]\n",
      " [  2.   4.  32.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 496\n",
      "Total Reward: 250\n",
      "Total episodes 264\n",
      "Eps_threshold: 0.025003821617138964\n",
      "Loss ep: 0.029169445688074284\n",
      "Score: 3180\n",
      "Highest: 256.0\n",
      "[[ 32.   8.   4.   2.]\n",
      " [ 16. 256.  32.   4.]\n",
      " [  4. 128.  16.  64.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 497\n",
      "Total Reward: 225\n",
      "Total episodes 239\n",
      "Eps_threshold: 0.02482559298583896\n",
      "Loss ep: 0.02941098073536382\n",
      "Score: 2968\n",
      "Highest: 256.0\n",
      "[[  2.   4.   2.  16.]\n",
      " [  4. 128.  16.   4.]\n",
      " [  8.  16.  64.   8.]\n",
      " [  2.   4.   8. 256.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 498\n",
      "Total Reward: 216\n",
      "Total episodes 230\n",
      "Eps_threshold: 0.024656075261638433\n",
      "Loss ep: 0.029780045799587086\n",
      "Score: 2616\n",
      "Highest: 256.0\n",
      "[[  4.  32.   8.   2.]\n",
      " [ 16.  64. 256.   8.]\n",
      " [  4.  32.  16.  32.]\n",
      " [  2.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 499\n",
      "Total Reward: 131\n",
      "Total episodes 145\n",
      "Eps_threshold: 0.024550202966802638\n",
      "Loss ep: 0.030025163190118196\n",
      "Score: 1372\n",
      "Highest: 128.0\n",
      "[[  4. 128.   4.   2.]\n",
      " [ 16.  32.   8.  16.]\n",
      " [  8.   2.  16.   4.]\n",
      " [  2.  64.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 500\n",
      "Total Reward: 214\n",
      "Total episodes 228\n",
      "Eps_threshold: 0.024385272542591714\n",
      "Loss ep: 0.02899286203217088\n",
      "Score: 2692\n",
      "Highest: 256.0\n",
      "[[ 16.  64.  32.   2.]\n",
      " [  2. 256.  64.   4.]\n",
      " [  4.  32.   8.   2.]\n",
      " [  2.   4.   2.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Update target_net\n",
      "Episode: 501\n",
      "Total Reward: 132\n",
      "Total episodes 146\n",
      "Eps_threshold: 0.024280642417631434\n",
      "Loss ep: 0.04769662308366331\n",
      "Score: 1424\n",
      "Highest: 128.0\n",
      "[[  2.   4.  32.   2.]\n",
      " [ 32.   8.  64.  16.]\n",
      " [  2. 128.   8.   4.]\n",
      " [  4.   2.  16.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 502\n",
      "Total Reward: 155\n",
      "Total episodes 169\n",
      "Eps_threshold: 0.0241604793929758\n",
      "Loss ep: 0.04468413358609352\n",
      "Score: 1696\n",
      "Highest: 128.0\n",
      "[[  2.  32.   4.   2.]\n",
      " [ 64.   4.   8.   4.]\n",
      " [ 16.   8. 128.  64.]\n",
      " [  4.  32.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 503\n",
      "Total Reward: 203\n",
      "Total episodes 217\n",
      "Eps_threshold: 0.024007668688734433\n",
      "Loss ep: 0.04150520271969281\n",
      "Score: 2684\n",
      "Highest: 256.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  4. 256.  16.   8.]\n",
      " [  2.  16. 128.  16.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 504\n",
      "Total Reward: 127\n",
      "Total episodes 141\n",
      "Eps_threshold: 0.023909261915941157\n",
      "Loss ep: 0.04219865798950195\n",
      "Score: 1344\n",
      "Highest: 128.0\n",
      "[[ 16.   8.   4.   2.]\n",
      " [  2.  32. 128.   4.]\n",
      " [  8.  16.  64.   8.]\n",
      " [  4.   2.   8.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 505\n",
      "Total Reward: 234\n",
      "Total episodes 248\n",
      "Eps_threshold: 0.023737852005952097\n",
      "Loss ep: 0.04089766933071998\n",
      "Score: 3036\n",
      "Highest: 256.0\n",
      "[[  4.   2.   8.   2.]\n",
      " [  2.  32. 256.   4.]\n",
      " [  8. 128.  16.  64.]\n",
      " [  2.   8.   4.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 506\n",
      "Total Reward: 73\n",
      "Total episodes 87\n",
      "Eps_threshold: 0.023678222138716266\n",
      "Loss ep: 0.037698688178226865\n",
      "Score: 628\n",
      "Highest: 64.0\n",
      "[[ 2.  8.  2.  4.]\n",
      " [ 4.  2. 16.  2.]\n",
      " [16. 64. 32.  4.]\n",
      " [ 8. 16.  8.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 507\n",
      "Total Reward: 228\n",
      "Total episodes 242\n",
      "Eps_threshold: 0.023513712938642677\n",
      "Loss ep: 0.037535667419433594\n",
      "Score: 2952\n",
      "Highest: 256.0\n",
      "[[  2.   4.  32.   8.]\n",
      " [  4.   8. 128.  32.]\n",
      " [ 16. 256.  32.   4.]\n",
      " [  8.   2.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 508\n",
      "Total Reward: 124\n",
      "Total episodes 138\n",
      "Eps_threshold: 0.023420789274681053\n",
      "Loss ep: 0.0389194004777549\n",
      "Score: 1344\n",
      "Highest: 128.0\n",
      "[[ 16.   4.   2.   4.]\n",
      " [  2.   8.  32.   8.]\n",
      " [ 16.  64.  16.   4.]\n",
      " [  2.   4. 128.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 509\n",
      "Total Reward: 149\n",
      "Total episodes 163\n",
      "Eps_threshold: 0.023311854354867458\n",
      "Loss ep: 0.03589955429357985\n",
      "Score: 1620\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   8.]\n",
      " [ 16.  64.  32.   2.]\n",
      " [  4. 128.   8.   4.]\n",
      " [  2.   4.  64.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 510\n",
      "Total Reward: 76\n",
      "Total episodes 90\n",
      "Eps_threshold: 0.023252085590849347\n",
      "Loss ep: 0.03752227094438341\n",
      "Score: 684\n",
      "Highest: 64.0\n",
      "[[ 2.  4. 16. 64.]\n",
      " [ 4. 32.  4.  8.]\n",
      " [ 2.  8. 32.  2.]\n",
      " [ 4.  2.  4. 16.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 511\n",
      "Total Reward: 133\n",
      "Total episodes 147\n",
      "Eps_threshold: 0.023155039841771908\n",
      "Loss ep: 0.03609547647489172\n",
      "Score: 1400\n",
      "Highest: 128.0\n",
      "[[  4.  16.   4.   2.]\n",
      " [ 16.  64. 128.   8.]\n",
      " [  2.  16.  32.  16.]\n",
      " [  4.   2.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 512\n",
      "Total Reward: 125\n",
      "Total episodes 139\n",
      "Eps_threshold: 0.02306392929077495\n",
      "Loss ep: 0.036099454481824694\n",
      "Score: 1316\n",
      "Highest: 128.0\n",
      "[[  4.   2.  32.   4.]\n",
      " [  2.  32.   8.  32.]\n",
      " [  4. 128.  16.   4.]\n",
      " [  2.   8.  32.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 513\n",
      "Total Reward: 217\n",
      "Total episodes 231\n",
      "Eps_threshold: 0.02291390894273021\n",
      "Loss ep: 0.03636702417811274\n",
      "Score: 2792\n",
      "Highest: 256.0\n",
      "[[  2.   4.   8.   2.]\n",
      " [  4.   8.  16.   4.]\n",
      " [  8.  32. 128. 256.]\n",
      " [  4.   8.  16.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 514\n",
      "Total Reward: 182\n",
      "Total episodes 196\n",
      "Eps_threshold: 0.022787970740207615\n",
      "Loss ep: 0.03569253853389195\n",
      "Score: 2344\n",
      "Highest: 256.0\n",
      "[[  2.   8.  16.   2.]\n",
      " [  4.  32.   4.  16.]\n",
      " [  8. 256.  64.   2.]\n",
      " [  2.   4.  16.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 515\n",
      "Total Reward: 134\n",
      "Total episodes 148\n",
      "Eps_threshold: 0.022693689029298927\n",
      "Loss ep: 0.03806820109083846\n",
      "Score: 1436\n",
      "Highest: 128.0\n",
      "[[  2.   4.  16.   8.]\n",
      " [ 16. 128.  64.  32.]\n",
      " [  2.   8.   4.   2.]\n",
      " [  4.  32.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 516\n",
      "Total Reward: 270\n",
      "Total episodes 284\n",
      "Eps_threshold: 0.02251471238663984\n",
      "Loss ep: 0.035097716559826485\n",
      "Score: 3332\n",
      "Highest: 256.0\n",
      "[[  4.  32.   8.   2.]\n",
      " [ 64. 256.  32.   4.]\n",
      " [  8.  32. 128.  16.]\n",
      " [  4.  16.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 517\n",
      "Total Reward: 144\n",
      "Total episodes 158\n",
      "Eps_threshold: 0.022416235654039697\n",
      "Loss ep: 0.03544706936124005\n",
      "Score: 1524\n",
      "Highest: 128.0\n",
      "[[128.   2.   4.   2.]\n",
      " [  2.  32.  64.   8.]\n",
      " [  4.  16.  32.   4.]\n",
      " [  8.  32.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 518\n",
      "Total Reward: 108\n",
      "Total episodes 122\n",
      "Eps_threshold: 0.022340727151621564\n",
      "Loss ep: 0.03390420460310139\n",
      "Score: 1200\n",
      "Highest: 128.0\n",
      "[[  4.  64.   8.   4.]\n",
      " [  2.   8.   4.   2.]\n",
      " [  8. 128.  16.   4.]\n",
      " [  2.  16.   8.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 519\n",
      "Total Reward: 194\n",
      "Total episodes 208\n",
      "Eps_threshold: 0.022213048668165335\n",
      "Loss ep: 0.03349891992715689\n",
      "Score: 2460\n",
      "Highest: 256.0\n",
      "[[  8. 256.   4.   2.]\n",
      " [ 16.  32.  64.  16.]\n",
      " [  4.  16.  32.   4.]\n",
      " [  2.   4.   2.   8.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 520\n",
      "Total Reward: 79\n",
      "Total episodes 93\n",
      "Eps_threshold: 0.022156389825759074\n",
      "Loss ep: 0.03467247306659658\n",
      "Score: 700\n",
      "Highest: 64.0\n",
      "[[ 4. 16.  4.  2.]\n",
      " [ 8. 32.  8. 32.]\n",
      " [ 2. 64. 16.  8.]\n",
      " [ 4.  2.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 521\n",
      "Total Reward: 70\n",
      "Total episodes 84\n",
      "Eps_threshold: 0.02210544005789953\n",
      "Loss ep: 0.033026996113005136\n",
      "Score: 604\n",
      "Highest: 64.0\n",
      "[[ 8.  2. 16.  8.]\n",
      " [ 2. 32.  4. 64.]\n",
      " [ 8. 16.  8.  2.]\n",
      " [ 4.  2.  4.  8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 522\n",
      "Total Reward: 110\n",
      "Total episodes 124\n",
      "Eps_threshold: 0.02203061851599862\n",
      "Loss ep: 0.03326692504267539\n",
      "Score: 1144\n",
      "Highest: 128.0\n",
      "[[  4.  16.   2.   4.]\n",
      " [  8.  32.   8.   2.]\n",
      " [  2. 128.   4.   8.]\n",
      " [ 32.   4.  16.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 523\n",
      "Total Reward: 148\n",
      "Total episodes 162\n",
      "Eps_threshold: 0.021933564107019802\n",
      "Loss ep: 0.033218601603566864\n",
      "Score: 1756\n",
      "Highest: 128.0\n",
      "[[  2.   4.  16.   2.]\n",
      " [  4.  16. 128.   4.]\n",
      " [  2. 128.   2.  16.]\n",
      " [ 32.   2.   8.   4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 524\n",
      "Total Reward: 176\n",
      "Total episodes 190\n",
      "Eps_threshold: 0.021820732048869154\n",
      "Loss ep: 0.03296893270392167\n",
      "Score: 2304\n",
      "Highest: 256.0\n",
      "[[  2.   8.   2.   4.]\n",
      " [ 32.  64.   8.   2.]\n",
      " [  8.   4.   2.  16.]\n",
      " [  2. 256.  16.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 525\n",
      "Total Reward: 211\n",
      "Total episodes 225\n",
      "Eps_threshold: 0.021688494046775895\n",
      "Loss ep: 0.03282901340060764\n",
      "Score: 2648\n",
      "Highest: 256.0\n",
      "[[ 64.   8.  16.   2.]\n",
      " [  8.   4. 256.   8.]\n",
      " [  4.   8.  64.  32.]\n",
      " [  2.   4.  16.   8.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 526\n",
      "Total Reward: 130\n",
      "Total episodes 144\n",
      "Eps_threshold: 0.021604639129593893\n",
      "Loss ep: 0.03181549244456821\n",
      "Score: 1380\n",
      "Highest: 128.0\n",
      "[[  4.   8.  16.   2.]\n",
      " [  8.   4. 128.   8.]\n",
      " [ 64.   8.  16.  32.]\n",
      " [  4.  16.   8.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 527\n",
      "Total Reward: 146\n",
      "Total episodes 160\n",
      "Eps_threshold: 0.02151217237672411\n",
      "Loss ep: 0.03232999444007874\n",
      "Score: 1592\n",
      "Highest: 128.0\n",
      "[[  2.   4.   2.   4.]\n",
      " [  8. 128.   8.  16.]\n",
      " [  2.   4.  32.   4.]\n",
      " [ 64.   8.  64.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 528\n",
      "Total Reward: 187\n",
      "Total episodes 201\n",
      "Eps_threshold: 0.02139705448069687\n",
      "Loss ep: 0.03221565692578975\n",
      "Score: 2164\n",
      "Highest: 128.0\n",
      "[[  2.   8.   2.   4.]\n",
      " [ 32.  64.   4.  16.]\n",
      " [  8.  32. 128.   8.]\n",
      " [  2. 128.  16.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 529\n",
      "Total Reward: 101\n",
      "Total episodes 115\n",
      "Eps_threshold: 0.02133170946439377\n",
      "Loss ep: 0.032284241137297255\n",
      "Score: 936\n",
      "Highest: 64.0\n",
      "[[ 4. 64. 16.  2.]\n",
      " [16.  4.  8. 32.]\n",
      " [ 4. 64. 16.  8.]\n",
      " [ 2.  8.  4.  2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 530\n",
      "Total Reward: 185\n",
      "Total episodes 199\n",
      "Eps_threshold: 0.021219518033194426\n",
      "Loss ep: 0.032961402107123755\n",
      "Score: 2340\n",
      "Highest: 256.0\n",
      "[[  4.  16.   8.   4.]\n",
      " [  2.   4.  16.  32.]\n",
      " [  8. 256.   8.   4.]\n",
      " [  2.   4.  64.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 531\n",
      "Total Reward: 208\n",
      "Total episodes 222\n",
      "Eps_threshold: 0.02109567001115524\n",
      "Loss ep: 0.03217691129392332\n",
      "Score: 2744\n",
      "Highest: 256.0\n",
      "[[  2.   8.   4.   8.]\n",
      " [ 32. 256.  16.   2.]\n",
      " [  8. 128.   8.   4.]\n",
      " [  2.   8.   4.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 532\n",
      "Total Reward: 152\n",
      "Total episodes 166\n",
      "Eps_threshold: 0.021003957085213326\n",
      "Loss ep: 0.031920203243393494\n",
      "Score: 2012\n",
      "Highest: 256.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  4.   2.   8.  32.]\n",
      " [  2.   8. 256.   2.]\n",
      " [  4.  16.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 533\n",
      "Total Reward: 123\n",
      "Total episodes 137\n",
      "Eps_threshold: 0.020928837557295507\n",
      "Loss ep: 0.031972738948181596\n",
      "Score: 1324\n",
      "Highest: 128.0\n",
      "[[  4.   8.   2.  64.]\n",
      " [  2.  16. 128.   4.]\n",
      " [  8.  32.  16.   2.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 534\n",
      "Total Reward: 87\n",
      "Total episodes 101\n",
      "Eps_threshold: 0.02087378604968376\n",
      "Loss ep: 0.03248276096759456\n",
      "Score: 764\n",
      "Highest: 64.0\n",
      "[[16.  2. 16.  4.]\n",
      " [32.  4. 32.  2.]\n",
      " [ 2. 16. 64.  4.]\n",
      " [16.  8.  4.  2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 535\n",
      "Total Reward: 131\n",
      "Total episodes 145\n",
      "Eps_threshold: 0.02079523618813612\n",
      "Loss ep: 0.030909636925006735\n",
      "Score: 1408\n",
      "Highest: 128.0\n",
      "[[  2. 128.   4.   2.]\n",
      " [  4.  32.   8.  32.]\n",
      " [ 64.   8.  16.   8.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 536\n",
      "Total Reward: 210\n",
      "Total episodes 224\n",
      "Eps_threshold: 0.020675004099349678\n",
      "Loss ep: 0.03157833218574524\n",
      "Score: 2608\n",
      "Highest: 256.0\n",
      "[[  2.   4.  16.   4.]\n",
      " [ 16.  64.   8.   2.]\n",
      " [  8.  16. 256.  16.]\n",
      " [  4.   8.  64.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 537\n",
      "Total Reward: 141\n",
      "Total episodes 155\n",
      "Eps_threshold: 0.020592592574724074\n",
      "Loss ep: 0.03118585155856225\n",
      "Score: 1528\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  8.  64.  16.   2.]\n",
      " [  4. 128.  64.   4.]\n",
      " [  2.   8.  16.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 538\n",
      "Total Reward: 72\n",
      "Total episodes 86\n",
      "Eps_threshold: 0.020547142214957667\n",
      "Loss ep: 0.030968638353569562\n",
      "Score: 668\n",
      "Highest: 64.0\n",
      "[[32.  2.  4.  2.]\n",
      " [ 2.  8. 32. 16.]\n",
      " [ 4.  2. 64.  2.]\n",
      " [ 8. 16.  2.  4.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 539\n",
      "Total Reward: 208\n",
      "Total episodes 222\n",
      "Eps_threshold: 0.02043071629562461\n",
      "Loss ep: 0.030680581256076023\n",
      "Score: 2632\n",
      "Highest: 256.0\n",
      "[[ 64.  32.   8.   4.]\n",
      " [  4.  16. 256.   8.]\n",
      " [  8.  64.  16.   4.]\n",
      " [  2.   4.   2.   8.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 540\n",
      "Total Reward: 144\n",
      "Total episodes 158\n",
      "Eps_threshold: 0.020348638271956338\n",
      "Loss ep: 0.03213082989559898\n",
      "Score: 1556\n",
      "Highest: 128.0\n",
      "[[  2.   4.   8.   4.]\n",
      " [  8.   2.  16.   2.]\n",
      " [ 64.  16.  64.  16.]\n",
      " [  4. 128.   8.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 541\n",
      "Total Reward: 67\n",
      "Total episodes 81\n",
      "Eps_threshold: 0.020306811044263566\n",
      "Loss ep: 0.03117673779711311\n",
      "Score: 600\n",
      "Highest: 64.0\n",
      "[[ 2.  4.  8.  2.]\n",
      " [16.  2. 32. 16.]\n",
      " [ 2.  8. 16.  4.]\n",
      " [ 4. 64.  4.  2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 542\n",
      "Total Reward: 151\n",
      "Total episodes 165\n",
      "Eps_threshold: 0.020222129644225324\n",
      "Loss ep: 0.03117965351451527\n",
      "Score: 1572\n",
      "Highest: 128.0\n",
      "[[  2.  16.   8.   4.]\n",
      " [ 32. 128.  32.   8.]\n",
      " [ 16.  64.   8.   2.]\n",
      " [  2.  32.   2.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 543\n",
      "Total Reward: 156\n",
      "Total episodes 170\n",
      "Eps_threshold: 0.020135609772624817\n",
      "Loss ep: 0.029377297794117647\n",
      "Score: 1840\n",
      "Highest: 128.0\n",
      "[[  2.  16.   4.   2.]\n",
      " [  4.  32.   2. 128.]\n",
      " [128.   8.  32.   8.]\n",
      " [  4.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 544\n",
      "Total Reward: 250\n",
      "Total episodes 264\n",
      "Eps_threshold: 0.020002698865474126\n",
      "Loss ep: 0.031184304844249378\n",
      "Score: 3180\n",
      "Highest: 256.0\n",
      "[[  2. 256.   8.   2.]\n",
      " [  4.  16.  64.  32.]\n",
      " [ 32. 128.  16.   4.]\n",
      " [  2.   8.   4.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 545\n",
      "Total Reward: 173\n",
      "Total episodes 187\n",
      "Eps_threshold: 0.019909609502030457\n",
      "Loss ep: 0.031025942634133732\n",
      "Score: 1836\n",
      "Highest: 128.0\n",
      "[[  2.   4.  32.   8.]\n",
      " [128.   8.  64.  32.]\n",
      " [  8.  32.  16.   4.]\n",
      " [  2.   4.  64.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 546\n",
      "Total Reward: 135\n",
      "Total episodes 149\n",
      "Eps_threshold: 0.01983605723363436\n",
      "Loss ep: 0.02986222465566341\n",
      "Score: 1444\n",
      "Highest: 128.0\n",
      "[[  8.  16.   4.   2.]\n",
      " [  4. 128.   8.  32.]\n",
      " [  2.  16.  32.   8.]\n",
      " [  8.  64.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 547\n",
      "Total Reward: 163\n",
      "Total episodes 177\n",
      "Eps_threshold: 0.019749392185605424\n",
      "Loss ep: 0.031209732853086654\n",
      "Score: 1792\n",
      "Highest: 128.0\n",
      "[[  8.   2.   4.  16.]\n",
      " [ 32. 128.  32.   2.]\n",
      " [ 64.  32.  64.   4.]\n",
      " [  4.   2.   8.   2.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 0\n",
      "---------------------------\n",
      "Episode: 548\n",
      "Total Reward: 149\n",
      "Total episodes 163\n",
      "Eps_threshold: 0.01967025755095514\n",
      "Loss ep: 0.030702830823652584\n",
      "Score: 1656\n",
      "Highest: 128.0\n",
      "[[  2.   8.   2.   8.]\n",
      " [  4.  64.  32.  64.]\n",
      " [ 32.   8.   2.   4.]\n",
      " [  2.   4. 128.   8.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 549\n",
      "Total Reward: 152\n",
      "Total episodes 166\n",
      "Eps_threshold: 0.019590326585658013\n",
      "Loss ep: 0.03020847849099033\n",
      "Score: 1668\n",
      "Highest: 128.0\n",
      "[[  2.  64.   4.   2.]\n",
      " [  4.  16.  32.  16.]\n",
      " [  8.  64.  16.   2.]\n",
      " [  4.  16.   2. 128.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 550\n",
      "Total Reward: 244\n",
      "Total episodes 258\n",
      "Eps_threshold: 0.019467405915622425\n",
      "Loss ep: 0.030546399049980695\n",
      "Score: 3160\n",
      "Highest: 256.0\n",
      "[[  2.   8.  32.   4.]\n",
      " [  4. 256.   8.  16.]\n",
      " [  8.  32. 128.  64.]\n",
      " [  2.  16.   2.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 551\n",
      "Total Reward: 198\n",
      "Total episodes 212\n",
      "Eps_threshold: 0.019367581417445465\n",
      "Loss ep: 0.02963313066734458\n",
      "Score: 2508\n",
      "Highest: 256.0\n",
      "[[  2.   4.  16.   4.]\n",
      " [ 32. 256.  32.   8.]\n",
      " [  4.   8.  64.   2.]\n",
      " [  2.  32.   8.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 552\n",
      "Total Reward: 161\n",
      "Total episodes 175\n",
      "Eps_threshold: 0.019285972639128297\n",
      "Loss ep: 0.031146812438964843\n",
      "Score: 1740\n",
      "Highest: 128.0\n",
      "[[  2.  16.  64.   2.]\n",
      " [  4.  32. 128.   4.]\n",
      " [  8.  64.  16.   8.]\n",
      " [  4.   8.  32.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 553\n",
      "Total Reward: 168\n",
      "Total episodes 182\n",
      "Eps_threshold: 0.019201853610184522\n",
      "Loss ep: 0.03113573200100071\n",
      "Score: 1968\n",
      "Highest: 128.0\n",
      "[[  2.  16. 128.   2.]\n",
      " [  4. 128.  16.   4.]\n",
      " [ 64.   8.   2.   8.]\n",
      " [  4.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 554\n",
      "Total Reward: 136\n",
      "Total episodes 150\n",
      "Eps_threshold: 0.019133097864446908\n",
      "Loss ep: 0.030151023864746093\n",
      "Score: 1440\n",
      "Highest: 128.0\n",
      "[[  2.   8.   4.   2.]\n",
      " [  4. 128.  16.   4.]\n",
      " [ 16.  32.   4.  32.]\n",
      " [  4.  64.   8.   4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 16\n",
      "---------------------------\n",
      "Episode: 555\n",
      "Total Reward: 243\n",
      "Total episodes 257\n",
      "Eps_threshold: 0.0190164883774094\n",
      "Loss ep: 0.029630015332411237\n",
      "Score: 3104\n",
      "Highest: 256.0\n",
      "[[  4.   8.   4.   2.]\n",
      " [  2.  32.  64.  16.]\n",
      " [ 16. 128. 256.   8.]\n",
      " [  4.  16.   4.   2.]]\n",
      "Last action: LEFT\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 556\n",
      "Total Reward: 129\n",
      "Total episodes 143\n",
      "Eps_threshold: 0.018952250409911622\n",
      "Loss ep: 0.030206703639530635\n",
      "Score: 1364\n",
      "Highest: 128.0\n",
      "[[  2.  64.  16.   4.]\n",
      " [  4.  16. 128.  16.]\n",
      " [  8.   4.   8.   4.]\n",
      " [  4.   2.  32.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 557\n",
      "Total Reward: 182\n",
      "Total episodes 196\n",
      "Eps_threshold: 0.018864946842095224\n",
      "Loss ep: 0.02901938010235222\n",
      "Score: 2064\n",
      "Highest: 128.0\n",
      "[[  8. 128.  32.   2.]\n",
      " [  2.   8. 128.   8.]\n",
      " [  8.  64.  16.   4.]\n",
      " [  4.   8.   4.   2.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 558\n",
      "Total Reward: 232\n",
      "Total episodes 246\n",
      "Eps_threshold: 0.018756575843860514\n",
      "Loss ep: 0.029537348243279186\n",
      "Score: 2936\n",
      "Highest: 256.0\n",
      "[[ 64.   8.   4.   2.]\n",
      " [ 16.  64. 256.  64.]\n",
      " [  4.  16.  32.  16.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: UP\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 559\n",
      "Total Reward: 148\n",
      "Total episodes 162\n",
      "Eps_threshold: 0.018685934064963276\n",
      "Loss ep: 0.029766936361053844\n",
      "Score: 1596\n",
      "Highest: 128.0\n",
      "[[  2.   8.  32.   2.]\n",
      " [ 16. 128.  64.   4.]\n",
      " [  4.   2.   4.  64.]\n",
      " [  2.   4.   8.   4.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 8\n",
      "---------------------------\n",
      "Episode: 560\n",
      "Total Reward: 97\n",
      "Total episodes 111\n",
      "Eps_threshold: 0.018637860658005406\n",
      "Loss ep: 0.03005585799346099\n",
      "Score: 844\n",
      "Highest: 64.0\n",
      "[[ 2.  8.  2.  4.]\n",
      " [ 4. 16.  8. 32.]\n",
      " [ 8. 32. 64.  8.]\n",
      " [ 2. 16. 32.  4.]]\n",
      "Last action: DOWN\n",
      "Last scores move: 4\n",
      "---------------------------\n",
      "Episode: 561\n",
      "Total Reward: 169\n",
      "Total episodes 183\n",
      "Eps_threshold: 0.018559184724292778\n",
      "Loss ep: 0.028965892687521345\n",
      "Score: 2148\n",
      "Highest: 256.0\n",
      "[[  8.  32.   4.   2.]\n",
      " [  2. 256.   2.  16.]\n",
      " [  8.  32.  16.   4.]\n",
      " [  2.   4.   8.   2.]]\n",
      "Last action: RIGHT\n",
      "Last scores move: 0\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
